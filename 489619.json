{"tid":489619,"cid":18,"subCid":0,"title":"初級Stat分享","createTime":"2017-12-05T00:25:23.000Z","updateTime":"2018-01-09T07:22:09.000Z","uid":161501,"like":238,"dislike":5,"uniUserReply":151,"replies":[{"pid":"fff285f9f5cf10dfdb3da05b13a30a8d5bb96ac3","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T00:25:23.000Z","msg":"利申先:讀緊STAT，見太多Major朋友問我Stat。<img src=\"/assets/faces/lomoji/30.png\" class=\"hkgmoji\" /> 心諗不如開個post分享下。<img src=\"/assets/faces/lomoji/13.png\" class=\"hkgmoji\" /> <br />\n不過我只係year3，太深要高手指教。<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <br />\n預計會講(technical terms會用English)  ：<br />\n1. Nature of Statistics (Variables and Type of Data, Observation Studies...)<br />\n2. Data Description (Mean, mode, median, variance,...)<br />\n3. Probability (Conditional Prob., Bayes' Theorem)<br />\n4. Discrete Probability Distribution (Binomial, Poisson)<br />\n5. Continuous Probability Distribution (Normal, Chi-squared, Student's T, F)<br />\n6. Central Limit Theorem<br />\n7. Point Estimates and Confidence Intervals (Concept)<br />\n8. Hypothesis Testing (Concept)<br />\n9. Non-parametric Approach (Ranks)<br />\n10. One Sample Location Problem (Z-test ,T-test, Sign test, Wilcoxon)<br />\n11. Two Sample Location Problem (T-test ,paired T-test, Rank-sum test)<br />\n12. One Sample Dispersion Problem (Chi-squared test)<br />\n13. Two Sample Dispersion Problem (F-test, Siegel Turkey Test, KS test)<br />\n14. One-way Anova (Parametric, Kruskal&ndash;Wallis)<br />\n15. Two-way Anova (Unrepeated, Repeated observation, Friedman) <br />\n當然，我expect你識中學野<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /> (Mean, Mode, Median, nCr, nPr,&hellip;)<br />\n唔expect你識Calculus, Linear Algebra<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <br />\n後面講Testing，會主力講點用excel 同點樣interpret<br />\n我主要focus 個方法同Computation。唔太會詳細prove(因為要calculus)<br />\n講住咁多，都好多下。希望做到每日一篇。<br />\n有咩想聽，可以講。"},{"pid":"69ef7e0018469f18384087e58c4fe0eb1f712ebe","tid":489619,"uid":161501,"like":41,"dislike":0,"score":41,"citedBy":0,"replyTime":"2017-12-05T00:27:47.000Z","msg":"1.\tNature of Statistics<br />\n一般講What is Statistics，好多書都會落以下定義：<br />\n&ldquo;Statistics is the science of conducting studies to collect, organize, summarize, analyze, and draw conclusions from data.&rdquo;<br />\n冇錯，好多時我地都係對住data。究其原因，我覺得不外乎：<br />\ni.)\t資料越來越多，我地要諗計從一部分資料推測大路既情況。<img src=\"/assets/faces/lomoji/30.png\" class=\"hkgmoji\" /> <br />\nii.)\t預測以後既狀況（Probability 係呢度既語言）<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /> <br />\n所以Statistics呢科都係近一兩個世代先興起。因為以前資訊冇咁多，唔太需要建構一套方法去研究。<br />\n<br />\n介紹下兩個字眼<br />\nPopulation：就係你所有既研究對象。<br />\nSample：一部分既研究對象。<br />\n例如：你研究全港既人工水平。咁Population就係全港人口，Sample就係任何一部份人口，可以係35-40歲既人、住新界既人&hellip;&hellip;當然，用個堆Sample估計Population合唔合理，準唔準確係後話。<img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" /> <br />\n<br />\n跟住係Variables，其實同中學見到嘅xyz冇咩分別，就係可以有唔同結果既野。例如：研究身高(height)，咁可以係160,170,甚至180，所以身高係Variable。簡單而言，就係可以變化既野。<br />\n如果將每一個outcome都賦予一個Probability，例如0.7係身高160，0.2係身高170，0.1係身高180等等。咁呢個variable 就叫做random variables.<img src=\"/assets/faces/normal/angel.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/angel.gif\" class=\"hkgmoji\" /> <br />\n當然，variables都有兩種：<br />\ni.)\tQualitative<br />\nii.)\tQuantitative<br />\n簡單來說，Qualitative variables既outcome唔係實質有意思既數字，可能只係形容緊個variables既野。例如：Gender，outcome只係 male or female。呢的就係Qualitative。Quantitative當然就係數字有實質意思既variables。例如：身高，體重，血壓&hellip;&hellip;<br />\n例如：成績。如果你用分數作為result，就係Quantitative；相反，如果你用Pass/Fail 作為result就係Qualitative。<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <br />\n<br />\n講住咁多，睇下反應，今晚可能再打。"},{"pid":"d2410e2d37426fca12a6cfbf2d79897cd1000a7f","tid":489619,"uid":49004,"like":3,"dislike":7,"score":-4,"citedBy":0,"replyTime":"2017-12-05T00:33:40.000Z","msg":"<img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <br />\nMaths is fun"},{"pid":"a29138856331606bf4d5e9c1b68537780d428fbb","tid":489619,"uid":112321,"like":3,"dislike":3,"score":0,"citedBy":0,"replyTime":"2017-12-05T00:43:46.000Z","msg":"如果上年睇到你個post就唔洗讀得咁辛苦了<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"4b07900ede39774be940ab6140c30ab65901c7b8","tid":489619,"uid":44073,"like":2,"dislike":9,"score":-7,"citedBy":0,"replyTime":"2017-12-05T00:50:32.000Z","msg":"此回覆已被刪除"},{"pid":"9b9f356c34b8ae6543804f43d7a7b668e5e17e74","tid":489619,"uid":138144,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T00:51:16.000Z","msg":"<img src=\"/assets/faces/normal/good.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/good.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> btw 想識啲再深少少嘅stat 希望有時間有興趣可以講下"},{"pid":"26a5f1214603f1c72953a2f1f715e95436f3db47","tid":489619,"uid":161501,"like":2,"dislike":1,"score":1,"citedBy":0,"replyTime":"2017-12-05T00:58:40.000Z","msg":"<blockquote>Can stat prove Murphy's law?</blockquote><br />\n我聽過 law of rare event, 話會係poisson dist. 唔知關唔關事。<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /> <br />\n但老實說，我覺得呢個似信念多過定理"},{"pid":"019ed19713c741c667944d50593013d0653f2704","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T00:59:42.000Z","msg":"<blockquote><img src=\"/assets/faces/normal/good.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/good.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> btw 想識啲再深少少嘅stat 希望有時間有興趣可以講下</blockquote><br />\n都可以交流，我依加先完左stochatic."},{"pid":"4f3f34d43812d9c04ba5ffc15b653c94e8f4673f","tid":489619,"uid":49004,"like":8,"dislike":1,"score":7,"citedBy":0,"replyTime":"2017-12-05T01:01:06.000Z","msg":"<blockquote><blockquote>Can stat prove Murphy's law?</blockquote><br />\n我聽過 law of rare event, 話會係poisson dist. 唔知關唔關事。<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /> <br />\n但老實說，我覺得呢個似信念多過定理</blockquote><br />\n唔使理烏大龜 只係刷存在感嘅可憐人<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n教你想要教嘅野就得<img src=\"/assets/faces/normal/biggrin.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" />"},{"pid":"c1d8da040b7b496344895cedaa1dea75f7fe1b16","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T01:02:10.000Z","msg":"<blockquote><img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <br />\nMaths is fun</blockquote><br />\nvery funny. 我依加讀埋個堆咩green divergence stoke都唔知有咩用"},{"pid":"9dfe9a998b9d1e2545b5e2f704e4284a8e201820","tid":489619,"uid":44073,"like":0,"dislike":8,"score":-8,"citedBy":0,"replyTime":"2017-12-05T01:02:26.000Z","msg":"此回覆已被刪除"},{"pid":"9d0a8b7a4e5e6feb390db0cdf1f6d1ad98572bb4","tid":489619,"uid":22148,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T01:02:34.000Z","msg":"Stat 路過 <img src=\"/assets/faces/normal/biggrin.gif\" class=\"hkgmoji\" />"},{"pid":"d850637dfd9f10244c6084c43af1ecd2d757d687","tid":489619,"uid":44073,"like":0,"dislike":7,"score":-7,"citedBy":0,"replyTime":"2017-12-05T01:03:08.000Z","msg":"此回覆已被刪除"},{"pid":"7e7f66bb3773c4955aff28b553934e6576d8acbc","tid":489619,"uid":141496,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T01:13:52.000Z","msg":"初級仔 學緊hypothesis testing, correlation and regression analysis <img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" />  學完今個sem就完 下個sem take advanced"},{"pid":"d07c7e1b62aea91454aec33459489409513924d9","tid":489619,"uid":76369,"like":2,"dislike":1,"score":1,"citedBy":0,"replyTime":"2017-12-05T01:17:40.000Z","msg":"留名 想學多啲hypothesis test既details<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"d84c1431b2a2a1da68dc7c5af9b10c57332d9d86","tid":489619,"uid":110892,"like":2,"dislike":0,"score":2,"citedBy":0,"replyTime":"2017-12-05T01:18:36.000Z","msg":"完全唔識STAT<br />\n<br />\n留名等教, distribution/ variance/ t test/ z stat"},{"pid":"603e08c7eba43b509fdb1743420e85300d09d29c","tid":489619,"uid":43770,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T01:25:59.000Z","msg":"樓主學左ARCH個啲未？"},{"pid":"55cd49339fa5943d3dde35818f06832e713065a1","tid":489619,"uid":67815,"like":5,"dislike":0,"score":5,"citedBy":0,"replyTime":"2017-12-05T01:38:45.000Z","msg":"工程撚表示勁憎stat<br />\n留名等樓主比我對stat改觀"},{"pid":"c065cbdfc2db4b48336b420f258ab9cff1c712f4","tid":489619,"uid":161501,"like":4,"dislike":0,"score":4,"citedBy":0,"replyTime":"2017-12-05T02:00:59.000Z","msg":"多謝各巴絲支持，我都要加快腳步。<img src=\"/assets/faces/lomoji/09.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/09.png\" class=\"hkgmoji\" /> <br />\n繼續variables，上次講到Qualitative and Quantitative variables. 咁Quantitative 重可以分為discrete and continuous variables. 應該唔難理解。<br />\nDiscrete variables 就係的outcomes你可以數出黎。例如：擲五次銀仔，公的次數。Outcomes 就係0,1,2,3,4,5你可以數。<br />\n但continuous variables就數唔到，通常係一個範圍內既數字。例如：身高。Outcomes 通常係150-200 cm.多數會包括分數小數。<br />\n<br />\nLevel of Measurement<br />\n呢個另一種將data 分為四種類別的方法。<br />\ni.)\tNominal<br />\nii.)\tOrdinal<br />\niii.)\tInterval<br />\niv.)\tRatio<br />\nNominal就係將data分為唔同既種類，而種類之間冇優次。例如：Gender. Male Female 只係種類而且冇得分男先定女先。咁就係Nominal。Examples include Nationality, religion,&hellip;<br />\n<br />\nOrdinal 同Nominal 差唔多，不過種類之間有優次。例如：Grade. A B C D F 係有優次。 Examples include Sport rankings, rating scale, course e(agree, disagree, very disagree&hellip;)<br />\n<br />\nInterval 同 Ratio 都係講 data 已經係數字(continuous)。但係interval 係冇 true zero，即0係冇意思(可以take negative) 。但Ratio有冇 true zero(唔可以take negative)<br />\nInterval level include IQ, Temperature (in Degree Celsius scale),&hellip;<br />\nOrdinal level include height, weight, temperature (in Kelvin scale)<br />\n<br />\n識得分可以選擇test時快的<br />\n<br />\n今晚可能講 observation studies."},{"pid":"14bcecd7b89cc41002f4f7d0160199843b1e287f","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T02:03:35.000Z","msg":"<blockquote>樓主學左ARCH個啲未？</blockquote><br />\n好似Time Series? 今個sem冇take，唔曉。<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" />"},{"pid":"6634d861c25ae0beea1ac09e2d14a141652981f6","tid":489619,"uid":43770,"like":0,"dislike":1,"score":-1,"citedBy":0,"replyTime":"2017-12-05T02:09:43.000Z","msg":"<blockquote><blockquote>樓主學左ARCH個啲未？</blockquote><br />\n好似Time Series? 今個sem冇take，唔曉。<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\nYes"},{"pid":"78a3172475c520bbca31101cad7528f48b4c893e","tid":489619,"uid":69238,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T02:14:35.000Z","msg":"留名學野"},{"pid":"87152bce3a3bf1fb8442d03442184af1ec16e595","tid":489619,"uid":14436,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-05T02:16:57.000Z","msg":"勁憎stat+1<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n不過支持樓主<img src=\"/assets/faces/normal/good.gif\" class=\"hkgmoji\" />"},{"pid":"7c072c7c1cf9877ea023bc8b788e42c940de916e","tid":489619,"uid":132847,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T02:22:02.000Z","msg":"同你同年 咩u? <br />\n利申 學嘢"},{"pid":"edb9125bcf9fc77a21b4ecaca7c4d67eff4bb423","tid":489619,"uid":161501,"like":0,"dislike":1,"score":-1,"citedBy":0,"replyTime":"2017-12-05T02:27:20.000Z","msg":"<blockquote>同你同年 咩u? <br />\n利申 學嘢</blockquote><br />\n唔太想自爆，三大。"},{"pid":"46e606f87515bd955652558a3dbb89d4909d358a","tid":489619,"uid":49004,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-05T03:12:33.000Z","msg":"<blockquote><blockquote>同你同年 咩u? <br />\n利申 學嘢</blockquote><br />\n唔太想自爆，三大。</blockquote><br />\n三大<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <br />\n好屈"},{"pid":"1a713b82f87b928793cbea74c7a2384e3b5e17c5","tid":489619,"uid":3441,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-05T03:29:11.000Z","msg":"留名。<br />\nAny reference?"},{"pid":"a213b6a1c06a00f1e0ce599e5982d6add3390d53","tid":489619,"uid":28052,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T03:32:13.000Z","msg":"想請教spss <br />\nPost host test<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" />"},{"pid":"2eaca673149e60aa5814b632164ac4db1a315429","tid":489619,"uid":138375,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T03:34:27.000Z","msg":"lm 學野 好多都唔記得了"},{"pid":"533512cf0069dd38b4c8e7d1e7faf5e2060da331","tid":489619,"uid":146760,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T03:37:26.000Z","msg":"次次都錯interval同ratio,唔係好明true zero"},{"pid":"d661eb156a92e50034fa3546e0ef8735b0c33db4","tid":489619,"uid":136002,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T03:40:28.000Z","msg":"今個sem 學R 學到<img src=\"/assets/faces/lomoji/18.png\" class=\"hkgmoji\" />"},{"pid":"1ed8bccabcfba3be3108cf689ca699b4cddd59f8","tid":489619,"uid":161666,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T03:50:19.000Z","msg":"已學 SPSS 22, SAS 9.3 9.4"},{"pid":"83281b12094f98928ed7fea1588e173ceadf7b84","tid":489619,"uid":100760,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-05T04:26:19.000Z","msg":"留名學嘢"},{"pid":"a7836423f7809e18f8655ef8a6233e3f1969bc8b","tid":489619,"uid":161407,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T04:38:47.000Z","msg":"留名，求教SPSS<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"f5a9730078e5ef84a89911f0d4448a0db9cf61e9","tid":489619,"uid":161501,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-05T04:59:32.000Z","msg":"<blockquote>留名。<br />\nAny reference?</blockquote><br />\n其實我都係跟Bluman 既 Elementary Statistics:A step by step approach<br />\n比較多examples"},{"pid":"6b90ce1eb65c5d299d925e53e098cc26d653a2d1","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T05:01:01.000Z","msg":"<blockquote>想請教spss <br />\nPost host test<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" /></blockquote><br />\npost hoc 我覺得最難係用咩test. 上youtube 打post hoc spss 應該有好多materials"},{"pid":"6f3369231622f85d4a0f1e8170e597f865ed52b6","tid":489619,"uid":161501,"like":2,"dislike":0,"score":2,"citedBy":0,"replyTime":"2017-12-05T05:02:58.000Z","msg":"<blockquote>次次都錯interval同ratio,唔係好明true zero</blockquote><br />\ntrue zero的確對初學者唔太友善，諗下可唔可以負數幫助大的"},{"pid":"e1a1e58d6fe2b4af84af6918554d30c015f410c4","tid":489619,"uid":65939,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T05:45:10.000Z","msg":"Lm 以前讀過，想溫下"},{"pid":"70cbd98c60422621fe39153a6de5577f2274bbc9","tid":489619,"uid":51673,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-05T05:49:31.000Z","msg":"好有用<br />\n實卜樓豬"},{"pid":"5dfdca785d0e72c44e1071a1e0d462c2ad20b3eb","tid":489619,"uid":100760,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T06:43:11.000Z","msg":"今個sem take左4個計數course，好辛苦<br />\n其中兩個係regression同time series，另外兩個course主要講markov chain"},{"pid":"0de4c740d70be29aae920397a5e1510d279be189","tid":489619,"uid":100760,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-05T06:44:49.000Z","msg":"<blockquote>樓主學左ARCH個啲未？</blockquote><br />\n巴打見你喺另外個數學post都有提time series<br />\n我今個sem學緊，可否講下係咩問題，睇下我識唔識<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"1fff175b5222f1357392f2124f4505d6320a6f2a","tid":489619,"uid":43770,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T07:29:44.000Z","msg":"<blockquote><blockquote>樓主學左ARCH個啲未？</blockquote><br />\n巴打見你喺另外個數學post都有提time series<br />\n我今個sem學緊，可否講下係咩問題，睇下我識唔識<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n係上個sem既course 黎架啦<br />\n睇返啲proof唔明自己寫咩<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"93598b1e5358fdfadd3e971e93bc9ebad3b73d4d","tid":489619,"uid":43770,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T07:38:06.000Z","msg":"另外MLE 有冇人知點搵<br />\n巴打可以既話講下likelihood<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"da873bb7a80f7b35c88fb630e7785a29fa1bbecf","tid":489619,"uid":161501,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-05T11:47:45.000Z","msg":"<blockquote>另外MLE 有冇人知點搵<br />\n巴打可以既話講下likelihood<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n呢個係point estimation 既一個方法。我地想從sample 中estimate model既 parameter. 例如 binomial 既 p , poisson既 lambda ,甚至係regression model 既 coefficients. <br />\n咁估要有方法，冇理由亂估。Maximum likelihood 既諗法係我估個parameter會令到個model generate 我呢個sample 既prob.係最大。<br />\n當然，講到maximize ，多數都係d完set做0。(亦有其他方法)"},{"pid":"8f855674dbd24e5de7e93d467a5efe8b58b71ce0","tid":489619,"uid":43770,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T12:29:06.000Z","msg":"<blockquote><blockquote>另外MLE 有冇人知點搵<br />\n巴打可以既話講下likelihood<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n呢個係point estimation 既一個方法。我地想從sample 中estimate model既 parameter. 例如 binomial 既 p , poisson既 lambda ,甚至係regression model 既 coefficients. <br />\n咁估要有方法，冇理由亂估。Maximum likelihood 既諗法係我估個parameter會令到個model generate 我呢個sample 既prob.係最大。<br />\n當然，講到maximize ，多數都係d完set做0。(亦有其他方法)</blockquote><br />\n即刻大約明哂<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"0c5f3b7aea13fd291fb75907dc57110e3c247ea6","tid":489619,"uid":39463,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T12:40:59.000Z","msg":"<img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /> 留名學野<br />\n十鳩幾年前學過，唔記得哂"},{"pid":"fcc0b0aea53e008af8eafbb40fad04747d71f142","tid":489619,"uid":20693,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-05T12:43:33.000Z","msg":"留名學野，唔好半途腰斬啊<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"32d07f9acb4e6240baeac4da52b3b962715ef3d0","tid":489619,"uid":103339,"like":0,"dislike":5,"score":-5,"citedBy":0,"replyTime":"2017-12-05T13:03:06.000Z","msg":"有冇d關賭博事嘅stat知識？<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <br />\n想知only,唔會賭"},{"pid":"c1fcb1ce5a2d8e1a12afd7f29cdfe258ea9632c3","tid":489619,"uid":69125,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T13:06:00.000Z","msg":"ratio interval唔係好明,點解temp (celsius)係interval?0度點解冇意義?"},{"pid":"271557dd46d11e40a6613c18740591cb030edf76","tid":489619,"uid":81424,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T13:09:21.000Z","msg":"留名<br />\n幾年前學過而家唔記得晒"},{"pid":"0fa223c73208278530e2601ae7c9bae3ff6dd4f5","tid":489619,"uid":81424,"like":2,"dislike":2,"score":0,"citedBy":0,"replyTime":"2017-12-05T13:10:25.000Z","msg":"<blockquote>ratio interval唔係好明,點解temp (celsius)係interval?0度點解冇意義?</blockquote><br />\n因為攝氏有-1度<br />\n所以0度冇咩意思 (interval)<br />\n<br />\n但絕對溫度冇-1度<br />\n所以好有意思 (ratio)"},{"pid":"5d1eb9de73d92b0efd36acc113c1ba2dc4698ff1","tid":489619,"uid":69125,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T13:12:01.000Z","msg":"<blockquote><blockquote>ratio interval唔係好明,點解temp (celsius)係interval?0度點解冇意義?</blockquote><br />\n因為攝氏有-1度<br />\n所以0度冇咩意思 (interval)<br />\n<br />\n但絕對溫度冇-1度<br />\n所以好有意思 (ratio)</blockquote><br />\n好難明<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" />"},{"pid":"b8bc790462b4e056b801eeab1e2ca2cc7facbddf","tid":489619,"uid":41204,"like":6,"dislike":1,"score":5,"citedBy":0,"replyTime":"2017-12-05T13:14:24.000Z","msg":"<blockquote><img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <br />\nMaths is fun</blockquote><br />\nstat唔係math"},{"pid":"5f8bb5b5fb8e81822f9b8f183743da7bbd4d0b0f","tid":489619,"uid":195,"like":1,"dislike":1,"score":0,"citedBy":0,"replyTime":"2017-12-05T13:15:34.000Z","msg":"<blockquote><blockquote>ratio interval唔係好明,點解temp (celsius)係interval?0度點解冇意義?</blockquote><br />\n因為攝氏有-1度<br />\n所以0度冇咩意思 (interval)<br />\n<br />\n但絕對溫度冇-1度<br />\n所以好有意思 (ratio)</blockquote><br />\n<br />\n用溫度有少少難解釋<br />\n因為唔係個個識Kelvin scale<br />\n長度係ratio就易明好多<br />\n你諗吓會唔會有人條丁負長度<img src=\"/assets/faces/normal/hehe.gif\" class=\"hkgmoji\" />"},{"pid":"ab458ed6593b6b7deba4231055ba1d43d7be8539","tid":489619,"uid":195,"like":0,"dislike":1,"score":-1,"citedBy":0,"replyTime":"2017-12-05T13:16:02.000Z","msg":"Btw留明學嘢<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" />"},{"pid":"f901d2180e267f554a2eeb0e981029b27ebc7206","tid":489619,"uid":69125,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T13:20:04.000Z","msg":"<blockquote><blockquote><blockquote>ratio interval唔係好明,點解temp (celsius)係interval?0度點解冇意義?</blockquote><br />\n因為攝氏有-1度<br />\n所以0度冇咩意思 (interval)<br />\n<br />\n但絕對溫度冇-1度<br />\n所以好有意思 (ratio)</blockquote><br />\n<br />\n用溫度有少少難解釋<br />\n因為唔係個個識Kelvin scale<br />\n長度係ratio就易明好多<br />\n你諗吓會唔會有人條丁負長度<img src=\"/assets/faces/normal/hehe.gif\" class=\"hkgmoji\" /></blockquote><br />\n溫度冇問題呀,我識degree k,但係某d長度就算冇負長度都唔會令0cm突然好有意義bor<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /> 定係你想講條丁0cm代表佢係女人,長過0cm就男人,所以有意義?"},{"pid":"2a28d2382ba676800becc895433ae5d25ed1a22b","tid":489619,"uid":3724,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-05T13:20:17.000Z","msg":"有無學過點先為止True random?<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"ad2eaad65ef07652c5b4b080135eb0e21539d4b8","tid":489619,"uid":40078,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T13:20:35.000Z","msg":"留名學嘢<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <br />\n學咗成個sem stat都唔知學咗乜嘢<img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" />"},{"pid":"924ddb9d1628374152186da330b64a6a26c78425","tid":489619,"uid":81424,"like":1,"dislike":1,"score":0,"citedBy":0,"replyTime":"2017-12-05T13:23:48.000Z","msg":"<blockquote><blockquote><blockquote><blockquote>ratio interval唔係好明,點解temp (celsius)係interval?0度點解冇意義?</blockquote><br />\n因為攝氏有-1度<br />\n所以0度冇咩意思 (interval)<br />\n<br />\n但絕對溫度冇-1度<br />\n所以好有意思 (ratio)</blockquote><br />\n<br />\n用溫度有少少難解釋<br />\n因為唔係個個識Kelvin scale<br />\n長度係ratio就易明好多<br />\n你諗吓會唔會有人條丁負長度<img src=\"/assets/faces/normal/hehe.gif\" class=\"hkgmoji\" /></blockquote><br />\n溫度冇問題呀,我識degree k,但係某d長度就算冇負長度都唔會令0cm突然好有意義bor<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /> 定係你想講條丁0cm代表佢係女人,長過0cm就男人,所以有意義?</blockquote><br />\n<br />\n攝氏30度熱過攝氏20度50%係冇意思<br />\n30cm長過20cm 50%係有意思 所以先叫ratio"},{"pid":"8de753d749bfc6ce53ff843b43e60f29285e41d2","tid":489619,"uid":69125,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T13:25:44.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote>ratio interval唔係好明,點解temp (celsius)係interval?0度點解冇意義?</blockquote><br />\n因為攝氏有-1度<br />\n所以0度冇咩意思 (interval)<br />\n<br />\n但絕對溫度冇-1度<br />\n所以好有意思 (ratio)</blockquote><br />\n<br />\n用溫度有少少難解釋<br />\n因為唔係個個識Kelvin scale<br />\n長度係ratio就易明好多<br />\n你諗吓會唔會有人條丁負長度<img src=\"/assets/faces/normal/hehe.gif\" class=\"hkgmoji\" /></blockquote><br />\n溫度冇問題呀,我識degree k,但係某d長度就算冇負長度都唔會令0cm突然好有意義bor<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /> 定係你想講條丁0cm代表佢係女人,長過0cm就男人,所以有意義?</blockquote><br />\n<br />\n<span style=\"color: red;\">攝氏30度熱過攝氏20度50%係冇意思</span><br />\n<span style=\"color: red;\">30cm長過20cm 50%係有意思</span> 所以先叫ratio</blockquote><br />\n紅字好難明<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" />"},{"pid":"a508235cc6ec07b78e37eefc12ec67fc4660da76","tid":489619,"uid":81424,"like":0,"dislike":2,"score":-2,"citedBy":0,"replyTime":"2017-12-05T13:31:09.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>ratio interval唔係好明,點解temp (celsius)係interval?0度點解冇意義?</blockquote><br />\n因為攝氏有-1度<br />\n所以0度冇咩意思 (interval)<br />\n<br />\n但絕對溫度冇-1度<br />\n所以好有意思 (ratio)</blockquote><br />\n<br />\n用溫度有少少難解釋<br />\n因為唔係個個識Kelvin scale<br />\n長度係ratio就易明好多<br />\n你諗吓會唔會有人條丁負長度<img src=\"/assets/faces/normal/hehe.gif\" class=\"hkgmoji\" /></blockquote><br />\n溫度冇問題呀,我識degree k,但係某d長度就算冇負長度都唔會令0cm突然好有意義bor<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /> 定係你想講條丁0cm代表佢係女人,長過0cm就男人,所以有意義?</blockquote><br />\n<br />\n<span style=\"color: red;\">攝氏30度熱過攝氏20度50%係冇意思</span><br />\n<span style=\"color: red;\">30cm長過20cm 50%係有意思</span> 所以先叫ratio</blockquote><br />\n紅字好難明<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /></blockquote><br />\n如果唔係嘅話<br />\n你會話攝氏100度係攝氏-100度 嘅 -100%<br />\n但suppose ratio會唔會出負數<br />\n所以唔叫佢做ratio"},{"pid":"5e8fb9cf72db09b81152da50efbb4d9ef663ce85","tid":489619,"uid":69125,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T13:32:30.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>ratio interval唔係好明,點解temp (celsius)係interval?0度點解冇意義?</blockquote><br />\n因為攝氏有-1度<br />\n所以0度冇咩意思 (interval)<br />\n<br />\n但絕對溫度冇-1度<br />\n所以好有意思 (ratio)</blockquote><br />\n<br />\n用溫度有少少難解釋<br />\n因為唔係個個識Kelvin scale<br />\n長度係ratio就易明好多<br />\n你諗吓會唔會有人條丁負長度<img src=\"/assets/faces/normal/hehe.gif\" class=\"hkgmoji\" /></blockquote><br />\n溫度冇問題呀,我識degree k,但係某d長度就算冇負長度都唔會令0cm突然好有意義bor<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /> 定係你想講條丁0cm代表佢係女人,長過0cm就男人,所以有意義?</blockquote><br />\n<br />\n<span style=\"color: red;\">攝氏30度熱過攝氏20度50%係冇意思</span><br />\n<span style=\"color: red;\">30cm長過20cm 50%係有意思</span> 所以先叫ratio</blockquote><br />\n紅字好難明<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /></blockquote><br />\n如果唔係嘅話<br />\n你會話攝氏100度係攝氏-100度 嘅 -100%<br />\n但suppose ratio會唔會出負數<br />\n所以唔叫佢做ratio</blockquote><br />\n明了<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"6899153c5ecf03222b52d34d9b5fc2e4367a91cf","tid":489619,"uid":63846,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T13:39:01.000Z","msg":"不如解釋下<br />\nConditional random field<br />\n<br />\nMarkov random field"},{"pid":"3d58f94a1bb8ca595b2c02a89b5656d0fb1d5cea","tid":489619,"uid":43770,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T14:06:41.000Z","msg":"<blockquote><blockquote><blockquote>另外MLE 有冇人知點搵<br />\n巴打可以既話講下likelihood<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n呢個係point estimation 既一個方法。我地想從sample 中estimate model既 parameter. 例如 binomial 既 p , poisson既 lambda ,甚至係regression model 既 coefficients. <br />\n咁估要有方法，冇理由亂估。Maximum likelihood 既諗法係我估個parameter會令到個model generate 我呢個sample 既prob.係最大。<br />\n當然，講到maximize ，多數都係d完set做0。(亦有其他方法)</blockquote><br />\n即刻大約明哂<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n點解likelihood function會係product of sequence ?"},{"pid":"2c6ca29e1a9e60fcd83a987274de85dfe5d7ac96","tid":489619,"uid":161501,"like":2,"dislike":0,"score":2,"citedBy":0,"replyTime":"2017-12-05T14:15:25.000Z","msg":"<blockquote><blockquote><blockquote><blockquote>另外MLE 有冇人知點搵<br />\n巴打可以既話講下likelihood<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n呢個係point estimation 既一個方法。我地想從sample 中estimate model既 parameter. 例如 binomial 既 p , poisson既 lambda ,甚至係regression model 既 coefficients. <br />\n咁估要有方法，冇理由亂估。Maximum likelihood 既諗法係我估個parameter會令到個model generate 我呢個sample 既prob.係最大。<br />\n當然，講到maximize ，多數都係d完set做0。(亦有其他方法)</blockquote><br />\n即刻大約明哂<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n點解likelihood function會係product of sequence ?</blockquote><br />\n因為每個observation都assume來自同一個distribution<br />\ne.g Let X~binomial distribution(n,p) n is known, estimate p<br />\n假設sample = {1,4,6,2} (做左四次experiments, assuming independent)<br />\n諗法係 Find the p s.t<br />\nP(X=1|p)*P(X=4|p)*P(X=6|p)*P(X=2|p) is maximized."},{"pid":"41415cc42c08cbddc2a078839e5c639b81f0524a","tid":489619,"uid":161501,"like":3,"dislike":0,"score":3,"citedBy":0,"replyTime":"2017-12-05T14:16:55.000Z","msg":"Observational Studies vs Experimental Studies<br />\n原來連點Study(硏究)都有分<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\nObservational Studies 就係個硏究主要從以往的觀察得出既數據作出結論，人為(researcher)操控成份很小。例如：想研究97後政府既民望，咁可能每一段時間check 下個民望，得出分析。基本上researcher唔會影響數據。<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /> <br />\nExperimental Studies 就唔同。Researcher會控制某的因素，睇下結果有咩不同。最常用既應該係Psychological studies。例如睇下環境對細路發展既影響<img src=\"/assets/faces/lomoji/03.png\" class=\"hkgmoji\" /> ，就會扔班細路去唔到地方，睇下有咩不同。Researcher控制既因素就叫independent variables 上例既independent variables就係環境; 結果就叫dependent variables上例既就係細路發展。"},{"pid":"72c181eabd2603f425ca948f2f9bc5f93efd5dda","tid":489619,"uid":43770,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T14:24:02.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote>另外MLE 有冇人知點搵<br />\n巴打可以既話講下likelihood<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n呢個係point estimation 既一個方法。我地想從sample 中estimate model既 parameter. 例如 binomial 既 p , poisson既 lambda ,甚至係regression model 既 coefficients. <br />\n咁估要有方法，冇理由亂估。Maximum likelihood 既諗法係我估個parameter會令到個model generate 我呢個sample 既prob.係最大。<br />\n當然，講到maximize ，多數都係d完set做0。(亦有其他方法)</blockquote><br />\n即刻大約明哂<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n點解likelihood function會係product of sequence ?</blockquote><br />\n因為每個observation都assume來自同一個distribution<br />\ne.g Let X~binomial distribution(n,p) n is known, estimate p<br />\n假設sample = {1,4,6,2} (做左四次experiments, assuming independent)<br />\n諗法係 Find the p s.t<br />\nP(X=1|p)*P(X=4|p)*P(X=6|p)*P(X=2|p) is maximized.</blockquote><br />\n<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> 明白"},{"pid":"e713b5bc64f01534a48bd48b4ef8a78bdce477bc","tid":489619,"uid":43770,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T14:25:54.000Z","msg":"上stat堂成日都有好多proof<br />\n試過抄足45分鐘抄完都唔知自己抄咩<br />\n<br />\n有咩方法可以改善<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" />"},{"pid":"58137d974e65e211a51976257d1e7539ee5de18e","tid":489619,"uid":72484,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T14:29:55.000Z","msg":"lm"},{"pid":"ab46c2cefdbec1111fa1527b12f66ad127042909","tid":489619,"uid":92117,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-05T14:32:47.000Z","msg":"點解用sample estimate個variance用n-1會準啲"},{"pid":"0c966d98f218035153e4f5be3217402c7ccee2aa","tid":489619,"uid":75209,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T14:48:07.000Z","msg":"讀Stat 洗唔洗數底，例如linear regression least square method 嘅proof <br />\n例如probability density function 點 derive 出嚟，又洗唔洗知<br />\ntest statistics 背後嘅數學logic 洗唔洗知得深入<br />\n定係application 為主？<br />\napplication 又用乜software <br />\nMATLAB，SAS洗唔洗好熟<br />\ncoding 又洗唔洗識？"},{"pid":"66fa91f3cd87a02d301c73126e43a772facda5c6","tid":489619,"uid":7115,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-05T16:39:37.000Z","msg":"可唔可以略略講下6，7，8 個d central limit theorem, estimations and hypotheses testing, 同埋confidence interval 個d野就快要final exam<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <br />\n利申year 1 student"},{"pid":"8cebd1ca050fda37042e259988059159d3be4053","tid":489619,"uid":110051,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T17:08:01.000Z","msg":"Quan Fin 樓名學野"},{"pid":"010c141958ec24da6dd1063c1b007284c82eb537","tid":489619,"uid":100760,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-05T17:16:08.000Z","msg":"<blockquote>讀Stat 洗唔洗數底，例如linear regression least square method 嘅proof <br />\n例如probability density function 點 derive 出嚟，又洗唔洗知<br />\ntest statistics 背後嘅數學logic 洗唔洗知得深入<br />\n定係application 為主？<br />\napplication 又用乜software <br />\nMATLAB，SAS洗唔洗好熟<br />\ncoding 又洗唔洗識？</blockquote><br />\n我自己就覺得係睇professor，今個sem take regression同time series，professor經常skip proof<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> 有啲professor就鍾意show下quali成日prove<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n我自己就數底差，鐘意skip proof<br />\n如果想做研究應該要識啲proof，出嚟做嘢就識用software做application就ok"},{"pid":"8191c372854198aaec71b40138b6131e867b4c6b","tid":489619,"uid":100760,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T17:20:11.000Z","msg":"<blockquote>上stat堂成日都有好多proof<br />\n試過抄足45分鐘抄完都唔知自己抄咩<br />\n<br />\n有咩方法可以改善<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n試下唔好抄，淨係影相，professor prove嘅時候諗下點解"},{"pid":"2452a642bee74cd684026517cfdea5452f225770","tid":489619,"uid":137123,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T17:20:36.000Z","msg":"thx樓主 幫到好多<img src=\"/assets/faces/big/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/big/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/big/adore.gif\" class=\"hkgmoji\" />"},{"pid":"02a138b83abbd36c3e974b0fcf8a2532e71f4eed","tid":489619,"uid":94069,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T17:25:07.000Z","msg":"高汁lm"},{"pid":"0ad80f32975c555c79bf5585cca687fb452df069","tid":489619,"uid":10631,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T17:29:46.000Z","msg":"Phys撚路過<br />\n想問樓主幾時sd用除n 幾時用除n-1<br />\n見親都好似用n-1<br />\n學Statistical thermodynamics 個陣就用n?"},{"pid":"05e6664cb19845056e86bcec5fbe3c61572f9a5f","tid":489619,"uid":44723,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T17:47:08.000Z","msg":"有冇邊本書岩初學者睇？"},{"pid":"200397f900080b1828c14f22a7852c651a60fd93","tid":489619,"uid":8243,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T17:57:33.000Z","msg":"留名先 畀stat玩咗兩個sem <img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" /> <br />\n尤其係probabilities <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" />"},{"pid":"ef1cf4970b4f4615be0464c2702f12772d569972","tid":489619,"uid":69125,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T18:01:24.000Z","msg":"<blockquote>Phys撚路過<br />\n想問樓主幾時sd用除n 幾時用除n-1<br />\n見親都好似用n-1<br />\n學Statistical thermodynamics 個陣就用n?</blockquote><br />\n好似係當sampling size細(m1學過sample size&lt;30)時要estimate population variance先用n-1?"},{"pid":"32ad287803c0a34b5e62e4c1a139b4ec160f76f9","tid":489619,"uid":72046,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T18:36:37.000Z","msg":"樓主可唔可以偷跑第五個topic<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <br />\n星期六考<img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" />"},{"pid":"656f703fcfedae14325d5af233a672e68f30e337","tid":489619,"uid":21345,"like":0,"dislike":1,"score":-1,"citedBy":0,"replyTime":"2017-12-05T19:46:52.000Z","msg":"<blockquote>樓主可唔可以偷跑第五個topic<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <br />\n星期六考<img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /></blockquote><br />\n自己睇書啦 基本嘢 prob and stat inference hogg 有"},{"pid":"b92ae323f0a9eec5f27cf00396214fa09b04b35b","tid":489619,"uid":21345,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T19:47:06.000Z","msg":"<blockquote>有冇邊本書岩初學者睇？</blockquote><br />\nprob and stat inference hogg"},{"pid":"42fde64bde62736251b4ecef2e761091ec74b142","tid":489619,"uid":121366,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T20:15:32.000Z","msg":"Lm"},{"pid":"0bddbe4fae4f502decf14c174a8cb4b6ff873642","tid":489619,"uid":121366,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T20:17:25.000Z","msg":"巴打可否解釋ANOVA 數學原理<img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" /> <br />\n下兩個星期要present <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"27838fd409ecb5191e581d1b1bfd1a5544d1a37a","tid":489619,"uid":27520,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T20:44:40.000Z","msg":"Language jj留名<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"39ac87a9a26b272060185e6da8c874c2171f7440","tid":489619,"uid":60333,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T21:29:05.000Z","msg":"樓主果個F-TEST係咪the f-test<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> ，唔太明果個，過兩日econometrics final要考<br />\n講緊啲variables contribution to y果個test<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"6aaf7886305618e277f4eae7f26bb40157b36152","tid":489619,"uid":41690,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-05T23:43:10.000Z","msg":"<blockquote><blockquote>Phys撚路過<br />\n想問樓主幾時sd用除n 幾時用除n-1<br />\n見親都好似用n-1<br />\n學Statistical thermodynamics 個陣就用n?</blockquote><br />\n好似係當sampling size細(m1學過sample size&lt;30)時要estimate population variance先用n-1?</blockquote><br />\n<br />\n我記得是population 用n, sample 用n-1"},{"pid":"1808c44470362c940f18de06a1616c379b4f56da","tid":489619,"uid":161501,"like":3,"dislike":0,"score":3,"citedBy":0,"replyTime":"2017-12-05T23:44:18.000Z","msg":"<blockquote>巴打可否解釋ANOVA 數學原理<img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" /> <br />\n下兩個星期要present <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\nAssume one -way anova．<br />\nintuitively,我地想test 有冇treatment difference between groups<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/06/071401_1865651b2a0b8d37f916dcd916a96c3b.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F06%2F071401_1865651b2a0b8d37f916dcd916a96c3b.png&h=369274f4&s={SIZE}\" /><br />\n就係睇下Sum of squared (within group) compare to sum of squared (between group) 會唔會好細．<br />\n當然有assumptions:<br />\n1. Normality<br />\n2. Independence between observations<br />\n3. Homoscedasticity (same variance)<br />\n大概outline係<br />\n1.Prove TSS (total sum of square) = SSW + SSB<br />\n2.Prove SSW/variance follows Chi-sqaure (n-r) (n is total observations, r is no. of groups) (Since each group square difference follows chi (%-1), % is no. observations of that group)<br />\n3.Under H0, TSS follows Chi-square (n-1)<br />\n4.因為Chi(r) + Chi(n) = Chi(n+r) (independent) 所以 SSB follows Chi (r-1)<br />\n5. F=(Chi/d.f)/(chi/d.f)=(SSB/(r-1))/(SSW/(n-r))=MSB/MSW<br />\n加上識睇呢個(我係excel整,very simple)<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /> <br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/06/074300_a02a1014f554bab0f0db5a5c268578bb.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F06%2F074300_a02a1014f554bab0f0db5a5c268578bb.png&h=5053179d&s={SIZE}\" /><br />\n唔明再寫詳細的"},{"pid":"3d5fde2c9f03d1f5ecfff0d2208801704b14f693","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T23:53:33.000Z","msg":"<blockquote>樓主果個F-TEST係咪the f-test<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> ，唔太明果個，過兩日econometrics final要考<br />\n講緊啲variables contribution to y果個test<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /></blockquote><br />\n唔太識econometrics<img src=\"/assets/faces/lomoji/37.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/37.png\" class=\"hkgmoji\" /> , 但variables contribution to y 係咪講regression.我地的確可以用f test ( or partial f test ) 睇下邊的x對predict y 有幫助"},{"pid":"26cb320527f9e86719d06a68b5c4c5028d11a674","tid":489619,"uid":23294,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-05T23:56:35.000Z","msg":"呢個sem學緊nonparametric stat lm<img src=\"/assets/faces/normal/hehe.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hehe.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hehe.gif\" class=\"hkgmoji\" /> 其實個idea幾有趣 諗緊可以點樣apply落financial market"},{"pid":"394ca95d828ae20dd149aceac0f41e3692be7f41","tid":489619,"uid":20693,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T01:34:56.000Z","msg":"樓主可唔可以講下咩叫fixed effect同random effect?<br />\n用GLMM成日用到但半桶水<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"05240279c147c06608a0cd9d3dee82406aadbdfd","tid":489619,"uid":60333,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T03:00:15.000Z","msg":"<blockquote><blockquote>樓主果個F-TEST係咪the f-test<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> ，唔太明果個，過兩日econometrics final要考<br />\n講緊啲variables contribution to y果個test<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /></blockquote><br />\n唔太識econometrics<img src=\"/assets/faces/lomoji/37.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/37.png\" class=\"hkgmoji\" /> , 但variables contribution to y 係咪講regression.我地的確可以用f test ( or partial f test ) 睇下邊的x對predict y 有幫助</blockquote><br />\n係呀，果隻F TEST都係根據regression analysis個結果計<img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" /> <br />\n上堂個prof話f test有兩隻解法<br />\n一隻就係計coef contribution<br />\n一隻就話all coef =0 &lt;唔係好明呢個"},{"pid":"01c55d2acaa66b9239f35b37505420842f0b711c","tid":489619,"uid":100760,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T03:50:01.000Z","msg":"<blockquote><blockquote><blockquote>樓主果個F-TEST係咪the f-test<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> ，唔太明果個，過兩日econometrics final要考<br />\n講緊啲variables contribution to y果個test<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /></blockquote><br />\n唔太識econometrics<img src=\"/assets/faces/lomoji/37.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/37.png\" class=\"hkgmoji\" /> , 但variables contribution to y 係咪講regression.我地的確可以用f test ( or partial f test ) 睇下邊的x對predict y 有幫助</blockquote><br />\n係呀，果隻F TEST都係根據regression analysis個結果計<img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" /> <br />\n上堂個prof話f test有兩隻解法<br />\n一隻就係計coef contribution<br />\n一隻就話all coef =0 &lt;唔係好明呢個</blockquote><br />\n一個係partial f test, only test one beta is zero<br />\n例如H0：beta 1 is zero<br />\nH1: beta 1 is not zero<br />\n<br />\n你唔明嗰個係test all beta are zero<br />\n即係H0：all betas are zero<br />\nH1: at least one of the beta above is not zero"},{"pid":"6842e3c29a331512f4a42331db985b21d7c5958a","tid":489619,"uid":838,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T04:30:26.000Z","msg":"數撚留名<br />\n<br />\n最憎statistics<img src=\"/assets/faces/normal/biggrin.gif\" class=\"hkgmoji\" /> <br />\n係一樣我呢世都唔會用嘅應用數學<img src=\"/assets/faces/normal/dead.gif\" class=\"hkgmoji\" />"},{"pid":"c21b59d3a74fe88220a9bb458c421195efd943ad","tid":489619,"uid":136396,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T04:45:15.000Z","msg":"lm"},{"pid":"92a7798ee58b344d6c2e00082ea21ddf02a74fa5","tid":489619,"uid":3929,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T05:51:49.000Z","msg":"<blockquote>數撚留名<br />\n<br />\n最憎statistics<img src=\"/assets/faces/normal/biggrin.gif\" class=\"hkgmoji\" /> <br />\n係一樣我呢世都唔會用嘅應用數學<img src=\"/assets/faces/normal/dead.gif\" class=\"hkgmoji\" /></blockquote><br />\nstat好有用喎<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"00d12064921fa979dacafe10564075e03c319fd4","tid":489619,"uid":132859,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T06:01:22.000Z","msg":"究竟啲H同X matrix係乜鳩黎<br />\n只係識運算唔識解<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" />"},{"pid":"862dbfd45810acbb09c03fd7f8a6c79b0d2617fe","tid":489619,"uid":23294,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T06:04:45.000Z","msg":"<blockquote><blockquote>數撚留名<br />\n<br />\n最憎statistics<img src=\"/assets/faces/normal/biggrin.gif\" class=\"hkgmoji\" /> <br />\n係一樣我呢世都唔會用嘅應用數學<img src=\"/assets/faces/normal/dead.gif\" class=\"hkgmoji\" /></blockquote><br />\nstat好有用喎<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n有用但唔好讀<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> 數撚應該唔會鍾意"},{"pid":"13b97ed2a6ec61686222ef6862dfcc8008f8a7da","tid":489619,"uid":87229,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T06:08:24.000Z","msg":"<img src=\"/assets/faces/normal/good.gif\" class=\"hkgmoji\" /> 過兩日考stat"},{"pid":"6702650cd02913b618e34748722ea07c74159c16","tid":489619,"uid":20693,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T06:11:13.000Z","msg":"<blockquote><blockquote><blockquote>數撚留名<br />\n<br />\n最憎statistics<img src=\"/assets/faces/normal/biggrin.gif\" class=\"hkgmoji\" /> <br />\n係一樣我呢世都唔會用嘅應用數學<img src=\"/assets/faces/normal/dead.gif\" class=\"hkgmoji\" /></blockquote><br />\nstat好有用喎<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n有用但唔好讀<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> 數撚應該唔會鍾意</blockquote><br />\n我自己係biol撚, 身邊都好多social sci人<br />\n我地都不約而同好想自己D stat好D<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" />"},{"pid":"21ee42a1706be4758e456342c160d04b9b9e89ad","tid":489619,"uid":563,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T06:25:54.000Z","msg":"<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" />"},{"pid":"b9d0008493902ce71c0fb751af9b60d087809485","tid":489619,"uid":69125,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T08:00:27.000Z","msg":"<blockquote><blockquote><blockquote>Phys撚路過<br />\n想問樓主幾時sd用除n 幾時用除n-1<br />\n見親都好似用n-1<br />\n學Statistical thermodynamics 個陣就用n?</blockquote><br />\n好似係當sampling size細(m1學過sample size&lt;30)時要estimate population variance先用n-1?</blockquote><br />\n<br />\n我記得是population 用n, sample 用n-1</blockquote><br />\n當sample size夠大應該可以直接當population直接用n?"},{"pid":"c47b38dbc0fc570205e047b382acd7dff9541a17","tid":489619,"uid":1304,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T09:10:24.000Z","msg":"19號考stat入嚟留個名先<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"5165b1d40506f973d084f9a409b256a5479cb2c1","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T09:13:54.000Z","msg":"<blockquote><blockquote><blockquote><blockquote>Phys撚路過<br />\n想問樓主幾時sd用除n 幾時用除n-1<br />\n見親都好似用n-1<br />\n學Statistical thermodynamics 個陣就用n?</blockquote><br />\n好似係當sampling size細(m1學過sample size&lt;30)時要estimate population variance先用n-1?</blockquote><br />\n<br />\n我記得是population 用n, sample 用n-1</blockquote><br />\n當sample size夠大應該可以直接當population直接用n?</blockquote><br />\nsample size夠大個陣，除n定n-1都無咩分別"},{"pid":"db77f715f43933893e03798fc63cbc37f209189c","tid":489619,"uid":49004,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T09:14:55.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote>Phys撚路過<br />\n想問樓主幾時sd用除n 幾時用除n-1<br />\n見親都好似用n-1<br />\n學Statistical thermodynamics 個陣就用n?</blockquote><br />\n好似係當sampling size細(m1學過sample size&lt;30)時要estimate population variance先用n-1?</blockquote><br />\n<br />\n我記得是population 用n, sample 用n-1</blockquote><br />\n當sample size夠大應該可以直接當population直接用n?</blockquote><br />\nsample size夠大個陣，除n定n-1都無咩分別</blockquote><br />\nSample除n-1意義係乜<br />\n點解係n-1唔係其他"},{"pid":"16607f1e74d17121751958e82ba0309eef743693","tid":489619,"uid":75209,"like":2,"dislike":0,"score":2,"citedBy":0,"replyTime":"2017-12-06T09:45:47.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>Phys撚路過<br />\n想問樓主幾時sd用除n 幾時用除n-1<br />\n見親都好似用n-1<br />\n學Statistical thermodynamics 個陣就用n?</blockquote><br />\n好似係當sampling size細(m1學過sample size&lt;30)時要estimate population variance先用n-1?</blockquote><br />\n<br />\n我記得是population 用n, sample 用n-1</blockquote><br />\n當sample size夠大應該可以直接當population直接用n?</blockquote><br />\nsample size夠大個陣，除n定n-1都無咩分別</blockquote><br />\nSample除n-1意義係乜<br />\n點解係n-1唔係其他</blockquote><br />\n你計sample  SD 係想measure population 嘅分散<br />\n如果你take n instead of n-1 <br />\nsample SD 一定會細過或等於population SD <br />\n因為sample 包含即observations 少<br />\n所以如果要將佢unbiased<br />\n就要減佢degree if freedom <br />\n減1係因為derive from 1個variable <br />\ndf=1<br />\n好似係，只係讀過少少 stat <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"c962e4ffe6defd9b9d9c82724adbc1b08f29a80c","tid":489619,"uid":838,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T09:55:39.000Z","msg":"識計 不等於 識解<img src=\"/assets/faces/lomoji/18.png\" class=\"hkgmoji\" /> <br />\n<br />\n好多人根本唔知自己做緊乜<br />\n唔知自己用緊嘅工具點解會啱<img src=\"/assets/faces/lomoji/04.png\" class=\"hkgmoji\" /> <br />\n<br />\n上第一個stat course已經唔知自己做緊乜，鳩計鳩背呃隻B返嚟<br />\n讀完year one以後都唔會再讀<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" />"},{"pid":"761a9036f20a2ded01b1fbe35024ac272121a47b","tid":489619,"uid":57700,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T09:58:58.000Z","msg":"此回覆已被刪除"},{"pid":"1a035c754112e27bb59c51dc7b26e28b89e90f9b","tid":489619,"uid":136924,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:01:39.000Z","msg":"Stat撚留名 完全唔知point estimation同hypothesis testing 做乜鳩<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"1f6eac6b675c4bccd7d8088d97fc7950fbc650c5","tid":489619,"uid":136924,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:01:39.000Z","msg":"Stat撚留名 完全唔知point estimation同hypothesis testing 做乜鳩<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"2e28c523b71b9da67910b1b09bf8eebbdd0b8b89","tid":489619,"uid":136924,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:01:39.000Z","msg":"Stat撚留名 完全唔知point estimation同hypothesis testing 做乜鳩<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"49d928289b19ae6d6a5265fc2a8353a198d54d29","tid":489619,"uid":136924,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:01:39.000Z","msg":"Stat撚留名 完全唔知point estimation同hypothesis testing 做乜鳩<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"859d0e27461cff200e1d6c2d1ed4e09069d2cabf","tid":489619,"uid":136924,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:01:39.000Z","msg":"Stat撚留名 完全唔知point estimation同hypothesis testing 做乜鳩<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"9e86fecbeb7eb1b4dcdab784a4355abfe47af9a3","tid":489619,"uid":136924,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:01:39.000Z","msg":"Stat撚留名 完全唔知point estimation同hypothesis testing 做乜鳩<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"a5df2d1560823b6ed687a895f44b99069bf5c87f","tid":489619,"uid":136924,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:01:39.000Z","msg":"Stat撚留名 完全唔知point estimation同hypothesis testing 做乜鳩<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"f58da4541aabc3ad3bf058e1acdffa8f81a593a7","tid":489619,"uid":136924,"like":0,"dislike":3,"score":-3,"citedBy":0,"replyTime":"2017-12-06T10:01:39.000Z","msg":"Stat撚留名 完全唔知point estimation同hypothesis testing 做乜鳩<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"3a2fe7976c9f286d74ba6f3e084b6da321979707","tid":489619,"uid":136924,"like":0,"dislike":1,"score":-1,"citedBy":0,"replyTime":"2017-12-06T10:02:30.000Z","msg":"屌㩒多咗<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /> 勿屌<img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" />"},{"pid":"a5ca663726056fa485b53e53aca826a29068a640","tid":489619,"uid":60333,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:04:40.000Z","msg":"<blockquote><blockquote><blockquote><blockquote>樓主果個F-TEST係咪the f-test<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> ，唔太明果個，過兩日econometrics final要考<br />\n講緊啲variables contribution to y果個test<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /></blockquote><br />\n唔太識econometrics<img src=\"/assets/faces/lomoji/37.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/37.png\" class=\"hkgmoji\" /> , 但variables contribution to y 係咪講regression.我地的確可以用f test ( or partial f test ) 睇下邊的x對predict y 有幫助</blockquote><br />\n係呀，果隻F TEST都係根據regression analysis個結果計<img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" /> <br />\n上堂個prof話f test有兩隻解法<br />\n一隻就係計coef contribution<br />\n一隻就話all coef =0 &lt;唔係好明呢個</blockquote><br />\n一個係partial f test, only test one beta is zero<br />\n例如H0：beta 1 is zero<br />\nH1: beta 1 is not zero<br />\n<br />\n你唔明嗰個係test all beta are zero<br />\n即係H0：all betas are zero<br />\nH1: at least one of the beta above is not zero</blockquote><br />\n唔該晒<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"faee98715410c620eb9e6a5af6410eeca3f58584","tid":489619,"uid":60333,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:06:08.000Z","msg":"考果陣都係得幾樣野要記式<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n上堂用stata計<br />\n真心好用，不過好撚貴<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"06d4cebc325b3948a2d4b5fb073deb622f9690ad","tid":489619,"uid":41690,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:06:47.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote>[quote][quote]Phys撚路過<br />\n想問樓主幾時sd用除n 幾時用除n-1<br />\n見親都好似用n-1<br />\n學Statistical thermodynamics 個陣就用n?</blockquote><br />\n好似係當sampling size細(m1學過sample size&lt;30)時要estimate population variance先用n-1?</blockquote><br />\n<br />\n我記得是population 用n, sample 用n-1</blockquote><br />\n當sample size夠大應該可以直接當population直接用n?</blockquote><br />\nsample size夠大個陣，除n定n-1都無咩分別</blockquote><br />\n<br />\n<br />\nSample size 要幾大先除返n?"},{"pid":"0858f9231c0641a555ded2698a72f4c3fbd9107b","tid":489619,"uid":13090,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:07:03.000Z","msg":"半桶水stat人留名支持<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"75e405a2ea11a47b1abe8f23cee7438a7f4495ca","tid":489619,"uid":69125,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:08:51.000Z","msg":"樓主幾時再出文?想學hypothesis testing同regression<img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" />"},{"pid":"b78147303ca528e8f80ed060df8755a49273f1e0","tid":489619,"uid":21503,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:09:43.000Z","msg":"留名<img src=\"/assets/faces/normal/love.gif\" class=\"hkgmoji\" /> <br />\n星期六考stat<br />\n比chi square,t,f distribution 搞到頭都大埋<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" />"},{"pid":"3e0f7f31a1459b27926cf3c3969b78795a4677a3","tid":489619,"uid":123497,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:14:24.000Z","msg":"有無人用R?"},{"pid":"8a4faa1b8126cd56784e808eb4706bac46eeed4f","tid":489619,"uid":121366,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:20:13.000Z","msg":"<blockquote><blockquote>巴打可否解釋ANOVA 數學原理<img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" /> <br />\n下兩個星期要present <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\nAssume one -way anova．<br />\nintuitively,我地想test 有冇treatment difference between groups<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/06/071401_1865651b2a0b8d37f916dcd916a96c3b.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F06%2F071401_1865651b2a0b8d37f916dcd916a96c3b.png&h=369274f4&s={SIZE}\" /><br />\n就係睇下Sum of squared (within group) compare to sum of squared (between group) 會唔會好細．<br />\n當然有assumptions:<br />\n1. Normality<br />\n2. Independence between observations<br />\n3. Homoscedasticity (same variance)<br />\n大概outline係<br />\n1.Prove TSS (total sum of square) = SSW + SSB<br />\n2.Prove SSW/variance follows Chi-sqaure (n-r) (n is total observations, r is no. of groups) (Since each group square difference follows chi (%-1), % is no. observations of that group)<br />\n3.Under H0, TSS follows Chi-square (n-1)<br />\n4.因為Chi(r) + Chi(n) = Chi(n+r) (independent) 所以 SSB follows Chi (r-1)<br />\n5. F=(Chi/d.f)/(chi/d.f)=(SSB/(r-1))/(SSW/(n-r))=MSB/MSW<br />\n加上識睇呢個(我係excel整,very simple)<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /> <br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/06/074300_a02a1014f554bab0f0db5a5c268578bb.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F06%2F074300_a02a1014f554bab0f0db5a5c268578bb.png&h=5053179d&s={SIZE}\" /><br />\n唔明再寫詳細的</blockquote><br />\n多謝巴打<img src=\"/assets/faces/lomoji/09.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/09.png\" class=\"hkgmoji\" /> <br />\n個我數學太渣 都係有d唔明<br />\n有得詳細d實好<img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" /> <br />\n我本身stat唔熟 但有個course要present <img src=\"/assets/faces/fs/want_die.gif\" class=\"hkgmoji\" />"},{"pid":"4513ca2eb53f0d458ea4c0489d1863299b2969be","tid":489619,"uid":62379,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:36:05.000Z","msg":"就快test 呢個post正"},{"pid":"1e7cd5262cf7f2e7e0aaf360cace072d28172eef","tid":489619,"uid":100760,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T10:51:54.000Z","msg":"<blockquote>有無人用R?</blockquote><br />\n有用嚟玩下time series<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"29307b97f75062951f430e553f018af32cbe1ede","tid":489619,"uid":138267,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T11:00:36.000Z","msg":"<img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" />"},{"pid":"67bc6d286b9aa4254f732e2a70de3a0ef0a10593","tid":489619,"uid":20693,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T11:05:08.000Z","msg":"<blockquote><blockquote>有無人用R?</blockquote><br />\n有用嚟玩下time series<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n用R做data exploration同univartiate/multivariate test<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" />"},{"pid":"7df0e0f0ff1d155e8f9d7a61bc91e98fa40576e3","tid":489619,"uid":1788,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T11:19:26.000Z","msg":"讀econo course留名"},{"pid":"c941ca9b5549080f6c4a1c7444dda1f0b4fd1f45","tid":489619,"uid":21761,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T12:08:29.000Z","msg":"<img src=\"https://i.imgur.com/6om9jMl.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fi.imgur.com%2F6om9jMl.png&h=168b3a9d&s={SIZE}\" /><br />\n有冇stat高手可以解答呢張圖up緊乜鳩<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <br />\nimplication大約係指出收入決定邊個level既教育 但唔明d數字點睇"},{"pid":"cead281e7b092dd293830cee60cbeac56b3ca156","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T12:31:59.000Z","msg":"sorry呀<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n今日番左學校考試，遲左出post。番屋企打埋Chapter2。聽日全日得閒，應該可以出多的。"},{"pid":"fb037edd56540ddf682c6d99b81408955644e91d","tid":489619,"uid":114159,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T13:13:22.000Z","msg":"想minor stat留名<img src=\"/assets/faces/normal/tongue.gif\" class=\"hkgmoji\" />"},{"pid":"012aefcfbaedd8249c037ba5f4694fd7b9ca9c9c","tid":489619,"uid":161501,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-06T13:37:30.000Z","msg":"2.\tData Description<br />\n通常我地研究data,都想睇兩樣野&mdash;central tendency, dispersion<img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" /> <br />\n<br />\nCentral Tendency<br />\n究竟以下2 set data 邊個睇落中間位置大的<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> <br />\nData A = {45, 48, 50 ,54, 59}<br />\nData B = {44, 53, 56, 60, 70}<br />\n應該覺得Data B掛，但我地點用一個數字去形容？<br />\n中學應該學過 Mean Mode Median，呢的都可以拎黎形容central tendency。每一個都有優缺點。<br />\nE.g mean 容易被極端值干擾&hellip;&hellip;<br />\n當然仲有其他，e.g midrange= (Max &ndash; Min)/2<br />\n但唔常用<br />\n<br />\nDispersion<br />\n睇番 Data A and Data B邊個睇落分散的?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> <br />\n應該都係Data B掛，但相同問題，點用一個數字去形容？<br />\n中學應該學過interquartile range，呢個係其中一個方法，但只係考慮兩個數字，唔夠全面。<br />\n另一個諗法係將每粒data同mean比較，如果差距大既話，證明分散程度。<br />\nThat&rsquo;s why we have variance. Formula應該中學學過，2次係因為避免負數。<br />\nStandard derivation 係square root of variance。主要因為想同堆data有相同單位<br />\n<br />\n至於好多人concern 除n定n-1. Population variance 係除n，這是定義。但點解sample variance 除n-1。<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <br />\n記住，我地永遠想知既都係population property (parameter)，sample 只係用來估計。我地希望用sample variance 來 estimate population variance。Turn out 發現除n-1既話，有一個特性唔錯，就係unbiasedness。<img src=\"/assets/faces/lomoji/35.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/35.png\" class=\"hkgmoji\" /> <br />\n意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n(Note:當然視方法不同，estimated variance 可以不同。E.g:某些distribution 你用MLE既方法estimate，variance就會除n，好似normal)<br />\n<br />\n下次講association(Pearson's index of correlation coefficient)"},{"pid":"e0a4c5d1d84d7076a1e30519b0be4e3afcdef434","tid":489619,"uid":838,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T14:00:51.000Z","msg":"「意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。」<br />\n<br />\n個因果關係好薄弱<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"1b52bfa74a9e1e16cecf428d0cd3a027974a8c28","tid":489619,"uid":26389,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T14:03:03.000Z","msg":"下個SEM 想一次過讀<br />\nstat inference (introductory course)<br />\nstatistical computing<br />\nstatistical quality control 點睇<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"345f22d384504e24b0528bbef2ad6472dc0a11fe","tid":489619,"uid":20693,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T14:03:14.000Z","msg":"意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" />"},{"pid":"cb769782c820c0fe9beca2264eda81f16b256cfb","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T14:12:17.000Z","msg":"<blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1."},{"pid":"60e3b8c4ba6118212c08768d5a6e96531d6a5062","tid":489619,"uid":64889,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T14:17:05.000Z","msg":"lm"},{"pid":"62d204f72f8e1b5555898c73d11d5622d9a54ce3","tid":489619,"uid":132859,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T14:18:28.000Z","msg":"<blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n用左n-1之後變左unbiased estimator(difference in expected values = 0),跟著越多sample入落去就越準"},{"pid":"637d90a65233012b56226e2db6931b6c9175ad97","tid":489619,"uid":82267,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T14:21:36.000Z","msg":"數撚但搞唔掂stat<img src=\"/assets/faces/fs/bye.gif\" class=\"hkgmoji\" />"},{"pid":"e8c5211de932f42b42c1ebf42c54a413bef6f5e7","tid":489619,"uid":156394,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T14:24:06.000Z","msg":"我岩岩都讀完呢科，完全唔明點解Aviation都要讀<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" />"},{"pid":"24929c4816d6c50878d6cd011f4175dfbc033822","tid":489619,"uid":20693,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T14:24:36.000Z","msg":"<blockquote><blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1.</blockquote><br />\n關唔關無讀stat事<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n唔明點解n-1有unbiased estimator呢項特點，同埋唔知咩叫unbiased estimator<br />\n我明點解越多sample就越接近population variance"},{"pid":"21b2dce4e5044230e48872d230d83f8d9a2c0fc6","tid":489619,"uid":132859,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T14:37:40.000Z","msg":"<blockquote><blockquote><blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1.</blockquote><br />\n關唔關無讀stat事<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n唔明點解n-1有unbiased estimator呢項特點，同埋唔知咩叫unbiased estimator<br />\n我明點解越多sample就越接近population variance</blockquote><br />\n用一個df去將個sample mean = population mean"},{"pid":"b39e3354b1185aaad3ef5dc6c2ab94df03dcd862","tid":489619,"uid":69125,"like":3,"dislike":0,"score":3,"citedBy":0,"replyTime":"2017-12-06T14:46:00.000Z","msg":"<blockquote><blockquote><blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1.</blockquote><br />\n關唔關無讀stat事<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n唔明點解n-1有unbiased estimator呢項特點，同埋唔知咩叫unbiased estimator<br />\n我明點解越多sample就越接近population variance</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=D1hgiAla3KI\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD1hgiAla3KI&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=7b2970cc\" target=\"_blank\">https://www.youtube.com/watch?v=D1hgiAla3KI</a><br />\n睇完明晒"},{"pid":"df1560fc08660b053a7c044c1d9ff3b788b7ee25","tid":489619,"uid":16670,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T15:08:00.000Z","msg":"我過兩日都考stat<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" />"},{"pid":"45413c1d2c4398b1ea8870393157f597a2a58b6d","tid":489619,"uid":39734,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T15:08:42.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>ratio interval唔係好明,點解temp (celsius)係interval?0度點解冇意義?</blockquote><br />\n因為攝氏有-1度<br />\n所以0度冇咩意思 (interval)<br />\n<br />\n但絕對溫度冇-1度<br />\n所以好有意思 (ratio)</blockquote><br />\n<br />\n用溫度有少少難解釋<br />\n因為唔係個個識Kelvin scale<br />\n長度係ratio就易明好多<br />\n你諗吓會唔會有人條丁負長度<img src=\"/assets/faces/normal/hehe.gif\" class=\"hkgmoji\" /></blockquote><br />\n溫度冇問題呀,我識degree k,但係某d長度就算冇負長度都唔會令0cm突然好有意義bor<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /> 定係你想講條丁0cm代表佢係女人,長過0cm就男人,所以有意義?</blockquote><br />\n<br />\n<span style=\"color: red;\">攝氏30度熱過攝氏20度50%係冇意思</span><br />\n<span style=\"color: red;\">30cm長過20cm 50%係有意思</span> 所以先叫ratio</blockquote><br />\n紅字好難明<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /></blockquote><br />\n睇完紅字明左<br />\n有讀stat course 但冇學過呢4樣野"},{"pid":"7334ece3d6d0760344f1911b9cc3228850284605","tid":489619,"uid":16670,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T15:12:25.000Z","msg":"<blockquote>我過兩日都考stat<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /></blockquote><br />\n求加速<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"7308cc2514fada668922799b9d88f34d8e392abf","tid":489619,"uid":154700,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-06T15:14:36.000Z","msg":"Risk man freshman 留名"},{"pid":"f8c7965c2e6dbb332be47336f8b4e6f7ed359fcf","tid":489619,"uid":161462,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T15:15:30.000Z","msg":"AMA1501<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" />"},{"pid":"381f9bf2796936477a837cfb0d90ad1b4b45e71d","tid":489619,"uid":161462,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T15:16:06.000Z","msg":"過兩日就考 屌 鳩背pp 算<br />\nHypothesis testing 同linear regression唔知做乜鳩"},{"pid":"139c71473ccc171ba17b30d9732b3bec2bbdd80e","tid":489619,"uid":161462,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T15:17:39.000Z","msg":"樓主可唔可以第5開始偷跑到第14<br />\n呀 上足堂都聽唔撚明佢做乜鳩<br />\n利申：yr1 jj"},{"pid":"29a6d1e6491d527b60c36733860652c1d991cd76","tid":489619,"uid":9253,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T15:19:02.000Z","msg":"<blockquote>過兩日就考 屌 鳩背pp 算<br />\nHypothesis testing 同linear regression唔知做乜鳩</blockquote><br />\n呢2樣鳩背就算 我下星期都要考<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"612094aecb172f0de0169bc3dd7c3a3392658e91","tid":489619,"uid":161462,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T15:23:33.000Z","msg":"<blockquote><blockquote>過兩日就考 屌 鳩背pp 算<br />\nHypothesis testing 同linear regression唔知做乜鳩</blockquote><br />\n呢2樣鳩背就算 我下星期都要考<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n變少少就唔能識 屌佢老味我究竟學左乜能野<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" />"},{"pid":"a9b33998a88d6ae89dfdbc27c4842112ecfea454","tid":489619,"uid":49004,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T16:05:42.000Z","msg":"<blockquote><blockquote><blockquote><blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1.</blockquote><br />\n關唔關無讀stat事<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n唔明點解n-1有unbiased estimator呢項特點，同埋唔知咩叫unbiased estimator<br />\n我明點解越多sample就越接近population variance</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=D1hgiAla3KI\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD1hgiAla3KI&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=7b2970cc\" target=\"_blank\">https://www.youtube.com/watch?v=D1hgiAla3KI</a><br />\n睇完明晒</blockquote><br />\n未睇片<img src=\"/assets/faces/normal/biggrin.gif\" class=\"hkgmoji\" /> <br />\n<br />\n想問sample &sigma;  同population &sigma; 關係<br />\nsample &sigma; =  population &sigma; / sqrt (total no.)<br />\n<br />\n定係<br />\nsample &sigma; * (total no. -1) = population &sigma; * (total no.)"},{"pid":"2fc6b4a2936b6185734b35f609a53087339e644b","tid":489619,"uid":69125,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-06T16:23:05.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1.</blockquote><br />\n關唔關無讀stat事<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n唔明點解n-1有unbiased estimator呢項特點，同埋唔知咩叫unbiased estimator<br />\n我明點解越多sample就越接近population variance</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=D1hgiAla3KI\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD1hgiAla3KI&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=7b2970cc\" target=\"_blank\">https://www.youtube.com/watch?v=D1hgiAla3KI</a><br />\n睇完明晒</blockquote><br />\n未睇片<img src=\"/assets/faces/normal/biggrin.gif\" class=\"hkgmoji\" /> <br />\n<br />\n想問sample &sigma;  同population &sigma; 關係<br />\nsample &sigma; =  population &sigma; / sqrt (total no.)<br />\n<br />\n定係<br />\nsample &sigma; * (total no. -1) = population &sigma; * (total no.)</blockquote><br />\n上面係sd of sample mean,下面係sample sd"},{"pid":"4cd2f41c4f183fef94ec7bae756dcc3e4eaeab75","tid":489619,"uid":69125,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-06T16:23:59.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1.</blockquote><br />\n關唔關無讀stat事<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n唔明點解n-1有unbiased estimator呢項特點，同埋唔知咩叫unbiased estimator<br />\n我明點解越多sample就越接近population variance</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=D1hgiAla3KI\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD1hgiAla3KI&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=7b2970cc\" target=\"_blank\">https://www.youtube.com/watch?v=D1hgiAla3KI</a><br />\n睇完明晒</blockquote><br />\n未睇片<img src=\"/assets/faces/normal/biggrin.gif\" class=\"hkgmoji\" /> <br />\n<br />\n想問sample &sigma;  同population &sigma; 關係<br />\nsample &sigma; =  population &sigma; / sqrt (total no.)<br />\n<br />\n定係<br />\nsample &sigma; * (total no. -1) = population &sigma; * (total no.)</blockquote><br />\n上面係sd of sample mean,下面係sample sd</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=7mYDHbrLEQo\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D7mYDHbrLEQo&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=b67417f7\" target=\"_blank\">https://www.youtube.com/watch?v=7mYDHbrLEQo</a>"},{"pid":"894046a991f58a2b1ae359ab97a8e1870cdc7410","tid":489619,"uid":136022,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T16:24:40.000Z","msg":"lm<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"af9114d5cf7ba584add8b452e67201334f3fa5be","tid":489619,"uid":57359,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T16:37:11.000Z","msg":"想請問究竟咩係confidence interval？有無啲通俗易明ge解法？<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <br />\n利申：行外人但睇research成日見到，唔太明個實際意義"},{"pid":"334826b3f73892b1bbca8d945798375fb4776be6","tid":489619,"uid":39734,"like":0,"dislike":1,"score":-1,"citedBy":0,"replyTime":"2017-12-06T16:45:15.000Z","msg":"<blockquote>想請問究竟咩係confidence interval？有無啲通俗易明ge解法？<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <br />\n利申：行外人但睇research成日見到，唔太明個實際意義</blockquote><br />\n字面解囉<br />\n你對呢句conclusion 有90/95/98/99% 信心佢係岩既<br />\n但都會有1%佢會出錯 咁囉"},{"pid":"7f3ea90065c1900f4cdb50bd39bdb55dfcc8b1d9","tid":489619,"uid":49004,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T16:46:51.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1.</blockquote><br />\n關唔關無讀stat事<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n唔明點解n-1有unbiased estimator呢項特點，同埋唔知咩叫unbiased estimator<br />\n我明點解越多sample就越接近population variance</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=D1hgiAla3KI\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD1hgiAla3KI&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=7b2970cc\" target=\"_blank\">https://www.youtube.com/watch?v=D1hgiAla3KI</a><br />\n睇完明晒</blockquote><br />\n未睇片<img src=\"/assets/faces/normal/biggrin.gif\" class=\"hkgmoji\" /> <br />\n<br />\n想問sample &sigma;  同population &sigma; 關係<br />\nsample &sigma; =  population &sigma; / sqrt (total no.)<br />\n<br />\n定係<br />\nsample &sigma; * (total no. -1) = population &sigma; * (total no.)</blockquote><br />\n上面係sd of sample mean,下面係sample sd</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=7mYDHbrLEQo\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D7mYDHbrLEQo&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=b67417f7\" target=\"_blank\">https://www.youtube.com/watch?v=7mYDHbrLEQo</a></blockquote><br />\n因為見到定義 sample 係除n-1, 但population係除n<br />\n<img src=\"https://i.imag.cx/TPU1x.jpg\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fi.imag.cx%2FTPU1x.jpg&h=ea147681&s={SIZE}\" /><br />\n<br />\n但係計數Normal distribution<br />\nX ~ N(mean, &sigma;^2)<br />\n但變成sample時<br />\n就要寫成 X ~ N(mean, (&sigma; / &radic;n)^2)"},{"pid":"5673369613db68f1fa7c213a6bf045e4e7547b34","tid":489619,"uid":43770,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T16:48:18.000Z","msg":"Random Variable <br />\nPair RV <br />\n會唔會可以講下<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" />"},{"pid":"79292999f7b3f004d8e038da0e9264a8469f96b2","tid":489619,"uid":135445,"like":0,"dislike":1,"score":-1,"citedBy":0,"replyTime":"2017-12-06T16:49:38.000Z","msg":"lm<img src=\"/assets/faces/normal/bomb.gif\" class=\"hkgmoji\" /> <br />\nstat真係好好玩"},{"pid":"7221e48199638ce7624277a073eef280c338aade","tid":489619,"uid":50216,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T16:50:00.000Z","msg":"lm"},{"pid":"9ea476286a6fbbf40a166ee184865cd724e688e8","tid":489619,"uid":132859,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T16:50:36.000Z","msg":"<blockquote>想請問究竟咩係confidence interval？有無啲通俗易明ge解法？<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <br />\n利申：行外人但睇research成日見到，唔太明個實際意義</blockquote><br />\n有幾%confident想揾既 true value係嗰interval入面"},{"pid":"4bc390e541c20a5da5c0a315e2822b9c29d3cec9","tid":489619,"uid":49004,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T16:51:30.000Z","msg":"<blockquote><blockquote>想請問究竟咩係confidence interval？有無啲通俗易明ge解法？<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <br />\n利申：行外人但睇research成日見到，唔太明個實際意義</blockquote><br />\n字面解囉<br />\n你對呢句conclusion 有90/95/98/99% 信心佢係岩既<br />\n但都會有1%佢會出錯 咁囉</blockquote><br />\n<img src=\"https://i.imag.cx/TPdTV.jpg\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fi.imag.cx%2FTPdTV.jpg&h=972d2b08&s={SIZE}\" /><br />\n距離標準(mean)幾多<br />\n如果90%confidence level<br />\n就係可接受個data距離個mean有上下45%誤差內"},{"pid":"0c3c2f36bc625c6f0f014854a1d79cd554d605b1","tid":489619,"uid":47659,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T16:54:45.000Z","msg":"會唔會講到multivariate同heteroskedasticity?"},{"pid":"8bd5cedac1b6dc1183990c810143acc2ef5bae2b","tid":489619,"uid":21345,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T16:57:20.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1.</blockquote><br />\n關唔關無讀stat事<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n唔明點解n-1有unbiased estimator呢項特點，同埋唔知咩叫unbiased estimator<br />\n我明點解越多sample就越接近population variance</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=D1hgiAla3KI\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD1hgiAla3KI&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=7b2970cc\" target=\"_blank\">https://www.youtube.com/watch?v=D1hgiAla3KI</a><br />\n睇完明晒</blockquote><br />\n未睇片<img src=\"/assets/faces/normal/biggrin.gif\" class=\"hkgmoji\" /> <br />\n<br />\n想問sample &sigma;  同population &sigma; 關係<br />\nsample &sigma; =  population &sigma; / sqrt (total no.)<br />\n<br />\n定係<br />\nsample &sigma; * (total no. -1) = population &sigma; * (total no.)</blockquote><br />\n上面係sd of sample mean,下面係sample sd</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=7mYDHbrLEQo\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D7mYDHbrLEQo&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=b67417f7\" target=\"_blank\">https://www.youtube.com/watch?v=7mYDHbrLEQo</a></blockquote><br />\n因為見到定義 sample 係除n-1, 但population係除n<br />\n<img src=\"https://i.imag.cx/TPU1x.jpg\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fi.imag.cx%2FTPU1x.jpg&h=ea147681&s={SIZE}\" /><br />\n<br />\n但係計數Normal distribution<br />\nX ~ N(mean, &sigma;^2)<br />\n但變成sample時<br />\n就要寫成 X ~ N(mean, (&sigma; / &radic;n)^2)</blockquote><br />\nRandom variable 變咗x bar 再standardise"},{"pid":"93728e1a80db21243f1ec7e865880c0aefb29270","tid":489619,"uid":40207,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:00:13.000Z","msg":"<img src=\"/assets/faces/normal/shocking.gif\" class=\"hkgmoji\" />"},{"pid":"e2ee2d0600eb7de4b98a89bb2d469919e97712e9","tid":489619,"uid":161462,"like":4,"dislike":1,"score":3,"citedBy":0,"replyTime":"2017-12-06T17:09:15.000Z","msg":"Stat真係好撚濕鳩呀屌你"},{"pid":"fd79b935ed2a768434c59a66871f65c97ab2d043","tid":489619,"uid":69779,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-06T17:14:07.000Z","msg":"<blockquote>想請問究竟咩係confidence interval？有無啲通俗易明ge解法？<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <br />\n利申：行外人但睇research成日見到，唔太明個實際意義</blockquote><br />\n你有冇玩過下面有塊板，要將個波反彈上去打爛啲磚個隻game？<br />\n<br />\n當你個confidence interval係塊板 你個波係個underlying parameter<br />\n<br />\n如果你塊板有(1-alpha)*100%嘅probability去捉到個波，咁就係(1-alpha)*100% confidence interval<br />\n<br />\nbtw呢度要小心，唔可以話個波有(1-alpha)*100% probability會的跌落塊板，因為個波跌去邊個電腦已經計咗，你控制嘅係塊板"},{"pid":"5693f8e9ee9bec747b42ff4ac642d3bcc5924c16","tid":489619,"uid":49228,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:15:35.000Z","msg":"<blockquote><blockquote><blockquote>過兩日就考 屌 鳩背pp 算<br />\nHypothesis testing 同linear regression唔知做乜鳩</blockquote><br />\n呢2樣鳩背就算 我下星期都要考<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n變少少就唔能識 屌佢老味我究竟學左乜能野<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n一樣完全唔識<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" />"},{"pid":"11f048d5ee0f05dffd6a56f6e5bfd62f2e857bc5","tid":489619,"uid":143023,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:15:51.000Z","msg":"咩係 standard error 同population 有咩關係"},{"pid":"98bfb0323395e33dc976a517c9be8a8510368bba","tid":489619,"uid":161462,"like":3,"dislike":4,"score":-1,"citedBy":0,"replyTime":"2017-12-06T17:16:55.000Z","msg":"鍾意stat 再讀上去個啲全部都係<br />\n裏裏外外 不折不扣既死濕鳩！！！！<br />\n品味差 低劣 <br />\n數學範疇內最低等 次要既存在<br />\n下流賤格卑鄙無恥！！！<br />\nStat全撚部topic都係食屎狗！！！<br />\n屌鳩哂同stat有關既野既老母！！！<br />\n屌撚爆哂你地個閪呀！！！！！"},{"pid":"d1e6c4d682493bade9340222c1e919cc37c84b4c","tid":489619,"uid":132859,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:19:02.000Z","msg":"<blockquote>鍾意stat 再讀上去個啲全部都係<br />\n裏裏外外 不折不扣既死濕鳩！！！！<br />\n品味差 低劣 <br />\n數學範疇內最低等 次要既存在<br />\n下流賤格卑鄙無恥！！！<br />\nStat全撚部topic都係食屎狗！！！<br />\n屌鳩哂同stat有關既野既老母！！！<br />\n屌撚爆哂你地個閪呀！！！！！</blockquote><br />\n你fail左course?"},{"pid":"1918b469c40a8035c5210121969538a38e581422","tid":489619,"uid":248,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-06T17:20:35.000Z","msg":"stat真係諗得明個陣就好玩<img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" />"},{"pid":"376f8daf1415ecbe2fce8ce0561136f304c1f891","tid":489619,"uid":161462,"like":3,"dislike":0,"score":3,"citedBy":0,"replyTime":"2017-12-06T17:21:09.000Z","msg":"<blockquote><blockquote>鍾意stat 再讀上去個啲全部都係<br />\n裏裏外外 不折不扣既死濕鳩！！！！<br />\n品味差 低劣 <br />\n數學範疇內最低等 次要既存在<br />\n下流賤格卑鄙無恥！！！<br />\nStat全撚部topic都係食屎狗！！！<br />\n屌鳩哂同stat有關既野既老母！！！<br />\n屌撚爆哂你地個閪呀！！！！！</blockquote><br />\n你fail左course?</blockquote><br />\n<img src=\"/assets/faces/normal/tongue.gif\" class=\"hkgmoji\" />"},{"pid":"d5081067cb414a6aee5aba2b25cb6ac328ad6343","tid":489619,"uid":4382,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:24:17.000Z","msg":"留名<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <br />\n就快exam 我stat屎到爆<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"e924579e94f9e095b97427b1d4d8ced3d36c50c1","tid":489619,"uid":139164,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:25:15.000Z","msg":"lm學o野"},{"pid":"97b7cccf18e77722665ded53f5f441e92bd46a86","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:25:53.000Z","msg":"<img src=\"https://img.eservice-hk.net/upload/2017/12/07/012340_d0b3244693f743a542dc6a84b8f5ae22.jpg\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F012340_d0b3244693f743a542dc6a84b8f5ae22.jpg&h=e63673d1&s={SIZE}\" /><br />\n<br />\nug stat畢業後master再讀同stat有關的科目係正宗癡線<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" />"},{"pid":"35994a30e089f3b3d469d57ed463befc785914ca","tid":489619,"uid":161462,"like":4,"dislike":0,"score":4,"citedBy":0,"replyTime":"2017-12-06T17:25:54.000Z","msg":"<blockquote>stat真係諗得明個陣就好玩<img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /></blockquote><br />\n拎個normal distribution <br />\n拎住你支牙籤仔對準佢中間個位當閪咁屌啦<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" />"},{"pid":"33f08f8ff13b20d02f9d7adbc4e984f282f4475f","tid":489619,"uid":161462,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-06T17:26:27.000Z","msg":"咁就好能好玩啦 屌你<img src=\"/assets/faces/normal/kill.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/kill.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/kill.gif\" class=\"hkgmoji\" />"},{"pid":"84aa4483483465fe4011bbd086d34092029f5bc2","tid":489619,"uid":70832,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:28:16.000Z","msg":"哇，乜黎<br />\n有冇中文"},{"pid":"f2a765f527d721bd11cc7c1f8b71d5ab84eb2d7b","tid":489619,"uid":82126,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:28:32.000Z","msg":"咩係least square method<img src=\"/assets/faces/normal/wonder.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/wonder.gif\" class=\"hkgmoji\" /> 啱啱呢個sem考完introductory statistics <img src=\"/assets/faces/normal/flowerface.gif\" class=\"hkgmoji\" /> 樓主繼續分享<img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" />"},{"pid":"f8ce22a3c58b3b9534fc0a15c577749dd6493e00","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:29:09.000Z","msg":"<blockquote><blockquote>stat真係諗得明個陣就好玩<img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /></blockquote><br />\n拎個normal distribution <br />\n拎住你支牙籤仔對準佢中間個位當閪咁屌啦<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /></blockquote><br />\n可惜港女的kurtosis 分分鐘係negative"},{"pid":"a7c06b81a79e7f1e60e3bf5135e8ec5e8ffc6811","tid":489619,"uid":49228,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:29:55.000Z","msg":"快啲出文<img src=\"/assets/faces/normal/kill.gif\" class=\"hkgmoji\" />"},{"pid":"d858d841217f6c2bfe0b9883b75f39438e0df45c","tid":489619,"uid":161462,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:30:41.000Z","msg":"<blockquote><blockquote><blockquote>stat真係諗得明個陣就好玩<img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /></blockquote><br />\n拎個normal distribution <br />\n拎住你支牙籤仔對準佢中間個位當閪咁屌啦<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /></blockquote><br />\n可惜港女的kurtosis 分分鐘係negative</blockquote><br />\n拎黎裝牙籤就岩哂"},{"pid":"d90e69388602022e6bdd2f954040394e4f45bde9","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:31:23.000Z","msg":"<blockquote>咩係least square method<img src=\"/assets/faces/normal/wonder.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/wonder.gif\" class=\"hkgmoji\" /> 啱啱呢個sem考完introductory statistics <img src=\"/assets/faces/normal/flowerface.gif\" class=\"hkgmoji\" /> 樓主繼續分享<img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /></blockquote><br />\n係未講緊regression?<br />\nleast square method係指用黎搵一條線，從而令所有的點同呢條線的距離再加埋一齊係最細"},{"pid":"38587c9b8866da55e11ce1d67d156ad3583eda2b","tid":489619,"uid":60261,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:33:55.000Z","msg":"yr1 stat 留名<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"9777bb2c311aaf66db92d416ce4fe34915fbd1c5","tid":489619,"uid":43414,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:35:23.000Z","msg":"Lm<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" />"},{"pid":"a5a25bed427ec42e45566d5375e1bab6312aa592","tid":489619,"uid":34522,"like":2,"dislike":0,"score":2,"citedBy":0,"replyTime":"2017-12-06T17:37:11.000Z","msg":"<blockquote><blockquote><blockquote><blockquote>過兩日就考 屌 鳩背pp 算<br />\nHypothesis testing 同linear regression唔知做乜鳩</blockquote><br />\n呢2樣鳩背就算 我下星期都要考<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n變少少就唔能識 屌佢老味我究竟學左乜能野<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n一樣完全唔識<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n講hypothesis點可以唔post呢張圖<br />\n<img src=\"https://pbs.twimg.com/media/B9E2XZOIAAApjeM.jpg\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FB9E2XZOIAAApjeM.jpg&h=71b9d66c&s={SIZE}\" /><br />\nhypothesis係講如果你假設左一樣野後發生一件事的機會率係幾多，例如你假設左個港女女友係拜金後佢叫你買禮物的機會率係幾多，如果細過某一個數（alpha value）的話就會推翻你的假設（姐係佢唔係拜金）"},{"pid":"3accd52d6ef4c872fefb16a926d54070fe8bb2e3","tid":489619,"uid":128360,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:38:25.000Z","msg":"本來喺中學都叫做學晒GCE S1 S2嘅內容<br />\n過到嚟奧地利exchange揀咗科初級stat諗住充下credit<br />\n點知堂堂就教用program(咩spss)撳掣出答案<br />\n搞到我都唔知學緊咩 顛覆晒我對stat嘅概念<img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" />"},{"pid":"1468a73197c4df860eebe272235971ec123c63b2","tid":489619,"uid":154006,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:39:22.000Z","msg":"此回覆已被刪除"},{"pid":"148ab25dd4f791ececa577df8e94bb4bc3df3269","tid":489619,"uid":161462,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:40:01.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote>過兩日就考 屌 鳩背pp 算<br />\nHypothesis testing 同linear regression唔知做乜鳩</blockquote><br />\n呢2樣鳩背就算 我下星期都要考<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n變少少就唔能識 屌佢老味我究竟學左乜能野<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n一樣完全唔識<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n講hypothesis點可以唔post呢張圖<br />\n<img src=\"https://pbs.twimg.com/media/B9E2XZOIAAApjeM.jpg\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FB9E2XZOIAAApjeM.jpg&h=71b9d66c&s={SIZE}\" /><br />\nhypothesis係講如果你假設左一樣野後發生一件事的機會率係幾多，例如你假設左個港女女友係拜金後佢叫你買禮物的機會率係幾多，如果細過某一個數（alpha value）的話就會推翻你的假設（姐係佢唔係拜金）</blockquote><br />\n幅圖講個啲野同張圖發生既野唔一樣？計數個陣都要咁寫返<img src=\"/assets/faces/normal/donno.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/ass.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/oh.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/wonder.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/kiss.gif\" class=\"hkgmoji\" />"},{"pid":"a1b9618604759ed211be35ce919236109c00e20c","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:49:03.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>過兩日就考 屌 鳩背pp 算<br />\nHypothesis testing 同linear regression唔知做乜鳩</blockquote><br />\n呢2樣鳩背就算 我下星期都要考<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n變少少就唔能識 屌佢老味我究竟學左乜能野<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n一樣完全唔識<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n講hypothesis點可以唔post呢張圖<br />\n<img src=\"https://pbs.twimg.com/media/B9E2XZOIAAApjeM.jpg\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FB9E2XZOIAAApjeM.jpg&h=71b9d66c&s={SIZE}\" /><br />\nhypothesis係講如果你假設左一樣野後發生一件事的機會率係幾多，例如你假設左個港女女友係拜金後佢叫你買禮物的機會率係幾多，如果細過某一個數（alpha value）的話就會推翻你的假設（姐係佢唔係拜金）</blockquote><br />\n幅圖講個啲野同張圖發生既野唔一樣？計數個陣都要咁寫返<img src=\"/assets/faces/normal/donno.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/ass.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/oh.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/wonder.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/kiss.gif\" class=\"hkgmoji\" /></blockquote><br />\ntype 1 error其實就係上面所講的機會率<br />\n一般考試就咁計個機會率後同alpha value比較就得"},{"pid":"3af5bdb9b6ad9b79b2f4f7cb1db2cb9562052d5f","tid":489619,"uid":28052,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:50:10.000Z","msg":"讀第四年都唔係好識<img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" />"},{"pid":"8f380212321c0e068b435d54e9d09d40ecf6ef2b","tid":489619,"uid":161462,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:52:14.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>過兩日就考 屌 鳩背pp 算<br />\nHypothesis testing 同linear regression唔知做乜鳩</blockquote><br />\n呢2樣鳩背就算 我下星期都要考<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n變少少就唔能識 屌佢老味我究竟學左乜能野<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n一樣完全唔識<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n講hypothesis點可以唔post呢張圖<br />\n<img src=\"https://pbs.twimg.com/media/B9E2XZOIAAApjeM.jpg\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FB9E2XZOIAAApjeM.jpg&h=71b9d66c&s={SIZE}\" /><br />\nhypothesis係講如果你假設左一樣野後發生一件事的機會率係幾多，例如你假設左個港女女友係拜金後佢叫你買禮物的機會率係幾多，如果細過某一個數（alpha value）的話就會推翻你的假設（姐係佢唔係拜金）</blockquote><br />\n幅圖講個啲野同張圖發生既野唔一樣？計數個陣都要咁寫返<img src=\"/assets/faces/normal/donno.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/ass.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/oh.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/wonder.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/kiss.gif\" class=\"hkgmoji\" /></blockquote><br />\ntype 1 error其實就係上面所講的機會率<br />\n一般考試就咁計個機會率後同alpha value比較就得</blockquote><br />\n<img src=\"/assets/faces/normal/surprise.gif\" class=\"hkgmoji\" />"},{"pid":"2b16b6499ae6f7c6070f2b63a70c490cf4fcda88","tid":489619,"uid":137314,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:52:41.000Z","msg":"lm"},{"pid":"16345e789396060557ee5a0dafb726ca96fcebd4","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:59:08.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><br />\n呢2樣鳩背就算 我下星期都要考<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n變少少就唔能識 屌佢老味我究竟學左乜能野<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n一樣完全唔識<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n講hypothesis點可以唔post呢張圖<br />\n<img src=\"https://pbs.twimg.com/media/B9E2XZOIAAApjeM.jpg\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FB9E2XZOIAAApjeM.jpg&h=71b9d66c&s={SIZE}\" /><br />\nhypothesis係講如果你假設左一樣野後發生一件事的機會率係幾多，例如你假設左個港女女友係拜金後佢叫你買禮物的機會率係幾多，如果細過某一個數（alpha value）的話就會推翻你的假設（姐係佢唔係拜金）</blockquote><br />\n幅圖講個啲野同張圖發生既野唔一樣？計數個陣都要咁寫返<img src=\"/assets/faces/normal/donno.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/ass.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/oh.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/wonder.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/kiss.gif\" class=\"hkgmoji\" /></blockquote><br />\ntype 1 error其實就係上面所講的機會率<br />\n一般考試就咁計個機會率後同alpha value比較就得</blockquote><br />\n<img src=\"/assets/faces/normal/surprise.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/07/015839_d0b3244693f743a542dc6a84b8f5ae22.jpg\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F015839_d0b3244693f743a542dc6a84b8f5ae22.jpg&h=b8f7e24c&s={SIZE}\" />"},{"pid":"2e2354c4df87167bc22811fa306a88bdcbafeb01","tid":489619,"uid":39734,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:59:14.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>過兩日就考 屌 鳩背pp 算<br />\nHypothesis testing 同linear regression唔知做乜鳩</blockquote><br />\n呢2樣鳩背就算 我下星期都要考<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n變少少就唔能識 屌佢老味我究竟學左乜能野<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n一樣完全唔識<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n講hypothesis點可以唔post呢張圖<br />\n<img src=\"https://pbs.twimg.com/media/B9E2XZOIAAApjeM.jpg\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FB9E2XZOIAAApjeM.jpg&h=71b9d66c&s={SIZE}\" /><br />\nhypothesis係講如果你假設左一樣野後發生一件事的機會率係幾多，例如你假設左個港女女友係拜金後佢叫你買禮物的機會率係幾多，如果細過某一個數（alpha value）的話就會推翻你的假設（姐係佢唔係拜金）</blockquote><br />\n幅圖講個啲野同張圖發生既野唔一樣？計數個陣都要咁寫返<img src=\"/assets/faces/normal/donno.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/ass.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/oh.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/wonder.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/kiss.gif\" class=\"hkgmoji\" /></blockquote><br />\n1 係將錯既野當岩<br />\n2 係將岩既野當錯"},{"pid":"e292af85c54a64fb804238518fea2fcdd97debd9","tid":489619,"uid":127454,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T17:59:36.000Z","msg":"留明學嘢<img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" />"},{"pid":"006c6937c1b2363882276306544f1f1bea180da3","tid":489619,"uid":161462,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T18:04:34.000Z","msg":"聽朝再睇睇<br />\n謝謝各位<img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" />"},{"pid":"764b27631596ff2ac144836c68c919aaf25f4876","tid":489619,"uid":4998,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T18:12:58.000Z","msg":"I love stat<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <br />\n上個sem讀 a-左<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" />"},{"pid":"555e1d71a7b64bb7f1bce839686a0ad0d0aebb54","tid":489619,"uid":63078,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T18:18:19.000Z","msg":"<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" />"},{"pid":"8c1d9aac827308c0e425c5a94e1063239ee3f443","tid":489619,"uid":86756,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T18:20:28.000Z","msg":"<blockquote>留名 想學多啲hypothesis test既details<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" />"},{"pid":"0f72571343b4a775b0ffccf96ccc0ffcdb2525d9","tid":489619,"uid":92600,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T18:21:47.000Z","msg":"巴打 講得好好<br />\n想問下有冇得自學？"},{"pid":"bd9f37c93f87e0badbee953d8b7233969066d2ef","tid":489619,"uid":33943,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T18:21:55.000Z","msg":"留名學野"},{"pid":"09cdd9bc5647b6823fe319e37c1ff858d6267700","tid":489619,"uid":60333,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T18:28:28.000Z","msg":"次次見到hypothesis test就煩<br />\nreject咪reject<br />\n唔reject咪reject<br />\n整個fail to reject出黎<br />\n搞到上堂好混亂，次次都要個prof慢慢咁講幾次全部人先抄到notes<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"c96ced38736e477949be3f2857318faa5ad61be2","tid":489619,"uid":60333,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T18:28:43.000Z","msg":"<blockquote>次次見到hypothesis test就煩<br />\nreject咪reject<br />\n唔reject咪<span style=\"color: red;\">唔</span>reject<br />\n整個fail to reject出黎<br />\n搞到上堂好混亂，次次都要個prof慢慢咁講幾次全部人先抄到notes<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" />"},{"pid":"72e9cc4ab967a7453d0b542a9c634cd152a32f9d","tid":489619,"uid":5137,"like":0,"dislike":11,"score":-11,"citedBy":0,"replyTime":"2017-12-06T18:41:50.000Z","msg":"难得有strong post<br />\n我是来留明的"},{"pid":"efb81d30970249558e4f15926fae438a33931b4a","tid":489619,"uid":838,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T18:42:46.000Z","msg":"<blockquote>难得有strong post<br />\n我是来留明的</blockquote><br />\n<img src=\"/assets/faces/normal/photo.gif\" class=\"hkgmoji\" />"},{"pid":"96b012392393b553ed18095459677a1973469a30","tid":489619,"uid":135445,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T18:43:42.000Z","msg":"<blockquote>难得有strong post<br />\n我是来留明的</blockquote><br />\n殘體<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" />"},{"pid":"62397fffe59cef32c0c42da74d6145c33f05d00d","tid":489619,"uid":139716,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T18:50:00.000Z","msg":"lm"},{"pid":"0eec9bf27cb8a1eda0b7ce8159e0b8a54bee390b","tid":489619,"uid":34999,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T19:07:38.000Z","msg":"Stat 愛好者對樓主表示G持<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" />"},{"pid":"ee71cc96efe2dd9d52d62e1e410004f921aa8142","tid":489619,"uid":30771,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T19:13:47.000Z","msg":"留名學野"},{"pid":"1770f48dd55cf008f09453e9c7d0bbd27b1e04ed","tid":489619,"uid":4149,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T19:18:14.000Z","msg":"其實啲test 有咩用<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <br />\n又 t test  又 p value<img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" />"},{"pid":"426f028e778bf2ca16507b61831f1201b4ccb354","tid":489619,"uid":74214,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T19:22:16.000Z","msg":"<img src=\"/assets/faces/normal/369.gif\" class=\"hkgmoji\" />"},{"pid":"17fdeb93d485bf28f47e24f270370e4b9d4b02c6","tid":489619,"uid":136113,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T19:48:35.000Z","msg":"講多啲<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> 下星期考完全唔撚識<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> 睇唔明佢啲notes"},{"pid":"9fd270e832d37ffb312a31fd580df1eb3f9ac921","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T19:57:54.000Z","msg":"<blockquote>講多啲<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> 下星期考完全唔撚識<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> 睇唔明佢啲notes</blockquote><br />\n初學個d未又係叫你計下p value,會唔會reject,計下confidence interval,再多d未計paired t test"},{"pid":"52d7d33009c60a7bd434ed46d9484b5c1dc36ec5","tid":489619,"uid":74214,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T22:11:12.000Z","msg":"<blockquote><blockquote>講多啲<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> 下星期考完全唔撚識<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> 睇唔明佢啲notes</blockquote><br />\n初學個d未又係叫你計下p value,會唔會reject,計下confidence interval,再多d未計paired t test</blockquote><br />\n巴打介唔介意留個tg<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"1d8eb9d21e3e28d167454a3b8c6ef9f9793ef606","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-06T22:24:14.000Z","msg":"<blockquote><blockquote><blockquote>講多啲<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> 下星期考完全唔撚識<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> 睇唔明佢啲notes</blockquote><br />\n初學個d未又係叫你計下p value,會唔會reject,計下confidence interval,再多d未計paired t test</blockquote><br />\n巴打介唔介意留個tg<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"/assets/faces/normal/offtopic.gif\" class=\"hkgmoji\" />"},{"pid":"bf4495774130f6e3bf0ce6030aabec825512edf2","tid":489619,"uid":161501,"like":4,"dislike":0,"score":4,"citedBy":0,"replyTime":"2017-12-06T22:27:43.000Z","msg":"見咁多巴絲要求，我偷跑左point estimates and confidence intervals 以及hypothesis testing. 但我expect你對前面topics有基本認識<img src=\"/assets/faces/lomoji/03.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/03.png\" class=\"hkgmoji\" /> <br />\n<br />\n7. Point Estimates and Confidence Intervals (Concepts)<br />\n好多時，我地想估計population既一些特徵(e.g mean variamce&hellip;&hellip; )(parameter)。咁點估?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> 當然，拎一個sample黎估。<br />\n<br />\nPoint Estimates<br />\n假設我已經拎左個sample<br />\n{45,48,53,57,60}<br />\n我叫你估下個mean.<br />\n有人可能估: (45+48+53+57+60)/5=52.6<br />\n但亦有人估: (48+53+57)/3=52.7<br />\n甚至有人鳩估:54<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <br />\n實際上，你冇得話邊個啱，邊個錯。因為大家都係估。但somehow 都有的critiria去judge你估得好唔好。<br />\ni.)\tUnbiasedness<br />\nii.)\tConsistency<br />\niii.)\tEfficiency<br />\nUnbiasedness 就已經講左。<img src=\"/assets/faces/lomoji/11.png\" class=\"hkgmoji\" /> Mathematically, E(estimator)= parameter<br />\n就係unbiased estimator. (P.S Estimate 應該都係random variable，因為唔同sample會有唔同既estimator.)<br />\n<br />\nConsistency 就係當sample size越來越大，estimate 會越來越近parameter.<br />\n咁都正路，冇理由我個sample越大，但個estimate越唔準。<br />\n<br />\nEfficiency 就係指估計值既variance，有時會估大的，有時會估細的。如果variance好大，咁呢個差距就有機會好大。所以我去傾向拎細variance既estimate.<br />\n<br />\n(Note:以上三項不一定同時發生。)<br />\ne.g<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/07/062616_c46ca9256e156c2edfd001916a5fe22d.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F062616_c46ca9256e156c2edfd001916a5fe22d.png&h=5c6a4592&s={SIZE}\" /><br />\nRed Curve: Unbiased but less efficient<br />\nBlue Curve : Bias but more efficient<br />\n<br />\n(Note: Sample mean and variance are unbiased and consistent estimators)<br />\n<br />\n<br />\n<br />\nConfidence Intervals<br />\n<br />\nPoint Estimates就只係俾左個數字我，但係唔知有幾準。所以好多時，我地會用一個Interval去估計，增加準確率之餘，仲可以specify 個估計程度。<br />\n<br />\nConfidence Intervals就係比較大路既interval estimation.我地會定義一個confidence level (e.g 90%,95%,&hellip;)，然後construct 一個Interval，但問題就係，點樣理解？<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <br />\n<br />\n首先，記住population parameter係唔會變，is an unknown constant。個randomness，個變化擺在係intervals身上。唔同sample會有唔同既interval。一旦sample 拎左，construct左interval，所有野已經決定左。<br />\n跟住落黎得兩個結果：估中，估唔中。<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> 冇任何random, prob. 可言。所以我地只會話有幾多％既confident，而不能說有幾多prob.個interval會中.<br />\n<br />\n請看下圖:<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/07/062725_b06609fff3106e63beaab289ef58d33a.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F062725_b06609fff3106e63beaab289ef58d33a.png&h=1597861b&s={SIZE}\" /><br />\n紅色就係不同sample既Confidence Intervals。你會發現有些cover true parameter，有些冇。<br />\nE.g 95% confidence interval 就係指有95%既intervals會cover true parameter.<br />\n<br />\n至於每一種parameter，點揾Confidence Intervals後面再講。"},{"pid":"d6dfcf86b55ea4c9bfc86fce42c5cfd620d8a3b9","tid":489619,"uid":5137,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T01:41:37.000Z","msg":"<blockquote><blockquote>难得有strong post<br />\n我是来留明的</blockquote><br />\n<img src=\"/assets/faces/normal/photo.gif\" class=\"hkgmoji\" /></blockquote><br />\n我明明打繁體 做咩會咁嘅<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" />"},{"pid":"1b8c0268c113ba210838b4057dc42855ff598336","tid":489619,"uid":114447,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T01:47:19.000Z","msg":"留名學野"},{"pid":"69b72fda068f094b851542ecf1a8bdf382e793ff","tid":489619,"uid":114447,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T01:56:54.000Z","msg":"都明明地sample variance 點解要n-1<br />\n但係唔明點解time series計 sample acvf(0) 就唔洗除n-1<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <br />\n有冇高手巴絲解答下<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" />"},{"pid":"740899322082ea57270c7e89c57f2967f2f0d69d","tid":489619,"uid":20693,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T01:58:47.000Z","msg":"<blockquote><blockquote><blockquote><blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1.</blockquote><br />\n關唔關無讀stat事<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n唔明點解n-1有unbiased estimator呢項特點，同埋唔知咩叫unbiased estimator<br />\n我明點解越多sample就越接近population variance</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=D1hgiAla3KI\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD1hgiAla3KI&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=7b2970cc\" target=\"_blank\">https://www.youtube.com/watch?v=D1hgiAla3KI</a><br />\n睇完明晒</blockquote><br />\n仲係唔明<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <br />\n未讀過stat唔知咩叫unbiased estimator, 我連咩係E(X)都唔知<br />\n真係好想識啊<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" />"},{"pid":"49a77bf644e92de3457e904c9e90f7c7e9683e36","tid":489619,"uid":161501,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-07T02:28:40.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1.</blockquote><br />\n關唔關無讀stat事<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n唔明點解n-1有unbiased estimator呢項特點，同埋唔知咩叫unbiased estimator<br />\n我明點解越多sample就越接近population variance</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=D1hgiAla3KI\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD1hgiAla3KI&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=7b2970cc\" target=\"_blank\">https://www.youtube.com/watch?v=D1hgiAla3KI</a><br />\n睇完明晒</blockquote><br />\n仲係唔明<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <br />\n未讀過stat唔知咩叫unbiased estimator, 我連咩係E(X)都唔知<br />\n真係好想識啊<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /></blockquote><br />\n其實E(X) = mean 同一樣野。<img src=\"/assets/faces/lomoji/16.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/16.png\" class=\"hkgmoji\" /> <br />\n考慮以下<img src=\"https://img.eservice-hk.net/upload/2017/12/07/102255_c0319bd704c48e85c44d64d36081b43a.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F102255_c0319bd704c48e85c44d64d36081b43a.png&h=578ceb8b&s={SIZE}\" /><br />\nSample mean 個行<br />\nC2=Mean of A2<br />\nC3=Mean of A2 and A3<br />\nC4=Mean of A2, A3 and A4<br />\nso on你會發覺不斷接近一個數<br />\n如果sample size grows larger(i.e more data)<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/07/102623_22a8e0d5d1e531574553d02111e83ec3.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F102623_22a8e0d5d1e531574553d02111e83ec3.png&h=c95c405f&s={SIZE}\" /><br />\n你會發覺差唔多一樣．<br />\n呢個就係unbiased estimator。"},{"pid":"f8b10584d6fb3bf490e7cf58b8230e61fbeca34d","tid":489619,"uid":20693,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T02:31:28.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1.</blockquote><br />\n關唔關無讀stat事<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n唔明點解n-1有unbiased estimator呢項特點，同埋唔知咩叫unbiased estimator<br />\n我明點解越多sample就越接近population variance</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=D1hgiAla3KI\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD1hgiAla3KI&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=7b2970cc\" target=\"_blank\">https://www.youtube.com/watch?v=D1hgiAla3KI</a><br />\n睇完明晒</blockquote><br />\n仲係唔明<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <br />\n未讀過stat唔知咩叫unbiased estimator, 我連咩係E(X)都唔知<br />\n真係好想識啊<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /></blockquote><br />\n其實E(X) = mean 同一樣野。<img src=\"/assets/faces/lomoji/16.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/16.png\" class=\"hkgmoji\" /> <br />\n考慮以下<img src=\"https://img.eservice-hk.net/upload/2017/12/07/102255_c0319bd704c48e85c44d64d36081b43a.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F102255_c0319bd704c48e85c44d64d36081b43a.png&h=578ceb8b&s={SIZE}\" /><br />\nSample mean 個行<br />\nC2=Mean of A2<br />\nC3=Mean of A2 and A3<br />\nC4=Mean of A2, A3 and A4<br />\nso on你會發覺不斷接近一個數<br />\n如果sample size grows larger(i.e more data)<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/07/102623_22a8e0d5d1e531574553d02111e83ec3.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F102623_22a8e0d5d1e531574553d02111e83ec3.png&h=c95c405f&s={SIZE}\" /><br />\n你會發覺差唔多一樣．<br />\n呢個就係unbiased estimator。</blockquote><br />\n呢個我明<br />\n咁但係點解由呢個解釋就可以跳去總結n-1有unbiased estimator呢個特性? 個因果我唔明"},{"pid":"7bd62e6023116c2b1b3b6ab560a56d88308e4561","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T02:37:12.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1.</blockquote><br />\n關唔關無讀stat事<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n唔明點解n-1有unbiased estimator呢項特點，同埋唔知咩叫unbiased estimator<br />\n我明點解越多sample就越接近population variance</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=D1hgiAla3KI\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD1hgiAla3KI&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=7b2970cc\" target=\"_blank\">https://www.youtube.com/watch?v=D1hgiAla3KI</a><br />\n睇完明晒</blockquote><br />\n仲係唔明<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <br />\n未讀過stat唔知咩叫unbiased estimator, 我連咩係E(X)都唔知<br />\n真係好想識啊<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /></blockquote><br />\n其實E(X) = mean 同一樣野。<img src=\"/assets/faces/lomoji/16.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/16.png\" class=\"hkgmoji\" /> <br />\n考慮以下<img src=\"https://img.eservice-hk.net/upload/2017/12/07/102255_c0319bd704c48e85c44d64d36081b43a.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F102255_c0319bd704c48e85c44d64d36081b43a.png&h=578ceb8b&s={SIZE}\" /><br />\nSample mean 個行<br />\nC2=Mean of A2<br />\nC3=Mean of A2 and A3<br />\nC4=Mean of A2, A3 and A4<br />\nso on你會發覺不斷接近一個數<br />\n如果sample size grows larger(i.e more data)<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/07/102623_22a8e0d5d1e531574553d02111e83ec3.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F102623_22a8e0d5d1e531574553d02111e83ec3.png&h=c95c405f&s={SIZE}\" /><br />\n你會發覺差唔多一樣．<br />\n呢個就係unbiased estimator。</blockquote><br />\n呢個我明<br />\n咁但係點解由呢個解釋就可以跳去總結n-1有unbiased estimator呢個特性? 個因果我唔明</blockquote><br />\n呢個係Prove出黎<br />\nE(Variance of sample)=n-1/n (sigma)^2<br />\n所以先有除n-1 instead of 除n<br />\nP.s Variance of sample = 除n既Variance"},{"pid":"d6839f40bfb5fd0dd652c01a1c366172a4f2d183","tid":489619,"uid":20693,"like":0,"dislike":1,"score":-1,"citedBy":0,"replyTime":"2017-12-07T02:45:32.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1.</blockquote><br />\n關唔關無讀stat事<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n唔明點解n-1有unbiased estimator呢項特點，同埋唔知咩叫unbiased estimator<br />\n我明點解越多sample就越接近population variance</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=D1hgiAla3KI\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD1hgiAla3KI&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=7b2970cc\" target=\"_blank\">https://www.youtube.com/watch?v=D1hgiAla3KI</a><br />\n睇完明晒</blockquote><br />\n仲係唔明<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <br />\n未讀過stat唔知咩叫unbiased estimator, 我連咩係E(X)都唔知<br />\n真係好想識啊<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /></blockquote><br />\n其實E(X) = mean 同一樣野。<img src=\"/assets/faces/lomoji/16.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/16.png\" class=\"hkgmoji\" /> <br />\n考慮以下<img src=\"https://img.eservice-hk.net/upload/2017/12/07/102255_c0319bd704c48e85c44d64d36081b43a.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F102255_c0319bd704c48e85c44d64d36081b43a.png&h=578ceb8b&s={SIZE}\" /><br />\nSample mean 個行<br />\nC2=Mean of A2<br />\nC3=Mean of A2 and A3<br />\nC4=Mean of A2, A3 and A4<br />\nso on你會發覺不斷接近一個數<br />\n如果sample size grows larger(i.e more data)<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/07/102623_22a8e0d5d1e531574553d02111e83ec3.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F102623_22a8e0d5d1e531574553d02111e83ec3.png&h=c95c405f&s={SIZE}\" /><br />\n你會發覺差唔多一樣．<br />\n呢個就係unbiased estimator。</blockquote><br />\n呢個我明<br />\n咁但係點解由呢個解釋就可以跳去總結n-1有unbiased estimator呢個特性? 個因果我唔明</blockquote><br />\n呢個係Prove出黎<br />\nE(Variance of sample)=n-1/n (sigma)^2<br />\n所以先有除n-1 instead of 除n<br />\nP.s Variance of sample = 除n既Variance</blockquote><br />\n算啦唔好理我<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/22.png\" class=\"hkgmoji\" />"},{"pid":"792dd97e437f88405883af4fe4e2cd762c76f1aa","tid":489619,"uid":132859,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T03:11:33.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>意思即係，我拎多幾個sample 黎計sample variance之後take average。只要有越來越多既samples，個average就會不斷趨向population variance.　所以sample variance係除n-1。<br />\n<br />\n<br />\n唔明呢句因果<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\n可能我寫得1999.［所以］前面係unbiasedness既解釋，因為除n-1有unbiased estimator呢項特點，所以sample variance除n-1.</blockquote><br />\n關唔關無讀stat事<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n唔明點解n-1有unbiased estimator呢項特點，同埋唔知咩叫unbiased estimator<br />\n我明點解越多sample就越接近population variance</blockquote><br />\n<a href=\"https://www.youtube.com/watch?v=D1hgiAla3KI\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD1hgiAla3KI&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=7b2970cc\" target=\"_blank\">https://www.youtube.com/watch?v=D1hgiAla3KI</a><br />\n睇完明晒</blockquote><br />\n仲係唔明<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <br />\n未讀過stat唔知咩叫unbiased estimator, 我連咩係E(X)都唔知<br />\n真係好想識啊<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /></blockquote><br />\n其實E(X) = mean 同一樣野。<img src=\"/assets/faces/lomoji/16.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/16.png\" class=\"hkgmoji\" /> <br />\n考慮以下<img src=\"https://img.eservice-hk.net/upload/2017/12/07/102255_c0319bd704c48e85c44d64d36081b43a.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F102255_c0319bd704c48e85c44d64d36081b43a.png&h=578ceb8b&s={SIZE}\" /><br />\nSample mean 個行<br />\nC2=Mean of A2<br />\nC3=Mean of A2 and A3<br />\nC4=Mean of A2, A3 and A4<br />\nso on你會發覺不斷接近一個數<br />\n如果sample size grows larger(i.e more data)<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/07/102623_22a8e0d5d1e531574553d02111e83ec3.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F102623_22a8e0d5d1e531574553d02111e83ec3.png&h=c95c405f&s={SIZE}\" /><br />\n你會發覺差唔多一樣．<br />\n呢個就係unbiased estimator。</blockquote><br />\n呢個我明<br />\n咁但係點解由呢個解釋就可以跳去總結n-1有unbiased estimator呢個特性? 個因果我唔明</blockquote><br />\n因為用一個df去令sample mean = population mean(ie unbiased estimator)<br />\n之後越多sample先會越似population"},{"pid":"67fbf95560cceb58bf343e4d8d46cb3b93235bb0","tid":489619,"uid":57359,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T03:22:02.000Z","msg":"<blockquote>見咁多巴絲要求，我偷跑左point estimates and confidence intervals 以及hypothesis testing. 但我expect你對前面topics有基本認識<img src=\"/assets/faces/lomoji/03.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/03.png\" class=\"hkgmoji\" /> <br />\n<br />\n7. Point Estimates and Confidence Intervals (Concepts)<br />\n好多時，我地想估計population既一些特徵(e.g mean variamce&hellip;&hellip; )(parameter)。咁點估?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> 當然，拎一個sample黎估。<br />\n<br />\nPoint Estimates<br />\n假設我已經拎左個sample<br />\n{45,48,53,57,60}<br />\n我叫你估下個mean.<br />\n有人可能估: (45+48+53+57+60)/5=52.6<br />\n但亦有人估: (48+53+57)/3=52.7<br />\n甚至有人鳩估:54<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <br />\n實際上，你冇得話邊個啱，邊個錯。因為大家都係估。但somehow 都有的critiria去judge你估得好唔好。<br />\ni.)\tUnbiasedness<br />\nii.)\tConsistency<br />\niii.)\tEfficiency<br />\nUnbiasedness 就已經講左。<img src=\"/assets/faces/lomoji/11.png\" class=\"hkgmoji\" /> Mathematically, E(estimator)= parameter<br />\n就係unbiased estimator. (P.S Estimate 應該都係random variable，因為唔同sample會有唔同既estimator.)<br />\n<br />\nConsistency 就係當sample size越來越大，estimate 會越來越近parameter.<br />\n咁都正路，冇理由我個sample越大，但個estimate越唔準。<br />\n<br />\nEfficiency 就係指估計值既variance，有時會估大的，有時會估細的。如果variance好大，咁呢個差距就有機會好大。所以我去傾向拎細variance既estimate.<br />\n<br />\n(Note:以上三項不一定同時發生。)<br />\ne.g<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/07/062616_c46ca9256e156c2edfd001916a5fe22d.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F062616_c46ca9256e156c2edfd001916a5fe22d.png&h=5c6a4592&s={SIZE}\" /><br />\nRed Curve: Unbiased but less efficient<br />\nBlue Curve : Bias but more efficient<br />\n<br />\n(Note: Sample mean and variance are unbiased and consistent estimators)<br />\n<br />\n<br />\n<br />\nConfidence Intervals<br />\n<br />\nPoint Estimates就只係俾左個數字我，但係唔知有幾準。所以好多時，我地會用一個Interval去估計，增加準確率之餘，仲可以specify 個估計程度。<br />\n<br />\nConfidence Intervals就係比較大路既interval estimation.我地會定義一個confidence level (e.g 90%,95%,&hellip;)，然後construct 一個Interval，但問題就係，點樣理解？<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <br />\n<br />\n首先，記住population parameter係唔會變，is an unknown constant。個randomness，個變化擺在係intervals身上。唔同sample會有唔同既interval。一旦sample 拎左，construct左interval，所有野已經決定左。<br />\n跟住落黎得兩個結果：估中，估唔中。<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> 冇任何random, prob. 可言。所以我地只會話有幾多％既confident，而不能說有幾多prob.個interval會中.<br />\n<br />\n請看下圖:<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/07/062725_b06609fff3106e63beaab289ef58d33a.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F062725_b06609fff3106e63beaab289ef58d33a.png&h=1597861b&s={SIZE}\" /><br />\n紅色就係不同sample既Confidence Intervals。你會發現有些cover true parameter，有些冇。<br />\nE.g 95% confidence interval 就係指有95%既intervals會cover true parameter.<br />\n<br />\n至於每一種parameter，點揾Confidence Intervals後面再講。</blockquote><br />\n再問多句，咁同confidence level有咩分別啊？<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> 外行人理解得好辛苦，無奈唔明的話又唔明啲journal up乜"},{"pid":"1c75a3183f00a97f9127366236f3b66ac8d88569","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T03:44:59.000Z","msg":"<blockquote><blockquote>見咁多巴絲要求，我偷跑左point estimates and confidence intervals 以及hypothesis testing. 但我expect你對前面topics有基本認識<img src=\"/assets/faces/lomoji/03.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/03.png\" class=\"hkgmoji\" /> <br />\n<br />\n7. Point Estimates and Confidence Intervals (Concepts)<br />\n好多時，我地想估計population既一些特徵(e.g mean variamce&hellip;&hellip; )(parameter)。咁點估?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> 當然，拎一個sample黎估。<br />\n<br />\nPoint Estimates<br />\n假設我已經拎左個sample<br />\n{45,48,53,57,60}<br />\n我叫你估下個mean.<br />\n有人可能估: (45+48+53+57+60)/5=52.6<br />\n但亦有人估: (48+53+57)/3=52.7<br />\n甚至有人鳩估:54<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <br />\n實際上，你冇得話邊個啱，邊個錯。因為大家都係估。但somehow 都有的critiria去judge你估得好唔好。<br />\ni.)\tUnbiasedness<br />\nii.)\tConsistency<br />\niii.)\tEfficiency<br />\nUnbiasedness 就已經講左。<img src=\"/assets/faces/lomoji/11.png\" class=\"hkgmoji\" /> Mathematically, E(estimator)= parameter<br />\n就係unbiased estimator. (P.S Estimate 應該都係random variable，因為唔同sample會有唔同既estimator.)<br />\n<br />\nConsistency 就係當sample size越來越大，estimate 會越來越近parameter.<br />\n咁都正路，冇理由我個sample越大，但個estimate越唔準。<br />\n<br />\nEfficiency 就係指估計值既variance，有時會估大的，有時會估細的。如果variance好大，咁呢個差距就有機會好大。所以我去傾向拎細variance既estimate.<br />\n<br />\n(Note:以上三項不一定同時發生。)<br />\ne.g<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/07/062616_c46ca9256e156c2edfd001916a5fe22d.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F062616_c46ca9256e156c2edfd001916a5fe22d.png&h=5c6a4592&s={SIZE}\" /><br />\nRed Curve: Unbiased but less efficient<br />\nBlue Curve : Bias but more efficient<br />\n<br />\n(Note: Sample mean and variance are unbiased and consistent estimators)<br />\n<br />\n<br />\n<br />\nConfidence Intervals<br />\n<br />\nPoint Estimates就只係俾左個數字我，但係唔知有幾準。所以好多時，我地會用一個Interval去估計，增加準確率之餘，仲可以specify 個估計程度。<br />\n<br />\nConfidence Intervals就係比較大路既interval estimation.我地會定義一個confidence level (e.g 90%,95%,&hellip;)，然後construct 一個Interval，但問題就係，點樣理解？<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <br />\n<br />\n首先，記住population parameter係唔會變，is an unknown constant。個randomness，個變化擺在係intervals身上。唔同sample會有唔同既interval。一旦sample 拎左，construct左interval，所有野已經決定左。<br />\n跟住落黎得兩個結果：估中，估唔中。<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> 冇任何random, prob. 可言。所以我地只會話有幾多％既confident，而不能說有幾多prob.個interval會中.<br />\n<br />\n請看下圖:<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/07/062725_b06609fff3106e63beaab289ef58d33a.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F062725_b06609fff3106e63beaab289ef58d33a.png&h=1597861b&s={SIZE}\" /><br />\n紅色就係不同sample既Confidence Intervals。你會發現有些cover true parameter，有些冇。<br />\nE.g 95% confidence interval 就係指有95%既intervals會cover true parameter.<br />\n<br />\n至於每一種parameter，點揾Confidence Intervals後面再講。</blockquote><br />\n再問多句，咁同confidence level有咩分別啊？<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> 外行人理解得好辛苦，無奈唔明的話又唔明啲journal up乜</blockquote><br />\nConfidence level 真係做個條友set出黎。　一般都係set95%，一般來講，越高confidence level ，個interval就越長。<br />\nAnother interpretation of confidence interval:(上網搵<img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" /> )<br />\n&quot;There is a 90% probability that the calculated confidence interval from some future experiment encompasses the true value of the population parameter.&quot;(Neyman, 1937)<br />\n(Note: Neyman 就係發明confidence interval 個條友，等佢自己解釋）<br />\n(Note: The future calculated confidence interval is unknown here.)"},{"pid":"9d3d0d15fc3308b2bb7869565aec08a2f133161d","tid":489619,"uid":143023,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T03:57:13.000Z","msg":"<blockquote>咩係 standard error 同population 有咩關係</blockquote><br />\n我知我垃圾"},{"pid":"6f636fc435aef9262c1a1d67814fd83269e0dffe","tid":489619,"uid":39734,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T04:18:45.000Z","msg":"<blockquote><blockquote><blockquote>見咁多巴絲要求，我偷跑左point estimates and confidence intervals 以及hypothesis testing. 但我expect你對前面topics有基本認識<img src=\"/assets/faces/lomoji/03.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/03.png\" class=\"hkgmoji\" /> <br />\n<br />\n7. Point Estimates and Confidence Intervals (Concepts)<br />\n好多時，我地想估計population既一些特徵(e.g mean variamce&hellip;&hellip; )(parameter)。咁點估?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> 當然，拎一個sample黎估。<br />\n<br />\nPoint Estimates<br />\n假設我已經拎左個sample<br />\n{45,48,53,57,60}<br />\n我叫你估下個mean.<br />\n有人可能估: (45+48+53+57+60)/5=52.6<br />\n但亦有人估: (48+53+57)/3=52.7<br />\n甚至有人鳩估:54<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <br />\n實際上，你冇得話邊個啱，邊個錯。因為大家都係估。但somehow 都有的critiria去judge你估得好唔好。<br />\ni.)\tUnbiasedness<br />\nii.)\tConsistency<br />\niii.)\tEfficiency<br />\nUnbiasedness 就已經講左。<img src=\"/assets/faces/lomoji/11.png\" class=\"hkgmoji\" /> Mathematically, E(estimator)= parameter<br />\n就係unbiased estimator. (P.S Estimate 應該都係random variable，因為唔同sample會有唔同既estimator.)<br />\n<br />\nConsistency 就係當sample size越來越大，estimate 會越來越近parameter.<br />\n咁都正路，冇理由我個sample越大，但個estimate越唔準。<br />\n<br />\nEfficiency 就係指估計值既variance，有時會估大的，有時會估細的。如果variance好大，咁呢個差距就有機會好大。所以我去傾向拎細variance既estimate.<br />\n<br />\n(Note:以上三項不一定同時發生。)<br />\ne.g<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/07/062616_c46ca9256e156c2edfd001916a5fe22d.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F062616_c46ca9256e156c2edfd001916a5fe22d.png&h=5c6a4592&s={SIZE}\" /><br />\nRed Curve: Unbiased but less efficient<br />\nBlue Curve : Bias but more efficient<br />\n<br />\n(Note: Sample mean and variance are unbiased and consistent estimators)<br />\n<br />\n<br />\n<br />\nConfidence Intervals<br />\n<br />\nPoint Estimates就只係俾左個數字我，但係唔知有幾準。所以好多時，我地會用一個Interval去估計，增加準確率之餘，仲可以specify 個估計程度。<br />\n<br />\nConfidence Intervals就係比較大路既interval estimation.我地會定義一個confidence level (e.g 90%,95%,&hellip;)，然後construct 一個Interval，但問題就係，點樣理解？<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <br />\n<br />\n首先，記住population parameter係唔會變，is an unknown constant。個randomness，個變化擺在係intervals身上。唔同sample會有唔同既interval。一旦sample 拎左，construct左interval，所有野已經決定左。<br />\n跟住落黎得兩個結果：估中，估唔中。<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> 冇任何random, prob. 可言。所以我地只會話有幾多％既confident，而不能說有幾多prob.個interval會中.<br />\n<br />\n請看下圖:<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/07/062725_b06609fff3106e63beaab289ef58d33a.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F07%2F062725_b06609fff3106e63beaab289ef58d33a.png&h=1597861b&s={SIZE}\" /><br />\n紅色就係不同sample既Confidence Intervals。你會發現有些cover true parameter，有些冇。<br />\nE.g 95% confidence interval 就係指有95%既intervals會cover true parameter.<br />\n<br />\n至於每一種parameter，點揾Confidence Intervals後面再講。</blockquote><br />\n再問多句，咁同confidence level有咩分別啊？<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> 外行人理解得好辛苦，無奈唔明的話又唔明啲journal up乜</blockquote><br />\nConfidence level 真係做個條友set出黎。　一般都係set95%，一般來講，越高confidence level ，個interval就越長。<br />\nAnother interpretation of confidence interval:(上網搵<img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/smile.gif\" class=\"hkgmoji\" /> )<br />\n&quot;There is a 90% probability that the calculated confidence interval from some future experiment encompasses the true value of the population parameter.&quot;(Neyman, 1937)<br />\n(Note: Neyman 就係發明confidence interval 個條友，等佢自己解釋）<br />\n(Note: The future calculated confidence interval is unknown here.)</blockquote><br />\n好正 以前讀果陣冇理<br />\n而家睇係好理所當然<br />\n原理就好似係買六合彩<br />\n<br />\n我買$10 一注，就有0.00000⋯⋯000001% 信心會中到頭獎<br />\n如果我要高啲confident 中到頭獎，係唔知頭獎開咩number(population mean)既情況下，我只可以買好多注，越多注，就越高confident 會中<br />\n直到99% c.i. 我應該係買左99%既投注組合"},{"pid":"2e4fe80c93595701a456ee280f7677769cb765f7","tid":489619,"uid":150730,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T05:09:04.000Z","msg":"hypothesis testing 其實都係睇條題問乜9之後就用咩test <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <br />\n<br />\n大學岩岩學果D 來來去去都係幾個test <img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /> <br />\n<br />\n一係出絕招全部都係跟 chi square (asymptotically) 不用分那麼細<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /> <br />\n<br />\n仲記得果陣stat 3rd year course 要prove 果題既 confidence region is an ellipse <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" />  好彩仲記得ellipse equation <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"3817e3a0a3d0a34a79800aadd2f348a658e42921","tid":489619,"uid":69779,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T05:18:30.000Z","msg":"<blockquote>hypothesis testing 其實都係睇條題問乜9之後就用咩test <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <br />\n<br />\n大學岩岩學果D 來來去去都係幾個test <img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /> <br />\n<br />\n一係出絕招全部都係跟 chi square (asymptotically) 不用分那麼細<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /> <br />\n<br />\n仲記得果陣stat 3rd year course 要prove 果題既 confidence region is an ellipse <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" />  好彩仲記得ellipse equation <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"/assets/faces/normal/flowerface.gif\" class=\"hkgmoji\" />"},{"pid":"bfb644edab254acd4a29df5b91f31f48e2de0020","tid":489619,"uid":99176,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T07:10:20.000Z","msg":"有冇得tg 問stat"},{"pid":"0733dff2e11c2b51e8b205e70dd6bbf46ac202a9","tid":489619,"uid":63740,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T17:30:52.000Z","msg":"點解normal approximation to binomial distribution 個個 correction for continuity點解係+-0.5?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" />"},{"pid":"535ba875c4698586f37df92aa5de6ddfce796fe5","tid":489619,"uid":63740,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T17:37:50.000Z","msg":"<blockquote>點解normal approximation to binomial distribution 個個 correction for continuity點解係+-0.5?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /></blockquote><br />\n<br />\n同埋點解binomial distribution可以用normal distribution去approximate<br />\n同CLT有咩關係<br />\n<br />\n利申：識做題目但冇concept<img src=\"/assets/faces/lomoji/21.png\" class=\"hkgmoji\" />"},{"pid":"8b823ac1b04b7e573d196289b00e53374128fd7f","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T18:23:33.000Z","msg":"<blockquote>點解normal approximation to binomial distribution 個個 correction for continuity點解係+-0.5?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /></blockquote><br />\nlinear approximation"},{"pid":"bb10bb4f31527a241509c37f6c1ba3df236fb1e5","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T18:25:02.000Z","msg":"<blockquote><blockquote>點解normal approximation to binomial distribution 個個 correction for continuity點解係+-0.5?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /></blockquote><br />\n<br />\n同埋點解binomial distribution可以用normal distribution去approximate<br />\n同CLT有咩關係<br />\n<br />\n利申：識做題目但冇concept<img src=\"/assets/faces/lomoji/21.png\" class=\"hkgmoji\" /></blockquote><br />\nclt指出如果sample size夠大的話可以將distribution轉變做normal distribution"},{"pid":"53609808c87974b14db3ac7838ea60689bfbbe28","tid":489619,"uid":63740,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T19:24:19.000Z","msg":"<blockquote><blockquote><blockquote>點解normal approximation to binomial distribution 個個 correction for continuity點解係+-0.5?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /></blockquote><br />\n<br />\n同埋點解binomial distribution可以用normal distribution去approximate<br />\n同CLT有咩關係<br />\n<br />\n利申：識做題目但冇concept<img src=\"/assets/faces/lomoji/21.png\" class=\"hkgmoji\" /></blockquote><br />\nclt指出如果sample size夠大的話可以將distribution轉變做normal distribution</blockquote><br />\n<br />\nX~Bin(n,p)<br />\nmean=np<br />\nvar=npq<br />\n<br />\nSample mean of X~N(np,npq)<br />\n咁點解npq唔洗除n?"},{"pid":"09faa93da2b005af8932ad353a28cee7e2484f03","tid":489619,"uid":64601,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T20:12:18.000Z","msg":"lm"},{"pid":"b26e88c28fa9d9f60bb1560c98e302f8edc8ca70","tid":489619,"uid":73231,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T20:21:15.000Z","msg":"有興趣知 SVM 係點樣構思出嚟<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n<br />\n<blockquote><br />\nThe original SVM algorithm was invented by Vladimir N. Vapnik and Alexey Ya. Chervonenkis in 1963. In 1992, Bernhard E. Boser, Isabelle M. Guyon and Vladimir N. Vapnik suggested a way to create nonlinear classifiers by applying the kernel trick to maximum-margin hyperplanes.[10] The current standard incarnation (soft margin) was proposed by Corinna Cortes and Vapnik in 1993 and published in 1995.[1]<br />\n</blockquote>"},{"pid":"0890f6441e4837e45844f96f523fa0e2ffa1b118","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T20:43:17.000Z","msg":"<blockquote><blockquote><blockquote><blockquote>點解normal approximation to binomial distribution 個個 correction for continuity點解係+-0.5?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /></blockquote><br />\n<br />\n同埋點解binomial distribution可以用normal distribution去approximate<br />\n同CLT有咩關係<br />\n<br />\n利申：識做題目但冇concept<img src=\"/assets/faces/lomoji/21.png\" class=\"hkgmoji\" /></blockquote><br />\nclt指出如果sample size夠大的話可以將distribution轉變做normal distribution</blockquote><br />\n<br />\nX~Bin(n,p)<br />\nmean=np<br />\nvar=npq<br />\n<br />\nSample mean of X~N(np,npq)<br />\n咁點解npq唔洗除n?</blockquote><br />\nsample mean of X係~N(p,pq/n) wor"},{"pid":"a92fd1066c7dc227b0d4cde558518da4e43849b7","tid":489619,"uid":13901,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T20:47:44.000Z","msg":"<blockquote>有興趣知 SVM 係點樣構思出嚟<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n<br />\n<blockquote><br />\nThe original SVM algorithm was invented by Vladimir N. Vapnik and Alexey Ya. Chervonenkis in 1963. In 1992, Bernhard E. Boser, Isabelle M. Guyon and Vladimir N. Vapnik suggested a way to create nonlinear classifiers by applying the kernel trick to maximum-margin hyperplanes.[10] The current standard incarnation (soft margin) was proposed by Corinna Cortes and Vapnik in 1993 and published in 1995.[1]<br />\n</blockquote></blockquote><br />\n你講邊部份先<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n最基本就係maximum margin problem<br />\n如果係一啲non linear separable既case<br />\n就試唔同既kernel即係一啲transformation<br />\n將啲point map去另一個seperable既coordinate到<br />\n詳細啲數學野我就唔打lu <br />\n不過本質上係regression problem"},{"pid":"eaee25012e32cc9e4e3360f20924c69a7c2d1fa9","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T20:53:20.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote>點解normal approximation to binomial distribution 個個 correction for continuity點解係+-0.5?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /></blockquote><br />\n<br />\n同埋點解binomial distribution可以用normal distribution去approximate<br />\n同CLT有咩關係<br />\n<br />\n利申：識做題目但冇concept<img src=\"/assets/faces/lomoji/21.png\" class=\"hkgmoji\" /></blockquote><br />\nclt指出如果sample size夠大的話可以將distribution轉變做normal distribution</blockquote><br />\n<br />\nX~Bin(n,p)<br />\nmean=np<br />\nvar=npq<br />\n<br />\nSample mean of X~N(np,npq)<br />\n咁點解npq唔洗除n?</blockquote><br />\nsample mean of X係~N(np,pq) wor</blockquote><br />\n睇錯，自膠<br />\nVar(x bar)<br />\n= Var(summation of Xi /n)<br />\n= 1/n^2Var(summation of Xi )<br />\n= 1/n^2Var(n乘 npq) <br />\n= pq"},{"pid":"b7a6bdc5c5d6501adfce2ab01cfd7f79aea4b2ec","tid":489619,"uid":63740,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T21:09:28.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>點解normal approximation to binomial distribution 個個 correction for continuity點解係+-0.5?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /></blockquote><br />\n<br />\n同埋點解binomial distribution可以用normal distribution去approximate<br />\n同CLT有咩關係<br />\n<br />\n利申：識做題目但冇concept<img src=\"/assets/faces/lomoji/21.png\" class=\"hkgmoji\" /></blockquote><br />\nclt指出如果sample size夠大的話可以將distribution轉變做normal distribution</blockquote><br />\n<br />\nX~Bin(n,p)<br />\nmean=np<br />\nvar=npq<br />\n<br />\nSample mean of X~N(np,npq)<br />\n咁點解npq唔洗除n?</blockquote><br />\nsample mean of X係~N(np,pq) wor</blockquote><br />\n睇錯，自膠<br />\nVar(x bar)<br />\n= Var(summation of Xi /n)<br />\n= 1/n^2Var(summation of Xi )<br />\n= 1/n^2Var(n乘 npq) <br />\n= pq</blockquote><br />\n但係做normal approximation個時<br />\nz=(x-np)&divide;開方(npq)<br />\n而唔係&divide;開方(pq)<br />\n好難呀<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" />"},{"pid":"44525269b14db5fd63916b328bbf223d08a306c3","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T21:44:16.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>點解normal approximation to binomial distribution 個個 correction for continuity點解係+-0.5?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /></blockquote><br />\n<br />\n同埋點解binomial distribution可以用normal distribution去approximate<br />\n同CLT有咩關係<br />\n<br />\n利申：識做題目但冇concept<img src=\"/assets/faces/lomoji/21.png\" class=\"hkgmoji\" /></blockquote><br />\nclt指出如果sample size夠大的話可以將distribution轉變做normal distribution</blockquote><br />\n<br />\nX~Bin(n,p)<br />\nmean=np<br />\nvar=npq<br />\n<br />\nSample mean of X~N(np,npq)<br />\n咁點解npq唔洗除n?</blockquote><br />\nsample mean of X係~N(np,pq) wor</blockquote><br />\n睇錯，自膠<br />\nVar(x bar)<br />\n= Var(summation of Xi /n)<br />\n= 1/n^2Var(summation of Xi )<br />\n= 1/n^2Var(n乘 npq) <br />\n= pq</blockquote><br />\n但係做normal approximation個時<br />\nz=(x-np)&divide;開方(npq)<br />\n而唔係&divide;開方(pq)<br />\n好難呀<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /></blockquote><br />\n而家你係計X定X bar的approximation? <br />\nX的話就係N(np,npq)<br />\nX bar就係N(np,pq)"},{"pid":"be8f1487b1eaf70030fe206292fbf744e6e73c82","tid":489619,"uid":64102,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T22:01:08.000Z","msg":"留名<br />\n3大畢業咗好幾年<br />\n想重溫番知識<br />\n個個terms都見過，還咗好多俾老師<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" />"},{"pid":"e2d2169f93407ace5781b9b9d9da1bdf9174a949","tid":489619,"uid":13901,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T22:02:33.000Z","msg":"<blockquote>留名<br />\n3大畢業咗好幾年<br />\n想重溫番知識<br />\n個個terms都見過，還咗好多俾老師<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n想問下師兄而家做緊邊行<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"beacbf2ceabdc535a454912fefe17eb36457d40a","tid":489619,"uid":64102,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T22:13:44.000Z","msg":"<blockquote><blockquote>留名<br />\n3大畢業咗好幾年<br />\n想重溫番知識<br />\n個個terms都見過，還咗好多俾老師<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n想問下師兄而家做緊邊行<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\nIT<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /> <br />\n想自修上去而家最hit既嘢<br />\nMachine Learning, AI 個堆"},{"pid":"c8bface82c17a3baed70d8869cb2f4a764773f89","tid":489619,"uid":64102,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T22:19:20.000Z","msg":"<blockquote><blockquote><blockquote>留名<br />\n3大畢業咗好幾年<br />\n想重溫番知識<br />\n個個terms都見過，還咗好多俾老師<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n想問下師兄而家做緊邊行<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\nIT<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /> <br />\n想自修上去而家最hit既嘢<br />\nMachine Learning, AI 個堆</blockquote><br />\nDeep learning 聽講係將Neural Network改個名<br />\n以前個prof教到一舊舊，學完都唔知做緊乜，除咗做assignment"},{"pid":"a6b2e6f42fdfef25637ceff310b58e4845bfdce8","tid":489619,"uid":64102,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-07T22:42:27.000Z","msg":"讀STAT同讀其他science科一樣，concept好撚重要。<br />\nIndependence呢樣嘢成日都出現<br />\nP(A and B) = P(A) x P(B) if A and B are indept.<br />\n<br />\n見到樓上有人問MLE點解係乘埋一舊<br />\n通常講親都係i.i.d. (independent &amp; identically distributed)<br />\n因為independent，所以可以將一個multivariate probability拆散再乘<br />\nP(X1, X2, ... , Xn) = P(X1)P(X2)...P(Xn)<br />\n因為identically distributed，所以每一個rv既probability function係一樣樣<br />\nP(X1)P(X2)...P(Xn) = P(X1)^n<br />\n<br />\n識derive到個公式，個concept就跟你一世"},{"pid":"4dec48bba266a88c170fe04e0a604ec5e7301f35","tid":489619,"uid":144513,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T23:12:11.000Z","msg":"lm"},{"pid":"e48bec177d87411b244397c69c49b6411864a8fd","tid":489619,"uid":13901,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-07T23:18:34.000Z","msg":"<blockquote>讀STAT同讀其他science科一樣，concept好撚重要。<br />\nIndependence呢樣嘢成日都出現<br />\nP(A and B) = P(A) x P(B) if A and B are indept.<br />\n<br />\n見到樓上有人問MLE點解係乘埋一舊<br />\n通常講親都係i.i.d. (independent &amp; identically distributed)<br />\n因為independent，所以可以將一個multivariate probability拆散再乘<br />\nP(X1, X2, ... , Xn) = P(X1)P(X2)...P(Xn)<br />\n因為identically distributed，所以每一個rv既probability function係一樣樣<br />\nP(X1)P(X2)...P(Xn) = P(X1)^n<br />\n<br />\n識derive到個公式，個concept就跟你一世</blockquote><br />\nLikelihood function同iid random variables 既 joint distribution個concept好似<br />\n不過分別係likelihood function講緊given一堆sample同proposed density function, parameters本身既distribution係點<br />\n而joint distribution就係given parameters同proposed density function,<br />\nsamples既distribution係點<br />\n(好似係)"},{"pid":"fc887dd807220472ce205bbc470135e50331c92e","tid":489619,"uid":145061,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T23:25:26.000Z","msg":"想問樓豬識唔識用matlab<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" />"},{"pid":"6a1dedbe6306c4b40caea403ffef61079337121d","tid":489619,"uid":13901,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-07T23:33:22.000Z","msg":"<blockquote><blockquote><blockquote><blockquote>留名<br />\n3大畢業咗好幾年<br />\n想重溫番知識<br />\n個個terms都見過，還咗好多俾老師<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n想問下師兄而家做緊邊行<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\nIT<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /> <br />\n想自修上去而家最hit既嘢<br />\nMachine Learning, AI 個堆</blockquote><br />\nDeep learning 聽講係將Neural Network改個名<br />\n以前個prof教到一舊舊，學完都唔知做緊乜，除咗做assignment</blockquote><br />\n你係會學到一堆工具<br />\n你要搞清楚既係<br />\n1.知道有咩效果(bias-variance問題?)<br />\n2.知道每個method (lasso ridge svm nnet...) solve緊乜野問題<br />\n3.知道放乜野input ,佢既output又係代表緊乜野<br />\n<br />\n問題係有好多時候唔係話人手乜都放比個algorithm計就得<br />\n簡單到linear/logistics regression問題<br />\n比電腦計都會ignore左好多資訊<br />\n例如好多cross-terms//higher order既野部電腦唔會考慮<br />\n人手做有效既feature extraction<br />\n好多時比起單純比部電腦去train個model effective好多"},{"pid":"f4f8d03875e6a4d0dd3afe3e2df9593ff1488c3f","tid":489619,"uid":64102,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T23:41:16.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote>留名<br />\n3大畢業咗好幾年<br />\n想重溫番知識<br />\n個個terms都見過，還咗好多俾老師<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n想問下師兄而家做緊邊行<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\nIT<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /> <br />\n想自修上去而家最hit既嘢<br />\nMachine Learning, AI 個堆</blockquote><br />\nDeep learning 聽講係將Neural Network改個名<br />\n以前個prof教到一舊舊，學完都唔知做緊乜，除咗做assignment</blockquote><br />\n你係會學到一堆工具<br />\n你要搞清楚既係<br />\n1.知道有咩效果(bias-variance問題?)<br />\n2.知道每個method (lasso ridge svm nnet...) solve緊乜野問題<br />\n3.知道放乜野input ,佢既output又係代表緊乜野<br />\n<br />\n問題係有好多時候唔係話人手乜都放比個algorithm計就得<br />\n簡單到linear/logistics regression問題<br />\n比電腦計都會ignore左好多資訊<br />\n例如好多cross-terms//higher order既野部電腦唔會考慮<br />\n人手做有效既feature extraction<br />\n好多時比起單純比部電腦去train個model effective好多</blockquote><br />\n巴打做盛行/讀緊書？<br />\n有冇Resource推介？"},{"pid":"ed644af979b01d8a29c60b0e18c09c1d9ad0ed71","tid":489619,"uid":64102,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T23:43:05.000Z","msg":"<blockquote><blockquote>讀STAT同讀其他science科一樣，concept好撚重要。<br />\nIndependence呢樣嘢成日都出現<br />\nP(A and B) = P(A) x P(B) if A and B are indept.<br />\n<br />\n見到樓上有人問MLE點解係乘埋一舊<br />\n通常講親都係i.i.d. (independent &amp; identically distributed)<br />\n因為independent，所以可以將一個multivariate probability拆散再乘<br />\nP(X1, X2, ... , Xn) = P(X1)P(X2)...P(Xn)<br />\n因為identically distributed，所以每一個rv既probability function係一樣樣<br />\nP(X1)P(X2)...P(Xn) = P(X1)^n<br />\n<br />\n識derive到個公式，個concept就跟你一世</blockquote><br />\nLikelihood function同iid random variables 既 joint distribution個concept好似<br />\n不過分別係likelihood function講緊given一堆sample同proposed density function, parameters本身既distribution係點<br />\n而joint distribution就係given parameters同proposed density function,<br />\nsamples既distribution係點<br />\n(好似係)</blockquote><br />\n冇錯<br />\n巴打你又幫我恢復知識啦<img src=\"/assets/faces/big/smile.gif\" class=\"hkgmoji\" />"},{"pid":"816c7b440934cebdb2c749743ae8de4742a5a58a","tid":489619,"uid":13901,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-07T23:52:12.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>留名<br />\n3大畢業咗好幾年<br />\n想重溫番知識<br />\n個個terms都見過，還咗好多俾老師<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /></blockquote><br />\n想問下師兄而家做緊邊行<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\nIT<img src=\"/assets/faces/normal/clown.gif\" class=\"hkgmoji\" /> <br />\n想自修上去而家最hit既嘢<br />\nMachine Learning, AI 個堆</blockquote><br />\nDeep learning 聽講係將Neural Network改個名<br />\n以前個prof教到一舊舊，學完都唔知做緊乜，除咗做assignment</blockquote><br />\n你係會學到一堆工具<br />\n你要搞清楚既係<br />\n1.知道有咩效果(bias-variance問題?)<br />\n2.知道每個method (lasso ridge svm nnet...) solve緊乜野問題<br />\n3.知道放乜野input ,佢既output又係代表緊乜野<br />\n<br />\n問題係有好多時候唔係話人手乜都放比個algorithm計就得<br />\n簡單到linear/logistics regression問題<br />\n比電腦計都會ignore左好多資訊<br />\n例如好多cross-terms//higher order既野部電腦唔會考慮<br />\n人手做有效既feature extraction<br />\n好多時比起單純比部電腦去train個model effective好多</blockquote><br />\n巴打做盛行/讀緊書？<br />\n有冇Resource推介？</blockquote><br />\nfinal year<br />\n想學工具既<br />\nThe Elements of<br />\nStatistical Learning<br />\nData Mining, Inference, and Prediction<br />\n呢本書唔錯<br />\n好多作為一個data scientist基本工具都可以學到<br />\n至於點用就睇個人造化<br />\n始終每個field有佢本身developed 同 effective既knowledge<br />\n點樣將呢啲野apply返入去statistics既model先係最重要既步驟<br />\n<br />\n我理解係 好多野其實setup一個algorithm去search都可以<br />\n不過好多時因應個問題會令個algorithm既time complexity exponential咁上<br />\neg best subset selection<br />\n而人手做一啲合理/有效既data cleansing , transformation ,extraction 先係現時最有效既solution"},{"pid":"ab1bfb125c846b5c8efb59e70bbb9cedf7312b6d","tid":489619,"uid":137123,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T02:55:21.000Z","msg":"<img src=\"/assets/faces/big/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/big/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/big/adore.gif\" class=\"hkgmoji\" />"},{"pid":"7ff1679e3d212591c2ac5a675105cd66aeedd902","tid":489619,"uid":28052,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T03:12:20.000Z","msg":"有無人話我知post hoc test要點樣講<br />\n原本用factorial anova 講哂p value 個咋<br />\n但係唔知post hoc tukey 點講<br />\n同埋plot(線圖）都唔識點樣講<img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" /> <br />\n上網搵咗好多都搵唔到"},{"pid":"5255b9a97d71060c43cca430e582589d6aa56a81","tid":489619,"uid":51594,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T04:21:57.000Z","msg":"lm覺野"},{"pid":"c2c2ae383e85b2186032f064a56a2beab55ec528","tid":489619,"uid":51594,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T04:22:07.000Z","msg":"<blockquote>lm學野</blockquote>"},{"pid":"2208e79bd0871c60cd47485a1b771cac0ed88bbf","tid":489619,"uid":63740,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T06:14:34.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><br />\n<br />\n同埋點解binomial distribution可以用normal distribution去approximate<br />\n同CLT有咩關係<br />\n<br />\n利申：識做題目但冇concept<img src=\"/assets/faces/lomoji/21.png\" class=\"hkgmoji\" /></blockquote><br />\nclt指出如果sample size夠大的話可以將distribution轉變做normal distribution</blockquote><br />\n<br />\nX~Bin(n,p)<br />\nmean=np<br />\nvar=npq<br />\n<br />\nSample mean of X~N(np,npq)<br />\n咁點解npq唔洗除n?</blockquote><br />\nsample mean of X係~N(np,pq) wor</blockquote><br />\n睇錯，自膠<br />\nVar(x bar)<br />\n= Var(summation of Xi /n)<br />\n= 1/n^2Var(summation of Xi )<br />\n= 1/n^2Var(n乘 npq) <br />\n= pq</blockquote><br />\n但係做normal approximation個時<br />\nz=(x-np)&divide;開方(npq)<br />\n而唔係&divide;開方(pq)<br />\n好難呀<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /></blockquote><br />\n而家你係計X定X bar的approximation? <br />\nX的話就係N(np,npq)<br />\nX bar就係N(np,pq)</blockquote><br />\n<br />\ncentral limit therom唔係講話<br />\n<br />\nX無論follow咩distribution都好<br />\n只要sample size夠大<br />\nsample mean Xbar都會follow normal distribution<br />\n<br />\n定係<br />\nX無論follow咩distribution都好<br />\n只要sample size夠大<br />\nX都會follow normal distribution"},{"pid":"09c13008076a62a4be7ef5ee649c15ac9d6a4615","tid":489619,"uid":161322,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T06:23:26.000Z","msg":"lm下個sem睇"},{"pid":"819c35a47ec07c709ebaa4200b0875d351412ded","tid":489619,"uid":100760,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T06:27:05.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><br />\nclt指出如果sample size夠大的話可以將distribution轉變做normal distribution</blockquote><br />\n<br />\nX~Bin(n,p)<br />\nmean=np<br />\nvar=npq<br />\n<br />\nSample mean of X~N(np,npq)<br />\n咁點解npq唔洗除n?</blockquote><br />\nsample mean of X係~N(np,pq) wor</blockquote><br />\n睇錯，自膠<br />\nVar(x bar)<br />\n= Var(summation of Xi /n)<br />\n= 1/n^2Var(summation of Xi )<br />\n= 1/n^2Var(n乘 npq) <br />\n= pq</blockquote><br />\n但係做normal approximation個時<br />\nz=(x-np)&divide;開方(npq)<br />\n而唔係&divide;開方(pq)<br />\n好難呀<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /></blockquote><br />\n而家你係計X定X bar的approximation? <br />\nX的話就係N(np,npq)<br />\nX bar就係N(np,pq)</blockquote><br />\n<br />\ncentral limit therom唔係講話<br />\n<br />\nX無論follow咩distribution都好<br />\n只要sample size夠大<br />\nsample mean Xbar都會follow normal distribution<br />\n<br />\n定係<br />\nX無論follow咩distribution都好<br />\n只要sample size夠大<br />\nX都會follow normal distribution</blockquote><br />\n應該係前者喎<br />\n後者咪第一句同第三句矛盾左"},{"pid":"9620f9e9f070c075f6e68b2233c3bfffbbdf723c","tid":489619,"uid":63740,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T06:36:19.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><br />\n<br />\nX~Bin(n,p)<br />\nmean=np<br />\nvar=npq<br />\n<br />\nSample mean of X~N(np,npq)<br />\n咁點解npq唔洗除n?</blockquote><br />\nsample mean of X係~N(np,pq) wor</blockquote><br />\n睇錯，自膠<br />\nVar(x bar)<br />\n= Var(summation of Xi /n)<br />\n= 1/n^2Var(summation of Xi )<br />\n= 1/n^2Var(n乘 npq) <br />\n= pq</blockquote><br />\n但係做normal approximation個時<br />\nz=(x-np)&divide;開方(npq)<br />\n而唔係&divide;開方(pq)<br />\n好難呀<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /></blockquote><br />\n而家你係計X定X bar的approximation? <br />\nX的話就係N(np,npq)<br />\nX bar就係N(np,pq)</blockquote><br />\n<br />\ncentral limit therom唔係講話<br />\n<br />\nX無論follow咩distribution都好<br />\n只要sample size夠大<br />\nsample mean Xbar都會follow normal distribution<br />\n<br />\n定係<br />\nX無論follow咩distribution都好<br />\n只要sample size夠大<br />\nX都會follow normal distribution</blockquote><br />\n應該係前者喎<br />\n後者咪第一句同第三句矛盾左</blockquote><br />\n咁如果係咁嘅話<br />\nX~Bin(n,p)<br />\nby clt,<br />\nXBar~N(np,npq/n)<br />\n咁做normal approximation to binomial<br />\nZ個分母咪應該係開方(pq)<br />\n救命<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" />"},{"pid":"c95b0c01cd2700e709bfc46318c14962820eccf1","tid":489619,"uid":13901,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T06:37:04.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><br />\n<br />\nX~Bin(n,p)<br />\nmean=np<br />\nvar=npq<br />\n<br />\nSample mean of X~N(np,npq)<br />\n咁點解npq唔洗除n?</blockquote><br />\nsample mean of X係~N(np,pq) wor</blockquote><br />\n睇錯，自膠<br />\nVar(x bar)<br />\n= Var(summation of Xi /n)<br />\n= 1/n^2Var(summation of Xi )<br />\n= 1/n^2Var(n乘 npq) <br />\n= pq</blockquote><br />\n但係做normal approximation個時<br />\nz=(x-np)&divide;開方(npq)<br />\n而唔係&divide;開方(pq)<br />\n好難呀<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /></blockquote><br />\n而家你係計X定X bar的approximation? <br />\nX的話就係N(np,npq)<br />\nX bar就係N(np,pq)</blockquote><br />\n<br />\ncentral limit therom唔係講話<br />\n<br />\nX無論follow咩distribution都好<br />\n只要sample size夠大<br />\nsample mean Xbar都會follow normal distribution<br />\n<br />\n定係<br />\nX無論follow咩distribution都好<br />\n只要sample size夠大<br />\nX都會follow normal distribution</blockquote><br />\n應該係前者喎<br />\n後者咪第一句同第三句矛盾左</blockquote><br />\n正解<br />\n不過留意返corresponding variance同mean點計"},{"pid":"6aca992c77eead40a98d574e055197cf30199e84","tid":489619,"uid":100760,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T07:17:40.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><br />\nsample mean of X係~N(np,pq) wor</blockquote><br />\n睇錯，自膠<br />\nVar(x bar)<br />\n= Var(summation of Xi /n)<br />\n= 1/n^2Var(summation of Xi )<br />\n= 1/n^2Var(n乘 npq) <br />\n= pq</blockquote><br />\n但係做normal approximation個時<br />\nz=(x-np)&divide;開方(npq)<br />\n而唔係&divide;開方(pq)<br />\n好難呀<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /></blockquote><br />\n而家你係計X定X bar的approximation? <br />\nX的話就係N(np,npq)<br />\nX bar就係N(np,pq)</blockquote><br />\n<br />\ncentral limit therom唔係講話<br />\n<br />\nX無論follow咩distribution都好<br />\n只要sample size夠大<br />\nsample mean Xbar都會follow normal distribution<br />\n<br />\n定係<br />\nX無論follow咩distribution都好<br />\n只要sample size夠大<br />\nX都會follow normal distribution</blockquote><br />\n應該係前者喎<br />\n後者咪第一句同第三句矛盾左</blockquote><br />\n咁如果係咁嘅話<br />\nX~Bin(n,p)<br />\nby clt,<br />\nXBar~N(np,npq/n)<br />\n咁做normal approximation to binomial<br />\nZ個分母咪應該係開方(pq)<br />\n救命<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\nx~B(n,p)<br />\nthen by CLT,<br />\nx bar~N(np, pq)<br />\nand can approximate x~N(np, npq)<br />\n你話唔知z除咩，咁要睇你係搵P(x&gt;一個數)定P(x bar&gt;一個數) 喎，前者咪除開方pq<br />\n<br />\n利申淨係識計數，唔知啲字眼啱唔啱"},{"pid":"8322289ebdc19800a43cd7a57b8c87ac36b6acee","tid":489619,"uid":63740,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T07:21:25.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><br />\n睇錯，自膠<br />\nVar(x bar)<br />\n= Var(summation of Xi /n)<br />\n= 1/n^2Var(summation of Xi )<br />\n= 1/n^2Var(n乘 npq) <br />\n= pq</blockquote><br />\n但係做normal approximation個時<br />\nz=(x-np)&divide;開方(npq)<br />\n而唔係&divide;開方(pq)<br />\n好難呀<img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/fs/smile.gif\" class=\"hkgmoji\" /></blockquote><br />\n而家你係計X定X bar的approximation? <br />\nX的話就係N(np,npq)<br />\nX bar就係N(np,pq)</blockquote><br />\n<br />\ncentral limit therom唔係講話<br />\n<br />\nX無論follow咩distribution都好<br />\n只要sample size夠大<br />\nsample mean Xbar都會follow normal distribution<br />\n<br />\n定係<br />\nX無論follow咩distribution都好<br />\n只要sample size夠大<br />\nX都會follow normal distribution</blockquote><br />\n應該係前者喎<br />\n後者咪第一句同第三句矛盾左</blockquote><br />\n咁如果係咁嘅話<br />\nX~Bin(n,p)<br />\nby clt,<br />\nXBar~N(np,npq/n)<br />\n咁做normal approximation to binomial<br />\nZ個分母咪應該係開方(pq)<br />\n救命<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" /></blockquote><br />\nx~B(n,p)<br />\nthen by CLT,<br />\nx bar~N(np, pq)<br />\nand can approximate x~N(np, npq)<br />\n你話唔知z除咩，咁要睇你係搵P(x&gt;一個數)定P(x bar&gt;一個數) 喎，前者咪除開方pq<br />\n<br />\n利申淨係識計數，唔知啲字眼啱唔啱</blockquote><br />\n咁即係X approximate to Normal係冇用到CLT?"},{"pid":"6ef981008499acd486fe0eeabe5e6d448e934d81","tid":489619,"uid":78468,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T07:38:04.000Z","msg":"留名等樓豬教stochastic process"},{"pid":"8fafd79233c93f9708b1e6a9fb72dc249b91b2b7","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T07:52:51.000Z","msg":"CLT 個度，以我所見，如果個random variable可以express成sum of i.i.d ，基本上都可以用normal 去 approximate"},{"pid":"a69fa8e3943012955c1f640379ec9e97d1db3852","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T07:53:51.000Z","msg":"<blockquote>留名等樓豬教stochastic process</blockquote><br />\n呢個sem 我都要考"},{"pid":"8457625214320b2b96fc5dadd26453c6b14db0e3","tid":489619,"uid":154488,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T08:12:05.000Z","msg":"想問下點解有時條問題講到明係sample mean/sd=xxx<br />\n但都要用normal distribution去搵confidence interval??<br />\n而唔係用t distribution?"},{"pid":"ce9391827a9a85518342167b275145abb517badc","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T08:43:49.000Z","msg":"<blockquote>想問下點解有時條問題講到明係sample mean/sd=xxx<br />\n但都要用normal distribution去搵confidence interval??<br />\n而唔係用t distribution?</blockquote><br />\n因為sample size夠大，t distribution係n大過30後就似normal"},{"pid":"83223f7699bd6972585333b04f38409fcca4844e","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T08:46:53.000Z","msg":"<blockquote><blockquote>留名等樓豬教stochastic process</blockquote><br />\n呢個sem 我都要考</blockquote><br />\n人手計steady state計到喊<img src=\"/assets/faces/lomoji/23.png\" class=\"hkgmoji\" />"},{"pid":"42b717b00127eb5cda128ed81421a93f101ab476","tid":489619,"uid":69125,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T08:50:10.000Z","msg":"可唔可以講吓regression hypothesis testing concept同計數上點做/prove<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> 我淨係學過m1,大學主要讀probability distribution,但好少讀stat,讀過covariance,correlation同唔同distribution,joint distribution點計,但係咪有d乜乜t-distribution,chi-square???"},{"pid":"b1a88d15841a168d885495abe7d4907f14f95bbc","tid":489619,"uid":154488,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T09:06:36.000Z","msg":"<blockquote><blockquote>想問下點解有時條問題講到明係sample mean/sd=xxx<br />\n但都要用normal distribution去搵confidence interval??<br />\n而唔係用t distribution?</blockquote><br />\n因為sample size夠大，t distribution係n大過30後就似normal</blockquote><br />\n即係如果n&gt;30既話,所謂既SAMPLE SD/MEAN其實都叫係POPULATION MEAN/SD??"},{"pid":"c40e85098c90a4e58531e0b9ec69369dd97437cf","tid":489619,"uid":34522,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T09:31:53.000Z","msg":"<blockquote><blockquote><blockquote>想問下點解有時條問題講到明係sample mean/sd=xxx<br />\n但都要用normal distribution去搵confidence interval??<br />\n而唔係用t distribution?</blockquote><br />\n因為sample size夠大，t distribution係n大過30後就似normal</blockquote><br />\n即係如果n&gt;30既話,所謂既SAMPLE SD/MEAN其實都叫係POPULATION MEAN/SD??</blockquote><br />\n搞錯左，係t dist會似normal，唔係sample sd似population sd"},{"pid":"99ae3c5f3eac218f415cce6d0ce22eb6534be28b","tid":489619,"uid":132931,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T14:36:26.000Z","msg":"LM STAT好有用."},{"pid":"73c870c05f218d7110c7d57e3c9671f5bee54c5e","tid":489619,"uid":132931,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T14:42:39.000Z","msg":"BTW 見有人討論learning GE問題,<br />\n依家哥D咩 AI呀 Deep learning GE野其實本質上係做緊optimization.<br />\nStat佔GE部份比較少.有心想鑽研呢方面其實應該去學optimization.<br />\n學術應用Stat同optimization真係最有用GE 2個領域<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" />"},{"pid":"1c9bbf30e6dcaa3e5954fb42416b0ac0a7faad29","tid":489619,"uid":1788,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-08T15:50:17.000Z","msg":"集一集氣聽朝考econometrics"},{"pid":"889e8380089228c8317bb0fcdb316fac3701b631","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-09T00:04:55.000Z","msg":"潛左水，sor<img src=\"/assets/faces/lomoji/22.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/22.png\" class=\"hkgmoji\" /> <br />\n繼續講confidence intervals，初學既話，其實知條式就ok。但當然我都要講下大概點搵。<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <br />\n首先，我地要知道個parameter係咩distribution ，然後搵兩個數字(usually from that distribution) bound住=confidence level<br />\n然後,solve 左佢<br />\n好似有的抽象，所以我打左落黎，以供參考。<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/09/080400_cfb1c8ebe5100ac2ad96f7d7c2b1f1ce.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F09%2F080400_cfb1c8ebe5100ac2ad96f7d7c2b1f1ce.png&h=936fc17a&s={SIZE}\" /><br />\n上半part係重溫CLT."},{"pid":"7c00dc791915a8848bfb1b8f2b676f9b37ce1403","tid":489619,"uid":152451,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-09T00:12:48.000Z","msg":"<blockquote><blockquote><img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <br />\nMaths is fun</blockquote><br />\nstat唔係math</blockquote><br />\nstat係baby math"},{"pid":"56c5a68ef93eb4611d278e48d386a55a3e0fcc0c","tid":489619,"uid":62068,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-09T17:09:21.000Z","msg":"LM"},{"pid":"ba0cd8a5de0fa89c1d673d4aa34e92a3e98a0394","tid":489619,"uid":25570,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-09T17:29:36.000Z","msg":"有性趣<img src=\"/assets/faces/normal/tongue.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/tongue.gif\" class=\"hkgmoji\" /><br />\n以前細個讀書唔識諗.<br />\n出到黎做野先知STAT好有用.<br />\n建議你如果有時間,不如整片黎講解.<br />\n之前有個清整左C++<br />\n我覺得幾好<br />\n不過文字解釋我都已經好欣賞!<br />\n支持!!<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" />"},{"pid":"1da24a53af65d7961d528c32b727727544f392ac","tid":489619,"uid":2679,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-09T17:34:31.000Z","msg":"Retake gg文科撚努力追post學野<img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" />"},{"pid":"d7eef9b1c74100fd7b7f0f5b66c9a3af9288e735","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-09T23:14:32.000Z","msg":"<blockquote>有性趣<img src=\"/assets/faces/normal/tongue.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/tongue.gif\" class=\"hkgmoji\" /><br />\n以前細個讀書唔識諗.<br />\n出到黎做野先知STAT好有用.<br />\n建議你如果有時間,不如整片黎講解.<br />\n之前有個清整左C++<br />\n我覺得幾好<br />\n不過文字解釋我都已經好欣賞!<br />\n支持!!<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /></blockquote><br />\n我都想拍片，因為有好多概念靠yup係好難"},{"pid":"98889c4ec3804d32a4a6f9a98df64c189ba15def","tid":489619,"uid":49004,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-09T23:23:45.000Z","msg":"<blockquote><blockquote>有性趣<img src=\"/assets/faces/normal/tongue.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/tongue.gif\" class=\"hkgmoji\" /><br />\n以前細個讀書唔識諗.<br />\n出到黎做野先知STAT好有用.<br />\n建議你如果有時間,不如整片黎講解.<br />\n<span style=\"color: red;\">之前有個清整左C++</span><br />\n我覺得幾好<br />\n不過文字解釋我都已經好欣賞!<br />\n支持!!<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /></blockquote><br />\n我都想拍片，因為有好多概念靠yup係好難</blockquote><br />\n<img src=\"/assets/faces/normal/oh.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/oh.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/oh.gif\" class=\"hkgmoji\" /> 有個清整左C++<br />\n係邊個post 我都想學<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/frown.gif\" class=\"hkgmoji\" />"},{"pid":"51259a9678e571ba200c3c265b86eb3a281e941e","tid":489619,"uid":161501,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-10T00:13:40.000Z","msg":"繼續confidence interval。 上次講到 confidence interval for population mean，但係variance係知道嘅。但係喺一般情況下，你有乜可能會知道個variance。<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />  <br />\n咁好多時我哋都係用sample variance，但係個distribution有冇唔同咗？仲係咪normal呢？<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> <br />\n咁呢有個人叫student prove 到原來係 t-distribution。 T distribution嘅特點就係同normal差唔多樣，但係佢兩邊嘅位置會比較大的，有多的probability， 當呢個sample size 越大嘅時候佢就會趨向normal。<br />\n所以可以用 t-distribution去整confidence interval for population mean當 variance is unknown。（但sample size &gt;30 後，用番normal 唔會差好遠。)<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /> <br />\n<br />\n要整 confidence interval for population variance既話。 要知道sample variance 呢個random variable係follow chi squared distribution。 <br />\n咁所有嘢同我哋之前做嘅係冇分別嘅。下邊有幅圖，解釋咗我啱啱所講嘅嘢。如果你係初學嘅話，其實淨係知條式就可以㗎啦。其他嗰啲，只不過係想俾你知道大概點嚟嘅啫。<img src=\"/assets/faces/normal/kiss.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/kiss.gif\" class=\"hkgmoji\" /> <br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/10/081311_5ae09988dd6808fadbcf090bc25b7cb0.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F10%2F081311_5ae09988dd6808fadbcf090bc25b7cb0.png&h=73dff9f9&s={SIZE}\" /><br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/10/081333_4a0ef04bc6d37536660c36ce43cc1934.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F10%2F081333_4a0ef04bc6d37536660c36ce43cc1934.png&h=b913af80&s={SIZE}\" />"},{"pid":"2ed29fde3c033854cf374c977c3bdcde113d9255","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-10T00:19:39.000Z","msg":"其實我覺得confidence interval 最後你都會搵機計。最重要係識點interpert rather  than you know how to compute by hands.<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"d6aaa22f98ab9ed33b5597ea65601ae8a1cc266e","tid":489619,"uid":49004,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-10T00:30:40.000Z","msg":"咁上上面Chi-square distribution又係乜<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <br />\n<br />\n<br />\nt-distribution通常絕大多數應用喺n細過30 (未必完全一定)<br />\n仲有係當題目population S.D/Var係unknown時用<br />\n<br />\n用來改善normal distribution喺太少size底下造成的誤差<br />\n好似係<img src=\"/assets/faces/normal/angel.gif\" class=\"hkgmoji\" />"},{"pid":"fb623f65092a85e48ca59469cfd098b8cb760986","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-10T00:46:19.000Z","msg":"<blockquote>咁上上面Chi-square distribution又係乜<img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/cry.gif\" class=\"hkgmoji\" /> <br />\n<br />\n<br />\nt-distribution通常絕大多數應用喺n細過30 (未必完全一定)<br />\n仲有係當題目population S.D/Var係unknown時用<br />\n<br />\n用來改善normal distribution喺太少size底下造成的誤差<br />\n好似係<img src=\"/assets/faces/normal/angel.gif\" class=\"hkgmoji\" /></blockquote><br />\n比較數學的既講法，chi-squared(d.f 1) = normal^2<br />\nchi-squared (d.f r) 就係r個independent chi-squared(d.f 1)加埋一齊<br />\n你諗下sample variance，佢係成炸２次既野加埋一齊，裏面有sample mean，which is likely normal.所以先估係 chi-squared ，and turn out it is.<br />\n但對初學來講，你當係多左個distribution，識查表就ok."},{"pid":"8da48e4f3a1471313412350c13895a5b30965fe8","tid":489619,"uid":28279,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-10T01:15:39.000Z","msg":"有無multivariate? <img src=\"/assets/faces/normal/good.gif\" class=\"hkgmoji\" />"},{"pid":"0fde3711602025d133616e3bf10f52530962c64c","tid":489619,"uid":4570,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-10T06:18:41.000Z","msg":"支持樓主<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <br />\n有時翻工要用<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> 但係想清楚明白背後點解咁計同點derive 條式出黎"},{"pid":"759f1f9c3e6ef92da934af304ae906ba60975d0c","tid":489619,"uid":8935,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-11T19:12:19.000Z","msg":"N&lt;30, sample mean of x bar又follow normal distribution ge? 同Clt矛盾wo"},{"pid":"933e0c717f7dfd6f4dd28be0ffc4ad069c984e80","tid":489619,"uid":69779,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-12T10:58:54.000Z","msg":"<blockquote>N&lt;30, sample mean of x bar又follow normal distribution ge? 同Clt矛盾wo</blockquote><br />\n<img src=\"/assets/faces/normal/@.gif\" class=\"hkgmoji\" />"},{"pid":"4c9378e293766bfc70321900b37924ab67abae42","tid":489619,"uid":81424,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-12T14:55:49.000Z","msg":"係咪即係t-distribution 係用計variance 嘅confidence interval<br />\n然後用variance嘅 confidence interval 同normal distribution 再計 mean 嘅 confidence interval<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" />"},{"pid":"63dfdab114425d99d53c050edb14f8e4e44fafd5","tid":489619,"uid":69779,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-12T14:58:01.000Z","msg":"<blockquote>係咪即係t-distribution 係用計variance 嘅confidence interval<br />\n然後用variance嘅 confidence interval 同normal distribution 再計 mean 嘅 confidence interval<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /></blockquote><br />\n可以咁講<br />\n<br />\n當然我哋assume咗呢個underlying distribution係normal<img src=\"/assets/faces/normal/biggrin.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/biggrin.gif\" class=\"hkgmoji\" />"},{"pid":"eaa1094503a99ffd2a5361219fa4c946e503bfe1","tid":489619,"uid":34301,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-12T15:56:21.000Z","msg":"stat撚留名"},{"pid":"e8c60fcc7cf08d093d3145aecdb6662b8fd3c34c","tid":489619,"uid":13901,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-13T01:01:18.000Z","msg":"<blockquote>stat撚留名</blockquote><br />\nStat神<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"b9ac7a8c3c8e69605af4d73011825ae239bb1244","tid":489619,"uid":34301,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-13T01:04:44.000Z","msg":"<blockquote><blockquote>stat撚留名</blockquote><br />\nStat神<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /></blockquote><br />\n痴線，繼續吹<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"067c3f1c904fcd83269230a005bea9df95a588fd","tid":489619,"uid":13901,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-13T01:06:45.000Z","msg":"<blockquote><blockquote><blockquote>stat撚留名</blockquote><br />\nStat神<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /></blockquote><br />\n痴線，繼續吹<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n頂你秒回<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"9523cffae62a5727c3f1921b56b05b6d54a96bb9","tid":489619,"uid":62610,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-13T03:05:04.000Z","msg":"<blockquote><blockquote><blockquote><blockquote>stat撚留名</blockquote><br />\nStat神<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /></blockquote><br />\n痴線，繼續吹<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n頂你秒回<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"4297e6e04ade40516246d18b6ccb2dfd1c0d8877","tid":489619,"uid":69779,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-13T03:28:21.000Z","msg":"<blockquote><blockquote>stat撚留名</blockquote><br />\nStat神<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"6357abdd48af9e67e6851d9ea6de46530b57f8fa","tid":489619,"uid":54667,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-13T06:03:56.000Z","msg":"留名"},{"pid":"4a9c84bcfce280f37e8648294d50dbbc67d3f0a9","tid":489619,"uid":132931,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-13T16:52:53.000Z","msg":"想問下fat-tailed 同heavy tailed 有咩分別 睇完WIKI唔太明<img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" />"},{"pid":"1d016339aebfe7306ea0d2a14ddd86eaa88c3d68","tid":489619,"uid":41460,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-14T04:01:02.000Z","msg":"讀過business stat留名<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"ce570a41888332d04dddb5ab784233769d929109","tid":489619,"uid":34301,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-14T05:44:34.000Z","msg":"<blockquote>想問下fat-tailed 同heavy tailed 有咩分別 睇完WIKI唔太明<img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /></blockquote><br />\nIn probability theory, <span style=\"color: red;\"><ins>heavy-tailed distributions</ins></span> are probability distributions <ins>whose tails are <strong>not exponentially bounded</strong></ins>: that is, they have <ins>heavier tails than the exponential distribution</ins>.<br />\n<br />\n...<br />\n<br />\nA <span style=\"color: red;\"><ins>fat-tailed</ins></span> distribution is a distribution for which the probability density function, for large x, <ins>goes to zero as a power x^{-a}</ins>. Since such a power is always bounded below by the probability density function of an exponential distribution, <ins>fat-tailed distributions are always heavy-tailed</ins>. ...<br />\n<br />\nSource: <a href=\"https://en.wikipedia.org/wiki/Heavy-tailed_distribution\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FHeavy-tailed_distribution&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=45d6c888\" target=\"_blank\">https://en.wikipedia.org/wiki/Heavy-tailed_distribution</a>"},{"pid":"5d5774aa817c3a7579872f31d0fd577a265d8acf","tid":489619,"uid":132931,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-14T07:35:21.000Z","msg":"可唔可以白話D咁講 睇完都係唔多明"},{"pid":"ec3d5e2e97e7edff09821bf93ddf822c8e7b42b4","tid":489619,"uid":132931,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-14T07:35:39.000Z","msg":"<blockquote><blockquote>想問下fat-tailed 同heavy tailed 有咩分別 睇完WIKI唔太明<img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /></blockquote><br />\nIn probability theory, <span style=\"color: red;\"><ins>heavy-tailed distributions</ins></span> are probability distributions <ins>whose tails are <strong>not exponentially bounded</strong></ins>: that is, they have <ins>heavier tails than the exponential distribution</ins>.<br />\n<br />\n...<br />\n<br />\nA <span style=\"color: red;\"><ins>fat-tailed</ins></span> distribution is a distribution for which the probability density function, for large x, <ins>goes to zero as a power x^{-a}</ins>. Since such a power is always bounded below by the probability density function of an exponential distribution, <ins>fat-tailed distributions are always heavy-tailed</ins>. ...<br />\n<br />\nSource: <a href=\"https://en.wikipedia.org/wiki/Heavy-tailed_distribution\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FHeavy-tailed_distribution&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=45d6c888\" target=\"_blank\">https://en.wikipedia.org/wiki/Heavy-tailed_distribution</a></blockquote><br />\n可唔可以白話D咁講 睇完都係唔多明"},{"pid":"4c2a7dcda6971979ac8a662ec0f1331fe682b477","tid":489619,"uid":34301,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-14T09:15:48.000Z","msg":"<blockquote><blockquote><blockquote>想問下fat-tailed 同heavy tailed 有咩分別 睇完WIKI唔太明<img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /></blockquote><br />\nIn probability theory, <span style=\"color: red;\"><ins>heavy-tailed distributions</ins></span> are probability distributions <ins>whose tails are <strong>not exponentially bounded</strong></ins>: that is, they have <ins>heavier tails than the exponential distribution</ins>.<br />\n<br />\n...<br />\n<br />\nA <span style=\"color: red;\"><ins>fat-tailed</ins></span> distribution is a distribution for which the probability density function, for large x, <ins>goes to zero as a power x^{-a}</ins>. Since such a power is always bounded below by the probability density function of an exponential distribution, <ins>fat-tailed distributions are always heavy-tailed</ins>. ...<br />\n<br />\nSource: <a href=\"https://en.wikipedia.org/wiki/Heavy-tailed_distribution\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FHeavy-tailed_distribution&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=45d6c888\" target=\"_blank\">https://en.wikipedia.org/wiki/Heavy-tailed_distribution</a></blockquote><br />\n可唔可以白話D咁講 睇完都係唔多明</blockquote><br />\n你可以當係啲tail轉彎嘅速度比其他exponential family嘅distribution會慢啲"},{"pid":"a34ad2f1282a446c47e6b580e51f35d50b220294","tid":489619,"uid":34301,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-14T09:28:50.000Z","msg":"<blockquote><blockquote><blockquote><blockquote>想問下fat-tailed 同heavy tailed 有咩分別 睇完WIKI唔太明<img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /></blockquote><br />\nIn probability theory, <span style=\"color: red;\"><ins>heavy-tailed distributions</ins></span> are probability distributions <ins>whose tails are <strong>not exponentially bounded</strong></ins>: that is, they have <ins>heavier tails than the exponential distribution</ins>.<br />\n<br />\n...<br />\n<br />\nA <span style=\"color: red;\"><ins>fat-tailed</ins></span> distribution is a distribution for which the probability density function, for large x, <ins>goes to zero as a power x^{-a}</ins>. Since such a power is always bounded below by the probability density function of an exponential distribution, <ins>fat-tailed distributions are always heavy-tailed</ins>. ...<br />\n<br />\nSource: <a href=\"https://en.wikipedia.org/wiki/Heavy-tailed_distribution\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FHeavy-tailed_distribution&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=45d6c888\" target=\"_blank\">https://en.wikipedia.org/wiki/Heavy-tailed_distribution</a></blockquote><br />\n可唔可以白話D咁講 睇完都係唔多明</blockquote><br />\n你可以當係啲tail轉彎嘅速度比其他exponential family嘅distribution會慢啲</blockquote><br />\n不過其實都唔一定<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"35571a344a6ba152b64d89690dcab6df9099211d","tid":489619,"uid":132931,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-14T10:37:37.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote>想問下fat-tailed 同heavy tailed 有咩分別 睇完WIKI唔太明<img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /></blockquote><br />\nIn probability theory, <span style=\"color: red;\"><ins>heavy-tailed distributions</ins></span> are probability distributions <ins>whose tails are <strong>not exponentially bounded</strong></ins>: that is, they have <ins>heavier tails than the exponential distribution</ins>.<br />\n<br />\n...<br />\n<br />\nA <span style=\"color: red;\"><ins>fat-tailed</ins></span> distribution is a distribution for which the probability density function, for large x, <ins>goes to zero as a power x^{-a}</ins>. Since such a power is always bounded below by the probability density function of an exponential distribution, <ins>fat-tailed distributions are always heavy-tailed</ins>. ...<br />\n<br />\nSource: <a href=\"https://en.wikipedia.org/wiki/Heavy-tailed_distribution\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FHeavy-tailed_distribution&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=45d6c888\" target=\"_blank\">https://en.wikipedia.org/wiki/Heavy-tailed_distribution</a></blockquote><br />\n可唔可以白話D咁講 睇完都係唔多明</blockquote><br />\n你可以當係啲tail轉彎嘅速度比其他exponential family嘅distribution會慢啲</blockquote><br />\n不過其實都唔一定<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n我知道heavy-tail一般係指尾端GE機率比指數分配 GE機率高<br />\n但係我睇完fat-tailed 唔太明fat-tailed同heavy-tailed GE分別 英文唔係太好<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"cf137c8e7bebbba2330ba7e8971cc01d35ba66de","tid":489619,"uid":96324,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-14T10:57:24.000Z","msg":"<blockquote>有無multivariate? <img src=\"/assets/faces/normal/good.gif\" class=\"hkgmoji\" /></blockquote>"},{"pid":"9feff28036d8e92c63f2195ef2091c345e4122a5","tid":489619,"uid":34301,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-14T11:00:05.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>想問下fat-tailed 同heavy tailed 有咩分別 睇完WIKI唔太明<img src=\"/assets/faces/normal/chicken.gif\" class=\"hkgmoji\" /></blockquote><br />\nIn probability theory, <span style=\"color: red;\"><ins>heavy-tailed distributions</ins></span> are probability distributions <ins>whose tails are <strong>not exponentially bounded</strong></ins>: that is, they have <ins>heavier tails than the exponential distribution</ins>.<br />\n<br />\n...<br />\n<br />\nA <span style=\"color: red;\"><ins>fat-tailed</ins></span> distribution is a distribution for which the probability density function, for large x, <ins>goes to zero as a power x^{-a}</ins>. Since such a power is always bounded below by the probability density function of an exponential distribution, <ins>fat-tailed distributions are always heavy-tailed</ins>. ...<br />\n<br />\nSource: <a href=\"https://en.wikipedia.org/wiki/Heavy-tailed_distribution\" data-sr-url=\"https://r.lihkg.com/link?u=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FHeavy-tailed_distribution&d=9XfMOBse%2BFxN9d%2B%2Faax2U1zEg0sy7MJ6GkP0ogsbSqo%3D&h=45d6c888\" target=\"_blank\">https://en.wikipedia.org/wiki/Heavy-tailed_distribution</a></blockquote><br />\n可唔可以白話D咁講 睇完都係唔多明</blockquote><br />\n你可以當係啲tail轉彎嘅速度比其他exponential family嘅distribution會慢啲</blockquote><br />\n不過其實都唔一定<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n我知道heavy-tail一般係指尾端GE機率比指數分配 GE機率高<br />\n但係我睇完fat-tailed 唔太明fat-tailed同heavy-tailed GE分別 英文唔係太好<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" /></blockquote><br />\n你啱<br />\n其實主要分別係fat-tailed嘅mgf除咗係undefined，條尾重要係以幾何級數decay<br />\n其他heavy-tailed distribution就唔一定係咁"},{"pid":"0e21c01338ed592ef02b43d64bf72eac9e90a5f6","tid":489619,"uid":34969,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-15T15:11:40.000Z","msg":"留名學野<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" />"},{"pid":"c66082c9a10a1535d438b6514f1540c9f73587d0","tid":489619,"uid":92117,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-16T07:29:24.000Z","msg":"想問下pmf同pdf有咩用<img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <br />\n個人認為P(X=x)/P(a&lt;X&lt;b)完全可以代替佢地"},{"pid":"a4b3e7680d2a0b4b52bb3011b95e741b375cddda","tid":489619,"uid":100760,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-16T09:37:56.000Z","msg":"<blockquote>想問下pmf同pdf有咩用<img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <br />\n個人認為P(X=x)/P(a&lt;X&lt;b)完全可以代替佢地</blockquote><br />\npmf同P(X=x)應該同一樣嘢嚟架啵<br />\n<br />\n至於用P(a&lt;X&lt;b)代替pdf，如果你只係想知probability，係可行嘅<br />\n但如果想搵E(X), where X is not a nonnegative Random Variable 嘅話，應該無得唔用pdf？"},{"pid":"12c7417158ba1452bb34e4fb902ac235a3146e41","tid":489619,"uid":92117,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-16T13:16:43.000Z","msg":"<blockquote><blockquote>想問下pmf同pdf有咩用<img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <br />\n個人認為P(X=x)/P(a&lt;X&lt;b)完全可以代替佢地</blockquote><br />\npmf同P(X=x)應該同一樣嘢嚟架啵<br />\n<br />\n至於用P(a&lt;X&lt;b)代替pdf，如果你只係想知probability，係可行嘅<br />\n但如果想搵E(X), where X is not a nonnegative Random Variable 嘅話，應該無得唔用pdf？</blockquote><br />\n所以唔知pmf整出嚟為乜<br />\n又好似冇實際用途<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /> <br />\n搵E(X)應該得掛<br />\nIntegrate from a to b [x*(d/dx)(P(a&lt;X&lt;x))]dx"},{"pid":"dcb3c8d442389130c9d990fe4b87906d3b9b1f5b","tid":489619,"uid":13901,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-16T13:36:13.000Z","msg":"<blockquote><blockquote><blockquote>想問下pmf同pdf有咩用<img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <br />\n個人認為P(X=x)/P(a&lt;X&lt;b)完全可以代替佢地</blockquote><br />\npmf同P(X=x)應該同一樣嘢嚟架啵<br />\n<br />\n至於用P(a&lt;X&lt;b)代替pdf，如果你只係想知probability，係可行嘅<br />\n但如果想搵E(X), where X is not a nonnegative Random Variable 嘅話，應該無得唔用pdf？</blockquote><br />\n所以唔知pmf整出嚟為乜<br />\n又好似冇實際用途<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /> <br />\n搵E(X)應該得掛<br />\nIntegrate from a to b [x*(d/dx)(P(a&lt;X&lt;x))]dx</blockquote><br />\n你唔好改一改個樣就當冇用到pdf/pmf得唔得<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"7dea4c78d286db158476f4e5d55ad40aef6735cd","tid":489619,"uid":69125,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-16T13:40:11.000Z","msg":"<blockquote><blockquote><blockquote><blockquote>想問下pmf同pdf有咩用<img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <br />\n個人認為P(X=x)/P(a&lt;X&lt;b)完全可以代替佢地</blockquote><br />\npmf同P(X=x)應該同一樣嘢嚟架啵<br />\n<br />\n至於用P(a&lt;X&lt;b)代替pdf，如果你只係想知probability，係可行嘅<br />\n但如果想搵E(X), where X is not a nonnegative Random Variable 嘅話，應該無得唔用pdf？</blockquote><br />\n所以唔知pmf整出嚟為乜<br />\n又好似冇實際用途<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /> <br />\n搵E(X)應該得掛<br />\nIntegrate from a to b [x*(d/dx)(P(a&lt;X&lt;x))]dx</blockquote><br />\n你唔好改一改個樣就當冇用到pdf/pmf得唔得<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"44e8e216effc64c8adaaa66667fc7f60726e483a","tid":489619,"uid":92117,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-16T13:45:03.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote>想問下pmf同pdf有咩用<img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <br />\n個人認為P(X=x)/P(a&lt;X&lt;b)完全可以代替佢地</blockquote><br />\npmf同P(X=x)應該同一樣嘢嚟架啵<br />\n<br />\n至於用P(a&lt;X&lt;b)代替pdf，如果你只係想知probability，係可行嘅<br />\n但如果想搵E(X), where X is not a nonnegative Random Variable 嘅話，應該無得唔用pdf？</blockquote><br />\n所以唔知pmf整出嚟為乜<br />\n又好似冇實際用途<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /> <br />\n搵E(X)應該得掛<br />\nIntegrate from a to b [x*(d/dx)(P(a&lt;X&lt;x))]dx</blockquote><br />\n你唔好改一改個樣就當冇用到pdf/pmf得唔得<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n唔係話有冇用到<br />\n我係想講唔需要特別定義pdf同pmf出黎<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n感覺好多餘"},{"pid":"54308db3c6c52c0199ebc532d239d2ba12ef57fd","tid":489619,"uid":34301,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-16T15:38:51.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>想問下pmf同pdf有咩用<img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <br />\n個人認為P(X=x)/P(a&lt;X&lt;b)完全可以代替佢地</blockquote><br />\npmf同P(X=x)應該同一樣嘢嚟架啵<br />\n<br />\n至於用P(a&lt;X&lt;b)代替pdf，如果你只係想知probability，係可行嘅<br />\n但如果想搵E(X), where X is not a nonnegative Random Variable 嘅話，應該無得唔用pdf？</blockquote><br />\n所以唔知pmf整出嚟為乜<br />\n又好似冇實際用途<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /> <br />\n搵E(X)應該得掛<br />\nIntegrate from a to b [x*(d/dx)(P(a&lt;X&lt;x))]dx</blockquote><br />\n你唔好改一改個樣就當冇用到pdf/pmf得唔得<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n唔係話有冇用到<br />\n我係想講唔需要特別定義pdf同pmf出黎<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n感覺好多餘</blockquote><br />\n呢啲嘢係foundation嚟<br />\n唔係點奠定之後嘅measure-theoretic definition<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"d42febc9b2851ccb779d31d16f75c8df5991d921","tid":489619,"uid":69125,"like":1,"dislike":0,"score":1,"citedBy":0,"replyTime":"2017-12-16T15:44:46.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><blockquote>想問下pmf同pdf有咩用<img src=\"/assets/faces/normal/hoho.gif\" class=\"hkgmoji\" /> <br />\n個人認為P(X=x)/P(a&lt;X&lt;b)完全可以代替佢地</blockquote><br />\npmf同P(X=x)應該同一樣嘢嚟架啵<br />\n<br />\n至於用P(a&lt;X&lt;b)代替pdf，如果你只係想知probability，係可行嘅<br />\n但如果想搵E(X), where X is not a nonnegative Random Variable 嘅話，應該無得唔用pdf？</blockquote><br />\n所以唔知pmf整出嚟為乜<br />\n又好似冇實際用途<img src=\"/assets/faces/normal/banghead.gif\" class=\"hkgmoji\" /> <br />\n搵E(X)應該得掛<br />\nIntegrate from a to b [x*(d/dx)(P(a&lt;X&lt;x))]dx</blockquote><br />\n你唔好改一改個樣就當冇用到pdf/pmf得唔得<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /></blockquote><br />\n唔係話有冇用到<br />\n我係想講唔需要特別定義pdf同pmf出黎<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" /> <br />\n感覺好多餘</blockquote><br />\n你係咪純粹覺得pmf pdf比起probability虛無漂渺所以覺得佢冇用?<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"3804618994f8c321f2f7a9cb77c10b230edf9cd0","tid":489619,"uid":66927,"like":0,"dislike":0,"score":0,"citedBy":1,"replyTime":"2017-12-16T15:45:07.000Z","msg":"樓主係hku？<img src=\"/assets/faces/normal/angel.gif\" class=\"hkgmoji\" />"},{"pid":"621cada8314c01362729dfd1df0b92b7a622469d","tid":489619,"uid":34301,"like":0,"dislike":0,"score":0,"citedBy":1,"replyTime":"2017-12-18T14:57:28.000Z","msg":"<img src=\"/assets/faces/normal/tongue.gif\" class=\"hkgmoji\" />"},{"pid":"e2f8bc47f479f0b125af0316e2055c36c6d7cfaa","tid":489619,"uid":93736,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-18T16:13:48.000Z","msg":"<img src=\"/assets/faces/normal/angry.gif\" class=\"hkgmoji\" />"},{"pid":"aeb91438dc0046806f7267d7da921f80276c8172","tid":489619,"uid":82382,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-18T16:19:28.000Z","msg":"留名學野<img src=\"/assets/faces/normal/angel.gif\" class=\"hkgmoji\" />"},{"pid":"3ddf857f2c523e3f082afba9ce9e43f3773f3182","tid":489619,"uid":34881,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-18T16:20:29.000Z","msg":"lm"},{"pid":"881a2c1284d1c932005846119323a02da5dde926","tid":489619,"uid":60261,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-23T10:05:57.000Z","msg":"有邊本書可以平時睇下學下basic stat咁"},{"pid":"b5598219cd2370a4decaf7a8b3d24125c88a0d36","tid":489619,"uid":69779,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-23T10:08:20.000Z","msg":"<img src=\"/assets/faces/normal/adore.gif\" class=\"hkgmoji\" />"},{"pid":"3ded90fb274ef80c48061fe408b71920de485af5","tid":489619,"uid":161501,"like":2,"dislike":0,"score":2,"citedBy":0,"replyTime":"2017-12-23T11:41:30.000Z","msg":"完sem拉!!!!!!!!!<img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/normal/agree.gif\" class=\"hkgmoji\" /> <br />\nHypothesis Testing (Concepts)<br />\n終於到hypothesis testing拉，亦都係應用十分廣泛既統計工具。<br />\n不如先黎一個motivation。<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /> <br />\n      假設你研究緊毒男平均初戀年齡<img src=\"/assets/faces/lomoji/08.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/08.png\" class=\"hkgmoji\" /> ，然後你隨機搵左100個毒男(Suppose曾經初戀)，紀錄低佢地既初戀年齡。<br />\n      然後你想問:毒男平均初戀年齡會唔會大過某個歲數(Let say 30)你會點做?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> <br />\n統計學上，Hypothesis Testing就可以幫助你落決定。<br />\n思路係先假設毒男平均初戀年齡細過30，我地叫null hypothesis(寫做H0)，想問既野係alternative hypothesis(寫做H1)，然後睇下如果H0係啱，generate我呢個sample甚至更extreme既case既機會大唔大。<img src=\"/assets/faces/lomoji/03.png\" class=\"hkgmoji\" /> <br />\n正常黎講，越細既機會，你會覺得越冇可能H０係啱。For example，擲100次骰,，40次係&rdquo;6&rdquo;，然後你想問粒係咪唔fair。<br />\n這時，<br />\n<div style=\"text-align: center;\">H0 : P(getting a &quot;6&quot;)&le;1/6  vs H1 : P(getting a &quot;6&quot;)&gt;1/6  </div><br />\n大多數時候，你會見到H0寫等於1/6。其實冇所謂，因為construct the test 既時候，都係拎番等於去計。<br />\n回正題，你會心諗：「大佬，100次有40次，點會fair?」<img src=\"/assets/faces/lomoji/10.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/10.png\" class=\"hkgmoji\" /> <br />\n係Hypothesis testing既解釋係:當H0 is true，the probability of getting 40 times &ldquo;6&rdquo;(or more extreme) is small。Therefore，we think that H0 is unlikely to be true.<br />\n如果擲到更多既&rdquo;6&rdquo;，你會覺得H0更加冇可能啱。<br />\n但問題係，點樣決定probability為之小？幾時要去reject H0 ?(reject H0代表你更加相信 H1 為真)<br />\n咁就要講Type 1 error and Type 2 error (通常寫 Type I error, Type II error)。<br />\n你reject or not reject H0，都有機會犯錯，見下表：<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/23/193613_da75ebd829e15e01efc01ca936aac39b.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F23%2F193613_da75ebd829e15e01efc01ca936aac39b.png&h=f210819d&s={SIZE}\" /><br />\n我地會adjust Type I error，盡量keep low (typically 0.05,呢個數叫level of significance).意思係，冇充分證據證明H1 is true，我地都唔會傾向接受H1<br />\n解答番上面，點樣決定probability為之小？就係低過level of significance。呢個probability有個名，叫 p-value。<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/slick.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/slick.gif\" class=\"hkgmoji\" /> <br />\n幾乎全部software計既時候，都係俾呢個數你，由你去決定reject or not.<img src=\"/assets/faces/xm/kiss.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/kiss.gif\" class=\"hkgmoji\" /> <br />\n最後講多一個term，power of a test。就係如果H1係啱，而你能夠成功reject H0  既probability。<br />\ni.e Power = 1-P(Type II error)"},{"pid":"013a97aca03df8484dbd03f85863672b04428ca2","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"quote":{"pid":"3804618994f8c321f2f7a9cb77c10b230edf9cd0","tid":489619,"uid":66927,"like":0,"dislike":0,"score":0,"citedBy":1,"replyTime":"2017-12-16T15:45:07.000Z","msg":"樓主係hku？<img src=\"/assets/faces/normal/angel.gif\" class=\"hkgmoji\" />"},"citedBy":0,"replyTime":"2017-12-23T11:51:52.000Z","msg":"<img src=\"/assets/faces/normal/no.gif\" class=\"hkgmoji\" />"},{"pid":"ce06b6a6a2fe768e51ab75301011c7368c00c83c","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"quote":{"pid":"621cada8314c01362729dfd1df0b92b7a622469d","tid":489619,"uid":34301,"like":0,"dislike":0,"score":0,"citedBy":1,"replyTime":"2017-12-18T14:57:28.000Z","msg":"<img src=\"/assets/faces/normal/tongue.gif\" class=\"hkgmoji\" />"},"citedBy":0,"replyTime":"2017-12-23T11:56:51.000Z","msg":"<img src=\"/assets/faces/normal/fuck.gif\" class=\"hkgmoji\" />"},{"pid":"0833a0a708c0fa7e2f64a23a2a48598afa819f28","tid":489619,"uid":13901,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-23T12:14:58.000Z","msg":"<blockquote><blockquote><img src=\"/assets/faces/normal/good.gif\" class=\"hkgmoji\" /></blockquote><img src=\"/assets/faces/normal/fuck.gif\" class=\"hkgmoji\" /></blockquote><br />\n好容易 prof 好人黎<img src=\"/assets/faces/xm/wink.gif\" class=\"hkgmoji\" />"},{"pid":"a936855a90a48b4683caf9ee967d410e7d80c9fb","tid":489619,"uid":34301,"like":0,"dislike":0,"score":0,"citedBy":1,"replyTime":"2017-12-23T13:42:13.000Z","msg":"<blockquote><blockquote><blockquote><img src=\"/assets/faces/normal/good.gif\" class=\"hkgmoji\" /></blockquote><img src=\"/assets/faces/normal/fuck.gif\" class=\"hkgmoji\" /></blockquote><br />\n好容易 prof 好人黎<img src=\"/assets/faces/xm/wink.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"/assets/faces/xm/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"8dc9fd8b841e66f8523a1c00c72507c45a2e322a","tid":489619,"uid":62610,"like":0,"dislike":0,"score":0,"quote":{"pid":"a936855a90a48b4683caf9ee967d410e7d80c9fb","tid":489619,"uid":34301,"like":0,"dislike":0,"score":0,"citedBy":1,"replyTime":"2017-12-23T13:42:13.000Z","msg":"<blockquote><blockquote><blockquote><img src=\"/assets/faces/normal/good.gif\" class=\"hkgmoji\" /></blockquote><img src=\"/assets/faces/normal/fuck.gif\" class=\"hkgmoji\" /></blockquote><br />\n好容易 prof 好人黎<img src=\"/assets/faces/xm/wink.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"/assets/faces/xm/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/sosad.gif\" class=\"hkgmoji\" />"},"citedBy":0,"replyTime":"2017-12-26T07:18:56.000Z","msg":"拿個exam真係唔難架<img src=\"/assets/faces/xm/hehe.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/hehe.gif\" class=\"hkgmoji\" />"},{"pid":"75cd8abbb56dfb30e2ab7d34a614868401da4e50","tid":489619,"uid":10905,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-26T07:22:35.000Z","msg":"Hypothesis係度就咁講應該好難明<img src=\"/assets/faces/normal/sosad.gif\" class=\"hkgmoji\" />"},{"pid":"85624fc199d2eaeca71f00f60c6fb561942ddc04","tid":489619,"uid":13901,"like":0,"dislike":0,"score":0,"citedBy":1,"replyTime":"2017-12-26T08:12:32.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><img src=\"/assets/faces/normal/good.gif\" class=\"hkgmoji\" /></blockquote><img src=\"/assets/faces/normal/fuck.gif\" class=\"hkgmoji\" /></blockquote><br />\n好容易 prof 好人黎<img src=\"/assets/faces/xm/wink.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"/assets/faces/xm/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/sosad.gif\" class=\"hkgmoji\" /></blockquote>拿個exam真係唔難架<img src=\"/assets/faces/xm/hehe.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/hehe.gif\" class=\"hkgmoji\" /></blockquote><br />\nChing滿分？<img src=\"/assets/faces/xm/hehe.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/hehe.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/hehe.gif\" class=\"hkgmoji\" />"},{"pid":"bc1c1ea5f190e24edb488374eedf3e64eaf5d4c5","tid":489619,"uid":62610,"like":0,"dislike":0,"score":0,"quote":{"pid":"85624fc199d2eaeca71f00f60c6fb561942ddc04","tid":489619,"uid":13901,"like":0,"dislike":0,"score":0,"citedBy":1,"replyTime":"2017-12-26T08:12:32.000Z","msg":"<blockquote><blockquote><blockquote><blockquote><blockquote><img src=\"/assets/faces/normal/good.gif\" class=\"hkgmoji\" /></blockquote><img src=\"/assets/faces/normal/fuck.gif\" class=\"hkgmoji\" /></blockquote><br />\n好容易 prof 好人黎<img src=\"/assets/faces/xm/wink.gif\" class=\"hkgmoji\" /></blockquote><br />\n<img src=\"/assets/faces/xm/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/sosad.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/sosad.gif\" class=\"hkgmoji\" /></blockquote>拿個exam真係唔難架<img src=\"/assets/faces/xm/hehe.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/hehe.gif\" class=\"hkgmoji\" /></blockquote><br />\nChing滿分？<img src=\"/assets/faces/xm/hehe.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/hehe.gif\" class=\"hkgmoji\" /> <img src=\"/assets/faces/xm/hehe.gif\" class=\"hkgmoji\" />"},"citedBy":0,"replyTime":"2017-12-26T16:53:44.000Z","msg":"<img src=\"/assets/faces/normal/oh.gif\" class=\"hkgmoji\" />"},{"pid":"f51b81add37a8d725bdb2565d5b43bdacfc577ef","tid":489619,"uid":91432,"like":0,"dislike":2,"score":-2,"citedBy":0,"replyTime":"2017-12-26T17:43:34.000Z","msg":"最憎stattt"},{"pid":"1e5f7243b789250e19c30fc84dcb09872662950a","tid":489619,"uid":23294,"like":0,"dislike":0,"score":0,"citedBy":0,"replyTime":"2017-12-29T16:54:34.000Z","msg":"樓主nonparametric嗰part仲寫唔寫？"},{"pid":"9ea922d50e92e2ce4db2f9d2f80866f7caab0596","tid":489619,"uid":161501,"like":0,"dislike":0,"score":0,"citedBy":1,"replyTime":"2017-12-30T09:21:56.000Z","msg":"其實我仲想講下Hypothesis Testing.我舉個例子說明，請看下圖，<br />\n<img src=\"https://img.eservice-hk.net/upload/2017/12/30/172048_4f179790a6af46c92ec7879c636556d3.png\" data-thumbnail-src=\"https://i.lih.kg/thumbnail?u=https%3A%2F%2Fimg.eservice-hk.net%2Fupload%2F2017%2F12%2F30%2F172048_4f179790a6af46c92ec7879c636556d3.png&h=d28678af&s={SIZE}\" /><br />\n唔洗理的code，只需要知道我地做緊的咩。<br />\n<br />\n我嘗試模擬擲1000次骰仔，然後count下有幾多6。發覺第一粒有157次，第二粒有237次，然後你想問：粒骰fair唔fair?<img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/26.png\" class=\"hkgmoji\" /> <br />\n當然，你開始會去計：若粒骰fair，1000次平均應有1000/6=167次左右。你應該會覺得第一粒好似fair，第二粒唔太fair。但你要明白，擲到幾多次，完全係隨機，難保你唔好彩，粒骰fair，但你一個6都冇。<br />\n可你會話：車，邊有咁邪？<img src=\"/assets/faces/lomoji/22.png\" class=\"hkgmoji\" /> <img src=\"/assets/faces/lomoji/22.png\" class=\"hkgmoji\" /> <br />\n所以我地有一個systematic既方法幫你決定。<br />\n就係上post既Hypothesis Testing。我地發現，如果粒骰係fair，骰到157次或更少既prob係0.219，骰到237次或更少既prob係接近1，換言之，237次或更多既prob接近0，基本上即係好難擲到咁鬼多次。之後，我地根據呢個prob做判斷。"},{"pid":"e5dfc91dde492a15b1d844891de0c5dcaa557e8b","tid":489619,"uid":81824,"like":0,"dislike":0,"score":0,"citedBy":1,"replyTime":"2017-12-30T10:57:45.000Z","msg":"LM<br />\npsycho 有stat course<br />\n但係啲stat唔撚係stat<br />\n飛左好多同數有關嘅部分(eg proof)<br />\n<br />\nbetween 有冇得解下啲符號<br />\nCLM 個到嘅 N(0,1) <br />\n個括號係咩黎？<br />\n未見過啊<img src=\"/assets/faces/lomoji/05.png\" class=\"hkgmoji\" />"}]}